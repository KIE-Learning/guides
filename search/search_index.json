{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home What will you learn today? Getting started with RHPAM Learn DMN Event-driven processes Learn the tools RHPAM on OpenShift About the guides: Getting Started with RHPAM: Order Management A great guide for users who are trying RHPAM for the first time. Recommended getting started guide. Learn DMN In this hands-on workshop, users can learn about the DMN specification, author decisions, and deploy it using Red Hat Decision Manager with basic, intermediate and advanced exercises. Event-driven processes This hands-on workshop allows the user to validate the experience of creating loan approval workflow with decision automation. The user will also have an introduction to Fuse, develop an endpoint and consume it using the workflow. Learn the tools In this hands-on workshop, create new decision services using Kogito tooling and the VSCode extension , create unit tests and deploy them on KIE Server. Learn how to deploy RHPAM on OpenShift using Operators Try out the business automation operator and learn how to manage your KIE Apps on OpenShift. Check the Learn more section for more guides and references about business automation with the projects under the KIE umbrella.","title":"Home"},{"location":"#home","text":"What will you learn today? Getting started with RHPAM Learn DMN Event-driven processes Learn the tools RHPAM on OpenShift","title":"Home"},{"location":"#about-the-guides","text":"Getting Started with RHPAM: Order Management A great guide for users who are trying RHPAM for the first time. Recommended getting started guide. Learn DMN In this hands-on workshop, users can learn about the DMN specification, author decisions, and deploy it using Red Hat Decision Manager with basic, intermediate and advanced exercises. Event-driven processes This hands-on workshop allows the user to validate the experience of creating loan approval workflow with decision automation. The user will also have an introduction to Fuse, develop an endpoint and consume it using the workflow. Learn the tools In this hands-on workshop, create new decision services using Kogito tooling and the VSCode extension , create unit tests and deploy them on KIE Server. Learn how to deploy RHPAM on OpenShift using Operators Try out the business automation operator and learn how to manage your KIE Apps on OpenShift. Check the Learn more section for more guides and references about business automation with the projects under the KIE umbrella.","title":"About the guides:"},{"location":"more/","text":"Learn more Videos KIE Live events are live streams designed to facilitate knowledge sharing about the Business Automation topic, including business rules, decisions, processes, resource planning, tooling, and AI. They're community events and anyone is welcome to attend. Check out all the KIE Lives at: https://red.ht/kielives Red Hat Scholars You can refer to Red Hat Scholars to find several up-to-date guides about business automation topics, including Kogito. Check out all the great guides available at: https://redhat-scholars.github.io/cloud-native-business-automation/ Guides There are several guided exercises and workshops that are not yet part of this guide. You can find them below: Loan Approval Workshop with DMN This workshop is aimed at providing hands on experience creating DMN assets. This lab will implement a Loan Approval workflow. Check out this guide here . Loan Approval Workshop This workshop is aimed at providing hands-on experience creating Decision and Process Assets. This lab will implement a Loan Approval workflow. Check out this guide here . Getting started with OptaPlanner This is a step-by-step guided exercise for a first experience with OptaPlanner running with Quarkus. It brings explanation of concepts along with the actual implementation and deployment of a new project. Check out this guide here . KIE Learning: RHPAM and RHDM This repository is a set of explanation and hands-on labs which you can try on your environment and follow at your own pace. The step-by-step guides covers different topics, since basics to more advanced and specific features. The content is not sequencial and it covers Decision Manager, Business Optimizer, Process Automation Manager and Kogito. Notice that this guide brings updated versions of some of the guides listed below. Setup 00: Installing RHDM and RHPAM => Pre requisite for most of the hands-on labs. 00: OpenShift Setup => Pre requisite for hands-on labs that uses OpenShift. Optaplanner (included in both rhdm and rhpam) 11: Shadow Variables 21: Conference Scheduling Red Hat Decision Manager (RHDM): 01: The Value of Decision Management 02: Introduction to Decision Central and Decision Server Creating a project Importing Assets 03: Authoring Decision Tables 04: Introducing DMN 06: Intermediate DMN 07: Advanced DMN 12: Decisions and AI: Combining DMN with PMML Lab 13: Prometheus: Monitoring DMN decisions with KIE-Server and Prometheus 20: Test Scenarios Red Hat Process Automation Manager (RHPAM): 10: Create Order Management Application 14: Recommendation Engine 15: Operator on OCP4 17: Event Driven Decision 19: Collaboration via Business Central 23: Process Modeling Lab: The new BPMN editor 24: Case Management 25: SpringBoot","title":"Learn more"},{"location":"more/#learn-more","text":"","title":"Learn more"},{"location":"more/#videos","text":"KIE Live events are live streams designed to facilitate knowledge sharing about the Business Automation topic, including business rules, decisions, processes, resource planning, tooling, and AI. They're community events and anyone is welcome to attend. Check out all the KIE Lives at: https://red.ht/kielives","title":"Videos"},{"location":"more/#red-hat-scholars","text":"You can refer to Red Hat Scholars to find several up-to-date guides about business automation topics, including Kogito. Check out all the great guides available at: https://redhat-scholars.github.io/cloud-native-business-automation/","title":"Red Hat Scholars"},{"location":"more/#guides","text":"There are several guided exercises and workshops that are not yet part of this guide. You can find them below: Loan Approval Workshop with DMN This workshop is aimed at providing hands on experience creating DMN assets. This lab will implement a Loan Approval workflow. Check out this guide here . Loan Approval Workshop This workshop is aimed at providing hands-on experience creating Decision and Process Assets. This lab will implement a Loan Approval workflow. Check out this guide here . Getting started with OptaPlanner This is a step-by-step guided exercise for a first experience with OptaPlanner running with Quarkus. It brings explanation of concepts along with the actual implementation and deployment of a new project. Check out this guide here . KIE Learning: RHPAM and RHDM This repository is a set of explanation and hands-on labs which you can try on your environment and follow at your own pace. The step-by-step guides covers different topics, since basics to more advanced and specific features. The content is not sequencial and it covers Decision Manager, Business Optimizer, Process Automation Manager and Kogito. Notice that this guide brings updated versions of some of the guides listed below. Setup 00: Installing RHDM and RHPAM => Pre requisite for most of the hands-on labs. 00: OpenShift Setup => Pre requisite for hands-on labs that uses OpenShift. Optaplanner (included in both rhdm and rhpam) 11: Shadow Variables 21: Conference Scheduling Red Hat Decision Manager (RHDM): 01: The Value of Decision Management 02: Introduction to Decision Central and Decision Server Creating a project Importing Assets 03: Authoring Decision Tables 04: Introducing DMN 06: Intermediate DMN 07: Advanced DMN 12: Decisions and AI: Combining DMN with PMML Lab 13: Prometheus: Monitoring DMN decisions with KIE-Server and Prometheus 20: Test Scenarios Red Hat Process Automation Manager (RHPAM): 10: Create Order Management Application 14: Recommendation Engine 15: Operator on OCP4 17: Event Driven Decision 19: Collaboration via Business Central 23: Process Modeling Lab: The new BPMN editor 24: Case Management 25: SpringBoot","title":"Guides"},{"location":"guided_exercises/dmn/advanced-lab-authoring/","text":"Authoring the decisioning for the Call Center The problem statement describes a number of different inputs to our decision: Call : the incoming call into the call-centre Employees : the employees of certain office. Office : an office to which the call could potentially be routed. Furthermore, the problem statement describes that phone numbers could be banned. So, also banned numbers can be regarded as an input to our model (although we will not implement it as an input in this lab). With the given input, we need to make the following decisions: Accept Call : the final decision we need to make is whether the given office will accept the call. Can Handle Call : whether the office can actually accept the call. As defined in the problem statement, this depends on: whether the phone number has been banned; the purpose of the phone call (\u201chelp\u201d or \u201cobjection\u201d). . Accept Call Decision Structure Accept Call : the final decision we need to make is whether the given office will accept the call. Add a Decision node to the diagram by clicking on the Decision node icon and placing it in the DRD. Double-click on the node to set the name. We will name this node Accept Call . With the Accept Call node selected, open the property panel. Set the Output data type to boolean . The input of this decision is the incoming call , office and employee . Create these 3 input nodes and connect them to the Accept Call decision. We can now set data types of our input nodes. Click on the incoming call node, open the property panel and in the Output data type section and click on the Manage button. This will open the Custom Data Types window. In the Custom Data Types window, click on the + Add button. Define the data type tPhoneNumber as follows: Define another data type tCall as follows. Note that this datatype has a field that is of type tPhoneNumber , the type we defined earlier: When you\u2019ve created the tCall type, go back to the DRD by clicking on the Model tab. Select the incoming call node, and in the property panel, set the node\u2019s Output data type to tCall Next, define the following data type and set it as the Output data type of the office input as such: Define the data type for employees as follows. Note that we\u2019ve first defined the type tEmployee , and afterwards we\u2019ve defined tEmployees as a List of tEmployee . Decision Service With the main structure defined, we can now look at the requirements of the decision whether the office can actually accept the call. As defined in the problem statement, this depends on: whether the phone number has been banned. the purpose of the phone call (\"help\" or \"objection\"). We will model this decision as a DMN Decision Service that can be called by our main decision Accept Call . First, model the Decision Service in the DRD and give it the name Can Handle Call . Set it\u2019s Output data type to boolean . Add a Decision Node to the Decision Service . Name it Call Can Be Handled and set it\u2019s Output data type to boolean . Add 2 additional Decision Nodes and name them Is Banned and Call Purpose Accepted . Both should have an Output data type of type boolean . Connect the 2 Decision Nodes to the Call Can Be Handled node. The input to both the Is Banned and Call Purpose Accepted decisions is a call . Connect the existing node \"incoming call\" to the 2 decision nodes. The Is Banned decision also needs a collection of banned phone numbers. Instead of implementing this as an Input node, we will implement this as a DMN Relation Decision . Create a new Decision Node and name it Banned Phone Numbers . Connect it to the Is Banned decision node. The Ouput data type of this nodes is a new custom data type, which is a list of tPhoneNumber . We\u2019ll name this type tPhoneNumbers : Click on the Edit button of the Banned Phone Numbers node. Set the logic type of the decision to Relation . Create the following table: We can now implement the logic of the Is Banned decision. Click on the Edit button of the decision node. We will implement the logic as a Literal Expression . Define the following FEEL expression: list contains(Banned Phone Numbers, call.phone) The next node for which we want to implement the decision logic is Call Purpose Accepted . Click on the node, and click on the Edit button. Implement the following logic as a Decision Table : We can now implement the decision of Call Can Be Handled . Click on the node and click on the node\u2019s Edit button. In the decision editor, set the logic type to Decision Table and implement the following table: Create a DMN Knowledge Requirement from the Can Handle Call decision service to the Accept Call decision. \"Accept Call\" Decision Logic Implement the Accept Call decision logic as follows. Notice that the line 1 is the invocation of the decision service \"Can Handle Call\". This is an Invocation of the Can Handle Call service, passing the incoming call input as the variable call . The output of this invocation will be the boolean variable Call can be handled . The Call can be handled variable as then used to validate the decision result in the last line. Next steps We're done. Next, we should deploy the project in KIE Server and test the model using the REST and Java API.","title":"Call Centre - Authoring Decisions"},{"location":"guided_exercises/dmn/advanced-lab-authoring/#authoring-the-decisioning-for-the-call-center","text":"The problem statement describes a number of different inputs to our decision: Call : the incoming call into the call-centre Employees : the employees of certain office. Office : an office to which the call could potentially be routed. Furthermore, the problem statement describes that phone numbers could be banned. So, also banned numbers can be regarded as an input to our model (although we will not implement it as an input in this lab). With the given input, we need to make the following decisions: Accept Call : the final decision we need to make is whether the given office will accept the call. Can Handle Call : whether the office can actually accept the call. As defined in the problem statement, this depends on: whether the phone number has been banned; the purpose of the phone call (\u201chelp\u201d or \u201cobjection\u201d).","title":"Authoring the decisioning for the Call Center"},{"location":"guided_exercises/dmn/advanced-lab-authoring/#accept-call-decision-structure","text":"Accept Call : the final decision we need to make is whether the given office will accept the call. Add a Decision node to the diagram by clicking on the Decision node icon and placing it in the DRD. Double-click on the node to set the name. We will name this node Accept Call . With the Accept Call node selected, open the property panel. Set the Output data type to boolean . The input of this decision is the incoming call , office and employee . Create these 3 input nodes and connect them to the Accept Call decision. We can now set data types of our input nodes. Click on the incoming call node, open the property panel and in the Output data type section and click on the Manage button. This will open the Custom Data Types window. In the Custom Data Types window, click on the + Add button. Define the data type tPhoneNumber as follows: Define another data type tCall as follows. Note that this datatype has a field that is of type tPhoneNumber , the type we defined earlier: When you\u2019ve created the tCall type, go back to the DRD by clicking on the Model tab. Select the incoming call node, and in the property panel, set the node\u2019s Output data type to tCall Next, define the following data type and set it as the Output data type of the office input as such: Define the data type for employees as follows. Note that we\u2019ve first defined the type tEmployee , and afterwards we\u2019ve defined tEmployees as a List of tEmployee .","title":". Accept Call Decision Structure"},{"location":"guided_exercises/dmn/advanced-lab-authoring/#decision-service","text":"With the main structure defined, we can now look at the requirements of the decision whether the office can actually accept the call. As defined in the problem statement, this depends on: whether the phone number has been banned. the purpose of the phone call (\"help\" or \"objection\"). We will model this decision as a DMN Decision Service that can be called by our main decision Accept Call . First, model the Decision Service in the DRD and give it the name Can Handle Call . Set it\u2019s Output data type to boolean . Add a Decision Node to the Decision Service . Name it Call Can Be Handled and set it\u2019s Output data type to boolean . Add 2 additional Decision Nodes and name them Is Banned and Call Purpose Accepted . Both should have an Output data type of type boolean . Connect the 2 Decision Nodes to the Call Can Be Handled node. The input to both the Is Banned and Call Purpose Accepted decisions is a call . Connect the existing node \"incoming call\" to the 2 decision nodes. The Is Banned decision also needs a collection of banned phone numbers. Instead of implementing this as an Input node, we will implement this as a DMN Relation Decision . Create a new Decision Node and name it Banned Phone Numbers . Connect it to the Is Banned decision node. The Ouput data type of this nodes is a new custom data type, which is a list of tPhoneNumber . We\u2019ll name this type tPhoneNumbers : Click on the Edit button of the Banned Phone Numbers node. Set the logic type of the decision to Relation . Create the following table: We can now implement the logic of the Is Banned decision. Click on the Edit button of the decision node. We will implement the logic as a Literal Expression . Define the following FEEL expression: list contains(Banned Phone Numbers, call.phone) The next node for which we want to implement the decision logic is Call Purpose Accepted . Click on the node, and click on the Edit button. Implement the following logic as a Decision Table : We can now implement the decision of Call Can Be Handled . Click on the node and click on the node\u2019s Edit button. In the decision editor, set the logic type to Decision Table and implement the following table: Create a DMN Knowledge Requirement from the Can Handle Call decision service to the Accept Call decision.","title":"Decision Service"},{"location":"guided_exercises/dmn/advanced-lab-authoring/#accept-call-decision-logic","text":"Implement the Accept Call decision logic as follows. Notice that the line 1 is the invocation of the decision service \"Can Handle Call\". This is an Invocation of the Can Handle Call service, passing the incoming call input as the variable call . The output of this invocation will be the boolean variable Call can be handled . The Call can be handled variable as then used to validate the decision result in the last line.","title":"\"Accept Call\" Decision Logic"},{"location":"guided_exercises/dmn/advanced-lab-authoring/#next-steps","text":"We're done. Next, we should deploy the project in KIE Server and test the model using the REST and Java API.","title":"Next steps"},{"location":"guided_exercises/dmn/advanced-lab-deployment/","text":"Deploying and testing the Decision Service With our decision model completed, we can now package our DMN model in a Deployment Unit (KJAR), deploy it on the Execution Server and test our decision. Deploying the decision service To deploy your business application, follow these steps: In the bread-crumb navigation in the upper-left corner, click on call-centre-decisions to go back to the project\u2019s Library View. Click on the Deploy button in the upper-right corner of the screen. This will package our DMN mode in a Deployment Unit (KJAR) and deploy it onto the Execution Server (KIE-Server). Go to the Execution Servers perspective by clicking on \"Menu \u2192 Deploy \u2192 Execution Servers\". You will see the Deployment Unit deployed on the Execution Server. Testing DMN Solution In this section, you will test the DMN solution with Execution Server\u2019s Swagger interface and via Java KIE Client API. Testing the Decision Service via the REST API The Swagger interface provides the description and documentation of the Execution Server\u2019s RESTful API. At the same time, it allows the APIs to be called from the UI. This enables developers and users to quickly test a, in this case, a deployed DMN Service . Navigate to KIE Server swagger docs Locate the DMN Models section. The DMN API provides the DMN model as a RESTful resources, which accepts 2 operations: GET : Retrieves the DMN model. POST : Evaluates the decisions for a given input. Expand the GET operation by clicking on it. Click on the Try it out button. Set the containerId field to call-centre-decision and set the Response content type to application/json and click on Execute If requested, provide the username and password of your Business Central and KIE-Server user. The response will be the model-description of your DMN model. Next, we will evaluate our model with some input data. We need to provide our model with the incoming call , list of employees and office location . Expand the POST operation and click on the Try it out button Set the containerId field to call-centre-decisions . Set the Parameter content type and Response content type fields to application/json . Pass the following request to evaluate whether the given call is accepted by the call-centre. IMPORTANT : We\u2019re explicitly specifying the decision-name of the decision we want to evaluate. If we would not specify this, the engine will evaluate the full model, and hence will also require us to pass the call input. When we only evaluate the Accept Call decision, we only need to specify the inputs of Accept Call . In the decision service invocation in the Accept Call logic, the input incoming call is passed to the call parameter of the decision service. { \"decision-name\" : \"Accept Call\", \"dmn-context\":{ \"incoming call\":{ \"phone\": { \"country prefix\": \"+420\", \"phone number\": \"1234\" }, \"purpose\": \"help\" }, \"employees\": [{ \"name\": \"Duncan\", \"office location\": \"Rome\" }], \"office\": { \"location\": \"Rome\" } } } Click on Execute . The result value of the Accept Call should be true . Test the service with a number of other values. For example, specify a banned phone number like: +421 92000001 Using the KIE-Server Client Red Hat Decision Manager provides a KIE-Server Client API that allows the user to interact with the KIE-Server from a Java client using a higher level API. It abstracts the data marshalling and unmarshalling and the creation and execution of the RESTful commands from the developer, allowing him/her to focus on developing business logic. In this section we will create a simple Java client for our DMN model. IMPORTANT: If your KIE Server is exposed via https you need to configure the `javax.net.ssl.trustStore and javax.net.ssl.trustStorePassword in the Java client code using the Remote Java API. If not, you may get a rest.NoEndpointFoundException`. For more information check this solution Red Hat's knowledge base. Create a new Maven Java JAR project in your favourite IDE (e.g. IntelliJ, Eclipse, Visual Studio Code). Add the following dependency to your project: <dependency> <groupId>org.kie.server</groupId> <artifactId>kie-server-client</artifactId> <version>7.48.0.Final-redhat-00006</version> <scope>compile</scope> </dependency> Create a Java package in your src/main/java folder with the name org.kie.dmn.lab . In the package you\u2019ve just created, create a Java class called Main . Add a public static void main(String[] args) method to your main class. Before we implement our method, we first define a number of constants that we will need when implementing our method (note that the values of your constants can be different depending on your environment, model namespace, etc.): private static final String KIE_SERVER_URL = \"http://localhost:8080/kie-server/services/rest/server\"; private static final String CONTAINER_ID = \"call-centre-decisions\"; private static final String USERNAME = \"pamAdmin\"; private static final String PASSWORD = \"redhatpam1!\"; private static final String DMN_MODEL_NAMESPACE = \"https://kiegroup.org/dmn/_2E9DCCE2-8C2B-496E-AC37-103694E51940\"; private static final String DMN_MODEL_NAME = \"call-centre\"; KIE-Server client API classes can mostly be retrieved from the KieServicesFactory class. We first need to create a KieServicesConfiguration instance that will hold our credentials and defines how we want our client to communicate with the server: KieServicesConfiguration kieServicesConfig = KieServicesFactory.newRestConfiguration(KIE_SERVER_URL, new EnteredCredentialsProvider(USERNAME, PASSWORD)); kieServicesConfig.setMarshallingFormat(MarshallingFormat.JSON); Next, we create the KieServicesClient : KieServicesClient kieServicesClient = KieServicesFactory.newKieServicesClient(kieServicesConfig); From this client we retrieve our DMNServicesClient: DMNServicesClient dmnServicesClient = kieServicesClient.getServicesClient(DMNServicesClient.class); To pass the input values to our model to the Execution Server, we need to create a DMNContext : DMNContext dmnContext = dmnServicesClient.newContext(); We pass the input variables to the DMNContext . We define the following three methods that create the data inputs: private static Map<String, Object> getIncomingCall() { Map<String, Object> incomingCall = new HashMap<>(); Map<String, Object> phone = new HashMap<>(); phone.put(\"country prefix\", \"+420\"); phone.put(\"phone number\", \"1234\"); incomingCall.put(\"phone\", phone); incomingCall.put(\"purpose\", \"help\"); return incomingCall; } private static List<Map<String, Object>> getEmployees() { List<Map<String,Object>> employees = new ArrayList<>(); Map<String, Object> employee = new HashMap<>(); employee.put(\"name\", \"Duncan\"); employee.put(\"office location\", \"Rome\"); employees.add(employee); return employees; } private static Map<String, Object> getOffice() { Map<String, Object> office = new HashMap<>(); office.put(\"location\", \"Rome\"); return office; } We can now add the data to the DMNContext as follows: dmnContext.set(\"incoming call\", getIncomingCall()); dmnContext.set(\"employees\", getEmployees()); dmnContext.set(\"office\", getOffice()); We now have defined all the required instances needed to send a DMN evaluation request to the server. We explicitly specify which decision we want to evaluate, in this case the Accept Call decision, by using the evaluateDecisionByName of the DMNServiceClient . ServiceResponse<DMNResult> dmnResultResponse = dmnServicesClient.evaluateDecisionByName(CONTAINER_ID, DMN_MODEL_NAMESPACE, DMN_MODEL_NAME, \"Accept Call\", dmnContext); Finally we can retrieve the DMN evaluation result and print it in the console: DMNDecisionResult decisionResult = dmnResultResponse.getResult().getDecisionResultByName(\"Accept Call\"); System.out.println(\"Is the call accepted?: \" + decisionResult.getResult()); Compile your project and run it. Observe the output in the console, which should say: Is the call accepted?: true The complete project can be found here: https://github.com/kmacedovarela/dmn-workshop-labs/tree/master/call-centre-dmn-lab-client","title":"Call Centre - Consuming Decisions"},{"location":"guided_exercises/dmn/advanced-lab-deployment/#deploying-and-testing-the-decision-service","text":"With our decision model completed, we can now package our DMN model in a Deployment Unit (KJAR), deploy it on the Execution Server and test our decision.","title":"Deploying and testing the Decision Service"},{"location":"guided_exercises/dmn/advanced-lab-deployment/#deploying-the-decision-service","text":"To deploy your business application, follow these steps: In the bread-crumb navigation in the upper-left corner, click on call-centre-decisions to go back to the project\u2019s Library View. Click on the Deploy button in the upper-right corner of the screen. This will package our DMN mode in a Deployment Unit (KJAR) and deploy it onto the Execution Server (KIE-Server). Go to the Execution Servers perspective by clicking on \"Menu \u2192 Deploy \u2192 Execution Servers\". You will see the Deployment Unit deployed on the Execution Server.","title":"Deploying the decision service"},{"location":"guided_exercises/dmn/advanced-lab-deployment/#testing-dmn-solution","text":"In this section, you will test the DMN solution with Execution Server\u2019s Swagger interface and via Java KIE Client API.","title":"Testing DMN Solution"},{"location":"guided_exercises/dmn/advanced-lab-deployment/#testing-the-decision-service-via-the-rest-api","text":"The Swagger interface provides the description and documentation of the Execution Server\u2019s RESTful API. At the same time, it allows the APIs to be called from the UI. This enables developers and users to quickly test a, in this case, a deployed DMN Service . Navigate to KIE Server swagger docs Locate the DMN Models section. The DMN API provides the DMN model as a RESTful resources, which accepts 2 operations: GET : Retrieves the DMN model. POST : Evaluates the decisions for a given input. Expand the GET operation by clicking on it. Click on the Try it out button. Set the containerId field to call-centre-decision and set the Response content type to application/json and click on Execute If requested, provide the username and password of your Business Central and KIE-Server user. The response will be the model-description of your DMN model. Next, we will evaluate our model with some input data. We need to provide our model with the incoming call , list of employees and office location . Expand the POST operation and click on the Try it out button Set the containerId field to call-centre-decisions . Set the Parameter content type and Response content type fields to application/json . Pass the following request to evaluate whether the given call is accepted by the call-centre. IMPORTANT : We\u2019re explicitly specifying the decision-name of the decision we want to evaluate. If we would not specify this, the engine will evaluate the full model, and hence will also require us to pass the call input. When we only evaluate the Accept Call decision, we only need to specify the inputs of Accept Call . In the decision service invocation in the Accept Call logic, the input incoming call is passed to the call parameter of the decision service. { \"decision-name\" : \"Accept Call\", \"dmn-context\":{ \"incoming call\":{ \"phone\": { \"country prefix\": \"+420\", \"phone number\": \"1234\" }, \"purpose\": \"help\" }, \"employees\": [{ \"name\": \"Duncan\", \"office location\": \"Rome\" }], \"office\": { \"location\": \"Rome\" } } } Click on Execute . The result value of the Accept Call should be true . Test the service with a number of other values. For example, specify a banned phone number like: +421 92000001","title":"Testing the Decision Service via the REST API"},{"location":"guided_exercises/dmn/advanced-lab-deployment/#using-the-kie-server-client","text":"Red Hat Decision Manager provides a KIE-Server Client API that allows the user to interact with the KIE-Server from a Java client using a higher level API. It abstracts the data marshalling and unmarshalling and the creation and execution of the RESTful commands from the developer, allowing him/her to focus on developing business logic. In this section we will create a simple Java client for our DMN model. IMPORTANT: If your KIE Server is exposed via https you need to configure the `javax.net.ssl.trustStore and javax.net.ssl.trustStorePassword in the Java client code using the Remote Java API. If not, you may get a rest.NoEndpointFoundException`. For more information check this solution Red Hat's knowledge base. Create a new Maven Java JAR project in your favourite IDE (e.g. IntelliJ, Eclipse, Visual Studio Code). Add the following dependency to your project: <dependency> <groupId>org.kie.server</groupId> <artifactId>kie-server-client</artifactId> <version>7.48.0.Final-redhat-00006</version> <scope>compile</scope> </dependency> Create a Java package in your src/main/java folder with the name org.kie.dmn.lab . In the package you\u2019ve just created, create a Java class called Main . Add a public static void main(String[] args) method to your main class. Before we implement our method, we first define a number of constants that we will need when implementing our method (note that the values of your constants can be different depending on your environment, model namespace, etc.): private static final String KIE_SERVER_URL = \"http://localhost:8080/kie-server/services/rest/server\"; private static final String CONTAINER_ID = \"call-centre-decisions\"; private static final String USERNAME = \"pamAdmin\"; private static final String PASSWORD = \"redhatpam1!\"; private static final String DMN_MODEL_NAMESPACE = \"https://kiegroup.org/dmn/_2E9DCCE2-8C2B-496E-AC37-103694E51940\"; private static final String DMN_MODEL_NAME = \"call-centre\"; KIE-Server client API classes can mostly be retrieved from the KieServicesFactory class. We first need to create a KieServicesConfiguration instance that will hold our credentials and defines how we want our client to communicate with the server: KieServicesConfiguration kieServicesConfig = KieServicesFactory.newRestConfiguration(KIE_SERVER_URL, new EnteredCredentialsProvider(USERNAME, PASSWORD)); kieServicesConfig.setMarshallingFormat(MarshallingFormat.JSON); Next, we create the KieServicesClient : KieServicesClient kieServicesClient = KieServicesFactory.newKieServicesClient(kieServicesConfig); From this client we retrieve our DMNServicesClient: DMNServicesClient dmnServicesClient = kieServicesClient.getServicesClient(DMNServicesClient.class); To pass the input values to our model to the Execution Server, we need to create a DMNContext : DMNContext dmnContext = dmnServicesClient.newContext(); We pass the input variables to the DMNContext . We define the following three methods that create the data inputs: private static Map<String, Object> getIncomingCall() { Map<String, Object> incomingCall = new HashMap<>(); Map<String, Object> phone = new HashMap<>(); phone.put(\"country prefix\", \"+420\"); phone.put(\"phone number\", \"1234\"); incomingCall.put(\"phone\", phone); incomingCall.put(\"purpose\", \"help\"); return incomingCall; } private static List<Map<String, Object>> getEmployees() { List<Map<String,Object>> employees = new ArrayList<>(); Map<String, Object> employee = new HashMap<>(); employee.put(\"name\", \"Duncan\"); employee.put(\"office location\", \"Rome\"); employees.add(employee); return employees; } private static Map<String, Object> getOffice() { Map<String, Object> office = new HashMap<>(); office.put(\"location\", \"Rome\"); return office; } We can now add the data to the DMNContext as follows: dmnContext.set(\"incoming call\", getIncomingCall()); dmnContext.set(\"employees\", getEmployees()); dmnContext.set(\"office\", getOffice()); We now have defined all the required instances needed to send a DMN evaluation request to the server. We explicitly specify which decision we want to evaluate, in this case the Accept Call decision, by using the evaluateDecisionByName of the DMNServiceClient . ServiceResponse<DMNResult> dmnResultResponse = dmnServicesClient.evaluateDecisionByName(CONTAINER_ID, DMN_MODEL_NAMESPACE, DMN_MODEL_NAME, \"Accept Call\", dmnContext); Finally we can retrieve the DMN evaluation result and print it in the console: DMNDecisionResult decisionResult = dmnResultResponse.getResult().getDecisionResultByName(\"Accept Call\"); System.out.println(\"Is the call accepted?: \" + decisionResult.getResult()); Compile your project and run it. Observe the output in the console, which should say: Is the call accepted?: true The complete project can be found here: https://github.com/kmacedovarela/dmn-workshop-labs/tree/master/call-centre-dmn-lab-client","title":"Using the KIE-Server Client"},{"location":"guided_exercises/dmn/advanced-lab-intro/","text":"Call Centre - Intro and Use Case This is an advanced Decision Model & Notation lab that introduces DMN Decision Services, Relations, nested boxed expressions, etc. It also explores a number of different FEEL constructs and expressions like, for example, list contains . Goals Implement a DMN model using the Red Hat DM/PAM DMN editor Deploy the existing DMN project to Decision Server Problem Statement In this lab we will create a decision that determines if a call-centre can take an incoming call. Whether a call will be accepted by a certain office depends on: The office accepts the call. There are employees currently available at the office. Whether the office can accepts a call depends on: whether the phone number has been banned. the purpose of the phone call (\"help\" or \"objection\"). Create a Decision Project To define and deploy a DMN decision model, we first need to create a new project in which we can store the model. To create a new project: Navigate to Business Central Login to the platform with the provided username and password. Click on Design to navigate to the Design perspective. In the Design perspective, create a new project. If your space is empty, this can be done by clicking on the blue Add Project button in the center of the page. If you already have projects in your space, you can click on the blue Add Project icon at the top right of the page. Give the project the name call-centre-decisions , and the description \"Call Centre Decisions\". With the project created, we can now create our DMN model. Click on the blue Add Asset button. In the Add Asset page, select Decision in the dropdown filter selector. Click on the DMN tile to create a new DMN model. Give it the name call-centre . This will create the asset and open the DMN editor. Next Steps You can do this lab in 2 ways: If you already have (some) DMN knowledge, we would like to challenge you to build the solution by yourself. After you\u2019ve built solution, you can verify your answer by going to the next module in which we will explain the solution and will deploy it onto the runtime. Follow this step-by-step guide which will guide you through the implementation.","title":"Call Center - Introduction"},{"location":"guided_exercises/dmn/advanced-lab-intro/#call-centre-intro-and-use-case","text":"This is an advanced Decision Model & Notation lab that introduces DMN Decision Services, Relations, nested boxed expressions, etc. It also explores a number of different FEEL constructs and expressions like, for example, list contains .","title":"Call Centre - Intro and Use Case"},{"location":"guided_exercises/dmn/advanced-lab-intro/#goals","text":"Implement a DMN model using the Red Hat DM/PAM DMN editor Deploy the existing DMN project to Decision Server","title":"Goals"},{"location":"guided_exercises/dmn/advanced-lab-intro/#problem-statement","text":"In this lab we will create a decision that determines if a call-centre can take an incoming call. Whether a call will be accepted by a certain office depends on: The office accepts the call. There are employees currently available at the office. Whether the office can accepts a call depends on: whether the phone number has been banned. the purpose of the phone call (\"help\" or \"objection\").","title":"Problem Statement"},{"location":"guided_exercises/dmn/advanced-lab-intro/#create-a-decision-project","text":"To define and deploy a DMN decision model, we first need to create a new project in which we can store the model. To create a new project: Navigate to Business Central Login to the platform with the provided username and password. Click on Design to navigate to the Design perspective. In the Design perspective, create a new project. If your space is empty, this can be done by clicking on the blue Add Project button in the center of the page. If you already have projects in your space, you can click on the blue Add Project icon at the top right of the page. Give the project the name call-centre-decisions , and the description \"Call Centre Decisions\". With the project created, we can now create our DMN model. Click on the blue Add Asset button. In the Add Asset page, select Decision in the dropdown filter selector. Click on the DMN tile to create a new DMN model. Give it the name call-centre . This will create the asset and open the DMN editor.","title":"Create a Decision Project"},{"location":"guided_exercises/dmn/advanced-lab-intro/#next-steps","text":"You can do this lab in 2 ways: If you already have (some) DMN knowledge, we would like to challenge you to build the solution by yourself. After you\u2019ve built solution, you can verify your answer by going to the next module in which we will explain the solution and will deploy it onto the runtime. Follow this step-by-step guide which will guide you through the implementation.","title":"Next Steps"},{"location":"guided_exercises/dmn/getting-started/","text":"Getting Started with Decision Model and Notation This lab introduces you to the deployment of an existing Decision Model and Notation (DMN) and validation of it's decisions. Explore an existing DMN file created using Business Central Deploy the existing DMN project to Decision Server Test the deployed DMN Examine Existing DMN Diagram The following example describes an insurance price calculator based on an applicant\u2019s age and accident history. This is a simple decision process based on the following decision table: DMN Decision Table The decision table was designed without using Business Central tools, but could be imported seemlesly due to the conformity with DMN specification. The DMN decision table includes a hit policy , inputs, and outputs. Unlike the drl based decision tables that can be created in Business Central, input and output names in DMN decision tables accept spaces. The conditions for the Age input is defined using the Friendly Enough Expression Language (FEEL). The decision can also be represented by the following decision requirements diagram: In this decision requirements diagram, note that the applicant\u2019s age and accident history are the required inputs for the decision table \"Insurance Total Price\". The DMN component is currently stored in the DMN GitHub repository . Download DMN File In this section, you download the GitHub repository to an accessible directory in your file system. Navigate to the GitHub repository . From the GitHub web page, click Clone or download on the right and then select Download ZIP : Using your favorite file system navigation tool, locate the downloaded ZIP file and unzip it to a directory in your file system. From this point forward, this location is referred to as $PROJECT_HOME . Importing a DMN in Business Central Log in to Business Central. Create a project in Business Central called policy-price . In the empty project library view for the policy-price project, click Import Asset . In the Create new Uploaded file dialog, enter insurance-pricing.dmn in the Uploaded file field: Using the browse button at the far right of the field labeled Please select a file to upload , navigate with the file browser to the $PROJECT_HOME directory where the unzipped Git repository is located. Select the $PROJECT_HOME\\policy-price\\insurance-pricing.dmn file. Click Ok to import the DMN asset. The diagram will open and you will be able to see the DRD. Explore the diagram nodes to check the decision policies of this diagram. Close the diagram. You should now be on the library view for the policy-price project. You should see the insurance-pricing asset is added to your project assets: From the policy-price project\u2019s library view, click Build , then Deploy to deploy the project to the execution server. After receiving the build confirmation, navigate to the container deployment list by clicking the \" View deployment details \" link in the confirmation pop-up, or by selecting Menu \u2192 Deploy \u2192 Execution Servers . Verify that policy-price_2.0.0 shows a green status: Testing the Decision Service In this section, you test the DMN solution using the REST endpoints available in the Decision Server (a.k.a. KIE Server). Open your Decision Server (a.k.a KIE Server) on the url \"/docs\". You should see something like this: Next, under DMN Models , click on the POST /server/containers/{containerId}/dmn\" and select \"Try it out\": Now use the following data: Container ID: policy-price Body (dmn context): {\"dmn-context\": {\"Age\": 20, \"had previous incidents\": false}} Parameter content type: application/json Click on the execute button. You should see the server response 200 and the results of the decision. Try out the Decision with different values for the age and accident history, and compare the results with the decision table: Conclusion Congratulations, you've finished the getting started exercise. Next, you will have an intermediate level exercise that will guide you through the implementation, deployment and testing of the Vacation Days use case.","title":"Insurance Price - Getting Started"},{"location":"guided_exercises/dmn/getting-started/#getting-started-with-decision-model-and-notation","text":"This lab introduces you to the deployment of an existing Decision Model and Notation (DMN) and validation of it's decisions. Explore an existing DMN file created using Business Central Deploy the existing DMN project to Decision Server Test the deployed DMN","title":"Getting Started with Decision Model and Notation"},{"location":"guided_exercises/dmn/getting-started/#examine-existing-dmn-diagram","text":"The following example describes an insurance price calculator based on an applicant\u2019s age and accident history. This is a simple decision process based on the following decision table: DMN Decision Table The decision table was designed without using Business Central tools, but could be imported seemlesly due to the conformity with DMN specification. The DMN decision table includes a hit policy , inputs, and outputs. Unlike the drl based decision tables that can be created in Business Central, input and output names in DMN decision tables accept spaces. The conditions for the Age input is defined using the Friendly Enough Expression Language (FEEL). The decision can also be represented by the following decision requirements diagram: In this decision requirements diagram, note that the applicant\u2019s age and accident history are the required inputs for the decision table \"Insurance Total Price\". The DMN component is currently stored in the DMN GitHub repository .","title":"Examine Existing DMN Diagram"},{"location":"guided_exercises/dmn/getting-started/#download-dmn-file","text":"In this section, you download the GitHub repository to an accessible directory in your file system. Navigate to the GitHub repository . From the GitHub web page, click Clone or download on the right and then select Download ZIP : Using your favorite file system navigation tool, locate the downloaded ZIP file and unzip it to a directory in your file system. From this point forward, this location is referred to as $PROJECT_HOME .","title":"Download DMN File"},{"location":"guided_exercises/dmn/getting-started/#importing-a-dmn-in-business-central","text":"Log in to Business Central. Create a project in Business Central called policy-price . In the empty project library view for the policy-price project, click Import Asset . In the Create new Uploaded file dialog, enter insurance-pricing.dmn in the Uploaded file field: Using the browse button at the far right of the field labeled Please select a file to upload , navigate with the file browser to the $PROJECT_HOME directory where the unzipped Git repository is located. Select the $PROJECT_HOME\\policy-price\\insurance-pricing.dmn file. Click Ok to import the DMN asset. The diagram will open and you will be able to see the DRD. Explore the diagram nodes to check the decision policies of this diagram. Close the diagram. You should now be on the library view for the policy-price project. You should see the insurance-pricing asset is added to your project assets: From the policy-price project\u2019s library view, click Build , then Deploy to deploy the project to the execution server. After receiving the build confirmation, navigate to the container deployment list by clicking the \" View deployment details \" link in the confirmation pop-up, or by selecting Menu \u2192 Deploy \u2192 Execution Servers . Verify that policy-price_2.0.0 shows a green status:","title":"Importing a DMN in Business Central"},{"location":"guided_exercises/dmn/getting-started/#testing-the-decision-service","text":"In this section, you test the DMN solution using the REST endpoints available in the Decision Server (a.k.a. KIE Server). Open your Decision Server (a.k.a KIE Server) on the url \"/docs\". You should see something like this: Next, under DMN Models , click on the POST /server/containers/{containerId}/dmn\" and select \"Try it out\": Now use the following data: Container ID: policy-price Body (dmn context): {\"dmn-context\": {\"Age\": 20, \"had previous incidents\": false}} Parameter content type: application/json Click on the execute button. You should see the server response 200 and the results of the decision. Try out the Decision with different values for the age and accident history, and compare the results with the decision table:","title":"Testing the Decision Service"},{"location":"guided_exercises/dmn/getting-started/#conclusion","text":"Congratulations, you've finished the getting started exercise. Next, you will have an intermediate level exercise that will guide you through the implementation, deployment and testing of the Vacation Days use case.","title":"Conclusion"},{"location":"guided_exercises/dmn/intermediate-lab-authoring/","text":"Vacation Days - Authoring Decisions Let's work on the decision model. Input Nodes The problem statement describes a number of different inputs to our decision: Age of the employee Years of Service of the employee Therefore, we should create two input nodes, one for each input: Add an Input node to the diagram by clicking on the Input node icon and placing it in the DRD. Double-click on the node to set the name. We will name this node Age . With the Age node selected, open the property panel. Set the data type to number . In the same way, create an Input node for Years of Service . This node should also have its data type set to number . Save the model. Constants The problem statement describes that every employee receives at least 22 days. So, if no other decisions apply, an employee receives 22 days. This is can be seen as a constant input value into our decision model. In DMN we can model such constant inputs with a Decision node with a Literal boxed expression that defines the constant value: Add a Decision node to the DRD Give the node the name Base Vacation Days . Click on the node to select it and open the property panel. Set the node\u2019s data type to number . Click on the node and click on the Edit icon to open the expression editor. In the expression editor, click on the box that says Select expression and select Literal expression . Simply set the Literal Expression to 22 , the number of base vacation days defined in the problem statement. Save the model. Decisions The problem statement defines 3 decisions which can cause extra days to be given to employees based on various criteria. Let\u2019s simply call these decision: Extra days case 1 Extra days case 2 Extra days case 3 Although these decisions could be implemented in a single decision node, we\u2019ve decided, in order to improve maintainability of the solution, to define these decisions in 3 separate decision nodes. In your DRD, create 3 decision nodes with these given names. Set their data types to number . We need to attach both input nodes, Age and Years of Service to all 3 decision nodes. We can do this by clicking on an Input node, clicking on its arrow icon, and attaching the arrow to the Decision node. Select the Extra days case 1 node and open its expression editor by clicking on the Edit button. Select the expression Decision Table to create a boxed expression implemented as a decision table. The first case defines 2 decisions which can be modelled with 2 rows in our decision table as such: employees younger than 18 or at least 60 years will receive 5 extra days, or \u2026 employees with at least 30 years of service will receive 5 extra days To add new lines to your table, right click the first column and select \"Insert below\" Note that the hit-policy of the decision table is by default set to U , which means Unique . This implies that only one rule is expected to fire for a given input. In this case however, we would like to set it to Collect Max , as, for a given input, multiple decisions might match, but we would like to collect the output from the rule with the highest number of additional vacation days. To do this, click on the U in the upper-left corner of the decision table. Now, set the Hit Policy to Collect and the Builtin Aggregator to MAX . Finally, we need to set the default result of the decision. This is the result that will be returned when none of the rules match the given input. This is done as follows: .. Select the output/result column of the decision table. In this case this is the column Extra days case 1 .. Open the properties panel on the right-side of the editor. .. Expand the Default output section. .. Set the Default output property to 0 . Save the model The other two decisions can be implemented in the same way. Now, implement the following two decision tables: Case 2: Case 3: Total Vacation Days The total vacation days needs to be determined from the base vacation days and the decisions taken by our 3 decision nodes. As such, we need to create a new Decision node, which takes the output of our 4 Decision nodes (3 decision tables and a literal expression) as input and determines the final output. To do this, we need to: Create a new Decision node in the model. Give the node the name Total Vacation Days and set its data type to number . Connect the 4 existing Decision nodes to the node. This defines that the output of these nodes will be the input of the next node. Click on the Total Vacation Days node and click on Edit to open the expression editor. Configure the expression as a literal expression. We need to configure the following logic: Everyone gets the Base Vacation Days. If both case 1 and case 3 add extra days, only the extra days of one of this decision is added. So, in that case we take the maximum. If case 2 adds extra days, add them to the total. The above logic can be implemented with the following FEEL expression: Save the completed model. Next steps We're done. Next, we should deploy the project in KIE Server and test the model using the REST and Java API.","title":"Vacation Days - Authoring Decisions"},{"location":"guided_exercises/dmn/intermediate-lab-authoring/#vacation-days-authoring-decisions","text":"Let's work on the decision model.","title":"Vacation Days - Authoring Decisions"},{"location":"guided_exercises/dmn/intermediate-lab-authoring/#input-nodes","text":"The problem statement describes a number of different inputs to our decision: Age of the employee Years of Service of the employee Therefore, we should create two input nodes, one for each input: Add an Input node to the diagram by clicking on the Input node icon and placing it in the DRD. Double-click on the node to set the name. We will name this node Age . With the Age node selected, open the property panel. Set the data type to number . In the same way, create an Input node for Years of Service . This node should also have its data type set to number . Save the model.","title":"Input Nodes"},{"location":"guided_exercises/dmn/intermediate-lab-authoring/#constants","text":"The problem statement describes that every employee receives at least 22 days. So, if no other decisions apply, an employee receives 22 days. This is can be seen as a constant input value into our decision model. In DMN we can model such constant inputs with a Decision node with a Literal boxed expression that defines the constant value: Add a Decision node to the DRD Give the node the name Base Vacation Days . Click on the node to select it and open the property panel. Set the node\u2019s data type to number . Click on the node and click on the Edit icon to open the expression editor. In the expression editor, click on the box that says Select expression and select Literal expression . Simply set the Literal Expression to 22 , the number of base vacation days defined in the problem statement. Save the model.","title":"Constants"},{"location":"guided_exercises/dmn/intermediate-lab-authoring/#decisions","text":"The problem statement defines 3 decisions which can cause extra days to be given to employees based on various criteria. Let\u2019s simply call these decision: Extra days case 1 Extra days case 2 Extra days case 3 Although these decisions could be implemented in a single decision node, we\u2019ve decided, in order to improve maintainability of the solution, to define these decisions in 3 separate decision nodes. In your DRD, create 3 decision nodes with these given names. Set their data types to number . We need to attach both input nodes, Age and Years of Service to all 3 decision nodes. We can do this by clicking on an Input node, clicking on its arrow icon, and attaching the arrow to the Decision node. Select the Extra days case 1 node and open its expression editor by clicking on the Edit button. Select the expression Decision Table to create a boxed expression implemented as a decision table. The first case defines 2 decisions which can be modelled with 2 rows in our decision table as such: employees younger than 18 or at least 60 years will receive 5 extra days, or \u2026 employees with at least 30 years of service will receive 5 extra days To add new lines to your table, right click the first column and select \"Insert below\" Note that the hit-policy of the decision table is by default set to U , which means Unique . This implies that only one rule is expected to fire for a given input. In this case however, we would like to set it to Collect Max , as, for a given input, multiple decisions might match, but we would like to collect the output from the rule with the highest number of additional vacation days. To do this, click on the U in the upper-left corner of the decision table. Now, set the Hit Policy to Collect and the Builtin Aggregator to MAX . Finally, we need to set the default result of the decision. This is the result that will be returned when none of the rules match the given input. This is done as follows: .. Select the output/result column of the decision table. In this case this is the column Extra days case 1 .. Open the properties panel on the right-side of the editor. .. Expand the Default output section. .. Set the Default output property to 0 . Save the model The other two decisions can be implemented in the same way. Now, implement the following two decision tables: Case 2: Case 3:","title":"Decisions"},{"location":"guided_exercises/dmn/intermediate-lab-authoring/#total-vacation-days","text":"The total vacation days needs to be determined from the base vacation days and the decisions taken by our 3 decision nodes. As such, we need to create a new Decision node, which takes the output of our 4 Decision nodes (3 decision tables and a literal expression) as input and determines the final output. To do this, we need to: Create a new Decision node in the model. Give the node the name Total Vacation Days and set its data type to number . Connect the 4 existing Decision nodes to the node. This defines that the output of these nodes will be the input of the next node. Click on the Total Vacation Days node and click on Edit to open the expression editor. Configure the expression as a literal expression. We need to configure the following logic: Everyone gets the Base Vacation Days. If both case 1 and case 3 add extra days, only the extra days of one of this decision is added. So, in that case we take the maximum. If case 2 adds extra days, add them to the total. The above logic can be implemented with the following FEEL expression: Save the completed model.","title":"Total Vacation Days"},{"location":"guided_exercises/dmn/intermediate-lab-authoring/#next-steps","text":"We're done. Next, we should deploy the project in KIE Server and test the model using the REST and Java API.","title":"Next steps"},{"location":"guided_exercises/dmn/intermediate-lab-deployment/","text":"Vacation Days - Consuming Decisions The first thing we should do is deploy the project. We'll deploy it in KIE Server using Business Central. Deploying the Decision Service With our decision model completed, we can now package our DMN model in a Deployment Unit (KJAR) and deploy it on the Execution Server. To do this: In the bread-crumb navigation in the upper-left corner, click on vacation-days-decisions to go back to the project\u2019s Library View. Click on the Deploy button in the upper-right corner of the screen. This will package our DMN mode in a Deployment Unit (KJAR) and deploy it onto the Execution Server (KIE-Server). Go to the Execution Servers perspective by clicking on \"Menu \u2192 Deploy \u2192 Execution Servers\". You will see the Deployment Unit deployed on the Execution Server. Testing DMN Solution In this section, you will test the DMN solution with Execution Server\u2019s Swagger interface and via Java KIE Client API. Testing the solution via REST API In this section, you will test the DMN solution with KIE Server\u2019s Swagger interface. The Swagger interface provides the description and documentation of the Execution Server\u2019s RESTful API. At the same time, it allows the APIs to be called from the UI. This enables developers and users to quickly test, in this case, a deployed DMN Service. Navigate to KIE Server Locate the DMN Models section. The DMN API provides the DMN model as a RESTful resources, which accepts 2 operations: GET : Retrieves the DMN model. POST : Evaluates the decisions for a given input. Expand the GET operation by clicking on it. Click on the Try it out button. Set the containerId field to vacation-days-decisions and set the Response content type to application/json and click on Execute If requested, provide the username and password of your Business Central and KIE-Server user. The response will be the model-description of your DMN model. Next, we will evaluate our model with some input data. We need to provide our model with the age of an employee and the number of years of service . Let\u2019s try a number of different values to test our deicions. Expand the POST operation and click on the Try it out button Set the containerId field to vacation-days-decisions . Set the Parameter content type and Response content type fields to application/json . Pass the following request to lookup the number of vacation days for an employee of 16 years old with 1 year of service (note that the namespace of your model is probably different as it is generated. You can lookup the namespace of your model in the response/result of the GET operation you executed ealier, which returned the model description). { \"dmn-context\":{ \"Age\":16, \"Years of Service\":1 } } Click on Execute . The result value of the Total Vacation Days should be 27. Test the service with a number of other values. See the following table for some sample values and expected output. Age Years of Service Total Vacation Days 16 1 27 25 5 22 44 20 24 44 30 30 50 20 24 50 30 30 60 20 30 Using the KIE Java Client Red Hat Decision Manager provides a KIE Java Client API that allows the user to interact with the KIE-Server from a Java client using a higher level API. It abstracts the data marshalling and unmarshalling and the creation and execution of the RESTful commands from the developer, allowing him/her to focus on developing business logic. In this section we will create a simple Java client for our DMN model. IMPORTANT: If your KIE Server is exposed via https you need to configure the `javax.net.ssl.trustStore and javax.net.ssl.trustStorePassword in the Java client code using the Remote Java API. If not, you may get a rest.NoEndpointFoundException`. For more information check this solution Red Hat's knowledge base. Create a new Maven Java JAR project in your favourite IDE (e.g. IntelliJ, Eclipse, Visual Studio Code). Add the following dependency to your project: <dependency> <groupId>org.kie.server</groupId> <artifactId>kie-server-client</artifactId> <version>7.48.0.Final-redhat-00006</version> <scope>compile</scope> </dependency> Create a Java package in your src/main/java folder with the name org.kie.dmn.lab . In the package you\u2019ve just created, create a Java class called Main.java . Add a public static void main(String[] args) method to your main class. Before we implement our method, we first define a number of constants that we will need when implementing our method (note that the values of your constants can be different depending on your environment, model namespace, etc.): private static final String KIE_SERVER_URL = \"http://localhost:8080/kie-server/services/rest/server\"; private static final String CONTAINER_ID = \"vacation-days-decisions\"; private static final String USERNAME = \"pamAdmin\"; private static final String PASSWORD = \"redhatpam1!\"; KIE-Server client API classes can mostly be retrieved from the KieServicesFactory class. We first need to create a KieServicesConfiguration instance that will hold our credentials and defines how we want our client to communicate with the server: KieServicesConfiguration kieServicesConfig = KieServicesFactory.newRestConfiguration(KIE_SERVER_URL, new EnteredCredentialsProvider(USERNAME, PASSWORD)); Next, we create the KieServicesClient : KieServicesClient kieServicesClient = KieServicesFactory.newKieServicesClient(kieServicesConfig); From this client we retrieve our DMNServicesClient: DMNServicesClient dmnServicesClient = kieServicesClient.getServicesClient(DMNServicesClient.class); To pass the input values to our model to the Execution Server, we need to create a DMNContext : DMNContext dmnContext = dmnServicesClient.newContext(); dmnContext.set(\"Age\", 16); dmnContext.set(\"Years of Service\", 1); We now have defined all the required instances needed to send a DMN evaluation request to the server: ServiceResponse<DMNResult> dmnResultResponse = dmnServicesClient.evaluateAll(CONTAINER_ID, dmnContext); Finally we can retrieve the DMN evaluation result and print it in the console: DMNDecisionResult decisionResult = dmnResultResponse.getResult().getDecisionResultByName(\"Total Vacation Days\"); System.out.println(\"Total vacation days: \" + decisionResult.getResult()); Compile your project and run it. Observe the output in the console, which should say: Total vacation days: 27 The complete project can be found here: https://github.com/kmacedovarela/dmn-workshop-labs/tree/master/vacation-days-dmn-lab-client","title":"Vacation Days - Consuming Decisions"},{"location":"guided_exercises/dmn/intermediate-lab-deployment/#vacation-days-consuming-decisions","text":"The first thing we should do is deploy the project. We'll deploy it in KIE Server using Business Central.","title":"Vacation Days - Consuming Decisions"},{"location":"guided_exercises/dmn/intermediate-lab-deployment/#deploying-the-decision-service","text":"With our decision model completed, we can now package our DMN model in a Deployment Unit (KJAR) and deploy it on the Execution Server. To do this: In the bread-crumb navigation in the upper-left corner, click on vacation-days-decisions to go back to the project\u2019s Library View. Click on the Deploy button in the upper-right corner of the screen. This will package our DMN mode in a Deployment Unit (KJAR) and deploy it onto the Execution Server (KIE-Server). Go to the Execution Servers perspective by clicking on \"Menu \u2192 Deploy \u2192 Execution Servers\". You will see the Deployment Unit deployed on the Execution Server.","title":"Deploying the Decision Service"},{"location":"guided_exercises/dmn/intermediate-lab-deployment/#testing-dmn-solution","text":"In this section, you will test the DMN solution with Execution Server\u2019s Swagger interface and via Java KIE Client API.","title":"Testing DMN Solution"},{"location":"guided_exercises/dmn/intermediate-lab-deployment/#testing-the-solution-via-rest-api","text":"In this section, you will test the DMN solution with KIE Server\u2019s Swagger interface. The Swagger interface provides the description and documentation of the Execution Server\u2019s RESTful API. At the same time, it allows the APIs to be called from the UI. This enables developers and users to quickly test, in this case, a deployed DMN Service. Navigate to KIE Server Locate the DMN Models section. The DMN API provides the DMN model as a RESTful resources, which accepts 2 operations: GET : Retrieves the DMN model. POST : Evaluates the decisions for a given input. Expand the GET operation by clicking on it. Click on the Try it out button. Set the containerId field to vacation-days-decisions and set the Response content type to application/json and click on Execute If requested, provide the username and password of your Business Central and KIE-Server user. The response will be the model-description of your DMN model. Next, we will evaluate our model with some input data. We need to provide our model with the age of an employee and the number of years of service . Let\u2019s try a number of different values to test our deicions. Expand the POST operation and click on the Try it out button Set the containerId field to vacation-days-decisions . Set the Parameter content type and Response content type fields to application/json . Pass the following request to lookup the number of vacation days for an employee of 16 years old with 1 year of service (note that the namespace of your model is probably different as it is generated. You can lookup the namespace of your model in the response/result of the GET operation you executed ealier, which returned the model description). { \"dmn-context\":{ \"Age\":16, \"Years of Service\":1 } } Click on Execute . The result value of the Total Vacation Days should be 27. Test the service with a number of other values. See the following table for some sample values and expected output. Age Years of Service Total Vacation Days 16 1 27 25 5 22 44 20 24 44 30 30 50 20 24 50 30 30 60 20 30","title":"Testing the solution via REST API"},{"location":"guided_exercises/dmn/intermediate-lab-deployment/#using-the-kie-java-client","text":"Red Hat Decision Manager provides a KIE Java Client API that allows the user to interact with the KIE-Server from a Java client using a higher level API. It abstracts the data marshalling and unmarshalling and the creation and execution of the RESTful commands from the developer, allowing him/her to focus on developing business logic. In this section we will create a simple Java client for our DMN model. IMPORTANT: If your KIE Server is exposed via https you need to configure the `javax.net.ssl.trustStore and javax.net.ssl.trustStorePassword in the Java client code using the Remote Java API. If not, you may get a rest.NoEndpointFoundException`. For more information check this solution Red Hat's knowledge base. Create a new Maven Java JAR project in your favourite IDE (e.g. IntelliJ, Eclipse, Visual Studio Code). Add the following dependency to your project: <dependency> <groupId>org.kie.server</groupId> <artifactId>kie-server-client</artifactId> <version>7.48.0.Final-redhat-00006</version> <scope>compile</scope> </dependency> Create a Java package in your src/main/java folder with the name org.kie.dmn.lab . In the package you\u2019ve just created, create a Java class called Main.java . Add a public static void main(String[] args) method to your main class. Before we implement our method, we first define a number of constants that we will need when implementing our method (note that the values of your constants can be different depending on your environment, model namespace, etc.): private static final String KIE_SERVER_URL = \"http://localhost:8080/kie-server/services/rest/server\"; private static final String CONTAINER_ID = \"vacation-days-decisions\"; private static final String USERNAME = \"pamAdmin\"; private static final String PASSWORD = \"redhatpam1!\"; KIE-Server client API classes can mostly be retrieved from the KieServicesFactory class. We first need to create a KieServicesConfiguration instance that will hold our credentials and defines how we want our client to communicate with the server: KieServicesConfiguration kieServicesConfig = KieServicesFactory.newRestConfiguration(KIE_SERVER_URL, new EnteredCredentialsProvider(USERNAME, PASSWORD)); Next, we create the KieServicesClient : KieServicesClient kieServicesClient = KieServicesFactory.newKieServicesClient(kieServicesConfig); From this client we retrieve our DMNServicesClient: DMNServicesClient dmnServicesClient = kieServicesClient.getServicesClient(DMNServicesClient.class); To pass the input values to our model to the Execution Server, we need to create a DMNContext : DMNContext dmnContext = dmnServicesClient.newContext(); dmnContext.set(\"Age\", 16); dmnContext.set(\"Years of Service\", 1); We now have defined all the required instances needed to send a DMN evaluation request to the server: ServiceResponse<DMNResult> dmnResultResponse = dmnServicesClient.evaluateAll(CONTAINER_ID, dmnContext); Finally we can retrieve the DMN evaluation result and print it in the console: DMNDecisionResult decisionResult = dmnResultResponse.getResult().getDecisionResultByName(\"Total Vacation Days\"); System.out.println(\"Total vacation days: \" + decisionResult.getResult()); Compile your project and run it. Observe the output in the console, which should say: Total vacation days: 27 The complete project can be found here: https://github.com/kmacedovarela/dmn-workshop-labs/tree/master/vacation-days-dmn-lab-client","title":"Using the KIE Java Client"},{"location":"guided_exercises/dmn/intermediate-lab-intro/","text":"Vacation Days - Use case and project creation In this lab you'll try out the combination of DMN decision tables with literal expressions. You will also explore a number of different FEEL constructs and expressions like, for example, ranges. Finally, you'll learn how to use the KIE Java Client to consume decisions. Goal Implement a DMN model using the Red Hat DM/PAM DMN editor Deploy the existing DMN project to Decision Server Consume the DMN project using the REST API Consume the DMN project using a Java API Problem Statement In this lab we will create a decision that determines the number of vacation days assigned to an employee. The number of vacation days depends on age and years of service. Every employee receives at least 22 days. Additional days are provided according to the following criteria: Only employees younger than 18 or at least 60 years, or employees with at least 30 years of service will receive 5 extra days; Employees with at least 30 years of service and also employees of age 60 or more, receive 3 extra days, on top of possible additional days already given; If an employee has at least 15 but less than 30 years of service, 2 extra days are given. These 2 days are also provided for employees of age 45 or more. These 2 extra days can not be combined with the 5 extra days. Create a Decision Project To define and deploy a DMN decision model, we first need to create a new project in which we can store the model. To create a new project: Navigate to Business Central Login to the platform with the provided username and password. Click on Design to navigate to the Design perspective. 4. In the Design perspective, create a new project. If your space is empty, this can be done by clicking on the blue Add Project button in the center of the page. If you already have projects in your space, you can click on the blue Add Project icon at the top right of the page. Give the project the name vacation-days-decisions , and the description \"Vacation Days Decisions\". With the project created, we can now create our DMN model. Click on the blue Add Asset button. In the Add Asset page, select Decision in the dropdown filter selector. Click on the DMN tile to create a new DMN model. Give it the name vacation-days . This will create the asset and open the DMN editor. Next Steps You can do this lab in 2 ways: If you already have (some) DMN knowledge, we would like to challenge you to build the solution by yourself. After you\u2019ve built solution, you can verify your answer by going to the next module in which we will explain the solution and will deploy it onto the runtime. Follow the next step with contains a step-by-step guide and will guide you through the implementation.","title":"Vacation Days - Introduction"},{"location":"guided_exercises/dmn/intermediate-lab-intro/#vacation-days-use-case-and-project-creation","text":"In this lab you'll try out the combination of DMN decision tables with literal expressions. You will also explore a number of different FEEL constructs and expressions like, for example, ranges. Finally, you'll learn how to use the KIE Java Client to consume decisions.","title":"Vacation Days - Use case and project creation"},{"location":"guided_exercises/dmn/intermediate-lab-intro/#goal","text":"Implement a DMN model using the Red Hat DM/PAM DMN editor Deploy the existing DMN project to Decision Server Consume the DMN project using the REST API Consume the DMN project using a Java API","title":"Goal"},{"location":"guided_exercises/dmn/intermediate-lab-intro/#problem-statement","text":"In this lab we will create a decision that determines the number of vacation days assigned to an employee. The number of vacation days depends on age and years of service. Every employee receives at least 22 days. Additional days are provided according to the following criteria: Only employees younger than 18 or at least 60 years, or employees with at least 30 years of service will receive 5 extra days; Employees with at least 30 years of service and also employees of age 60 or more, receive 3 extra days, on top of possible additional days already given; If an employee has at least 15 but less than 30 years of service, 2 extra days are given. These 2 days are also provided for employees of age 45 or more. These 2 extra days can not be combined with the 5 extra days.","title":"Problem Statement"},{"location":"guided_exercises/dmn/intermediate-lab-intro/#create-a-decision-project","text":"To define and deploy a DMN decision model, we first need to create a new project in which we can store the model. To create a new project: Navigate to Business Central Login to the platform with the provided username and password. Click on Design to navigate to the Design perspective. 4. In the Design perspective, create a new project. If your space is empty, this can be done by clicking on the blue Add Project button in the center of the page. If you already have projects in your space, you can click on the blue Add Project icon at the top right of the page. Give the project the name vacation-days-decisions , and the description \"Vacation Days Decisions\". With the project created, we can now create our DMN model. Click on the blue Add Asset button. In the Add Asset page, select Decision in the dropdown filter selector. Click on the DMN tile to create a new DMN model. Give it the name vacation-days . This will create the asset and open the DMN editor.","title":"Create a Decision Project"},{"location":"guided_exercises/dmn/intermediate-lab-intro/#next-steps","text":"You can do this lab in 2 ways: If you already have (some) DMN knowledge, we would like to challenge you to build the solution by yourself. After you\u2019ve built solution, you can verify your answer by going to the next module in which we will explain the solution and will deploy it onto the runtime. Follow the next step with contains a step-by-step guide and will guide you through the implementation.","title":"Next Steps"},{"location":"guided_exercises/dmn/introduction/","text":"Introduction This is a series of guided exercises that will allow you to experiment the authoring of decisions using Decision Model and Notation - DMN. You will be able to experiment decision authoring in Business Central, along with the deployment and consumption of the decisions in the engine, KIE Server. What is DMN Take a look at the explanation of the DMN standard in the OMG website: \"DMN is a modeling language and notation for the precise specification of business decisions and business rules. DMN is easily readable by the different types of people involved in decision management. These include: business people who specify the rules and monitor their application; business analysts. DMN is designed to work alongside BPMN and/or CMMN, providing a mechanism to model the decision-making associated with processes and cases. While BPMN, CMMN and DMN can be used independently, they were carefully designed to be complementary. Indeed, many organizations require a combination of process models for their prescriptive workflows, case models for their reactive activities, and decision models for their more complex, multi-criteria business rules. Those organizations will benefit from using the three standards in combination, selecting which one is most appropriate to each type of activity modeling. This is why BPMN, CMMN and DMN really constitute the \u201ctriple crown\u201d of process improvement standards.\" Red Hat Process Automation Manager and Red Hat Decision Manager bring a set of graphical tooling that allow you to author decisions using DMN and a lightweight engine that can execute these decisions. The engine and the authoring tooling set are decoupled and you can scale it independently. Tooling Set In Red Hat PAM and DM you can author decisions using: Business Central (in RHPAM) or Decision Central (in RHDM) A more business friendly UI; Business Automation VSCode Extension A developer IDE ( Visual Studio Code ) extension that allows the visualization and editing of BPMN, DMN and Test Scenarios inside VSCode. There is also a set of community tooling that's also available for use. All the tools below are backed by Red Hat: Learn DMN in 15 minutes A guided tour in a website through the elements of DMN GitHub Chrome Extension A browser extension that allows you to visualize and edit BPMN, DMN and Test Scenario files directly in GitHub. Online Editors BPMN.new - A free online editor for business processes; DMN.new - A free online editor for decision models; PMML.new - A free online editor for scorecards; Business Modeler Hub Allows for the download of the: VSCode extension, GitHub Chrome Extension, and Desktop App The DMN Editor The DMN Editor consists of a number of components: Decision Navigator : shows the nodes used in the Decision Requirements Diagram (DRD, the diagram), and the decisions behind the nodes. Allows for quick navigation through the model. Decision Requirements Diagram Editor : the canvas in which the model can be created. Palette : Contains all the DMN constructs that can be used in a DRD, e.g. Input Node, Decision Node, etc. Expression Editor : Editor in which DMN boxed expressions, like decision tables and literal expressions, can be created. Property Panel : provides access to the properties of the model (name, namespace, etc), nodes, etc. Data Types : allows the user to define (complex) datatypes. Guided Labs These are the labs you have available in this workshop: Insurance Price calculation: a getting started exercise. You will import an existing module, explore it, deploy it and test it using the decision engine's REST API. Vacation Days: an intermediate level exercise. You will author a model from scratch, use decision tables, work with different hit policies, different FEEL constructs and expressions. Finally, you will deploy it and test it using not only the decision engine's REST API but also the Java KIE Client API. Call Centre: an advanced level exercise. You will author a model from scratch, create data types, consume DMN decision services from within decision nodes, and more FEEL constructs and expressions. Finally, you will deploy it and test it using not only the decision engine's REST API but also the Java KIE Client API. These are independent guided exercises and you don't need to implement the previous use case to implement the next one.","title":"Introduction"},{"location":"guided_exercises/dmn/introduction/#introduction","text":"This is a series of guided exercises that will allow you to experiment the authoring of decisions using Decision Model and Notation - DMN. You will be able to experiment decision authoring in Business Central, along with the deployment and consumption of the decisions in the engine, KIE Server.","title":"Introduction"},{"location":"guided_exercises/dmn/introduction/#what-is-dmn","text":"Take a look at the explanation of the DMN standard in the OMG website: \"DMN is a modeling language and notation for the precise specification of business decisions and business rules. DMN is easily readable by the different types of people involved in decision management. These include: business people who specify the rules and monitor their application; business analysts. DMN is designed to work alongside BPMN and/or CMMN, providing a mechanism to model the decision-making associated with processes and cases. While BPMN, CMMN and DMN can be used independently, they were carefully designed to be complementary. Indeed, many organizations require a combination of process models for their prescriptive workflows, case models for their reactive activities, and decision models for their more complex, multi-criteria business rules. Those organizations will benefit from using the three standards in combination, selecting which one is most appropriate to each type of activity modeling. This is why BPMN, CMMN and DMN really constitute the \u201ctriple crown\u201d of process improvement standards.\" Red Hat Process Automation Manager and Red Hat Decision Manager bring a set of graphical tooling that allow you to author decisions using DMN and a lightweight engine that can execute these decisions. The engine and the authoring tooling set are decoupled and you can scale it independently.","title":"What is DMN"},{"location":"guided_exercises/dmn/introduction/#tooling-set","text":"In Red Hat PAM and DM you can author decisions using: Business Central (in RHPAM) or Decision Central (in RHDM) A more business friendly UI; Business Automation VSCode Extension A developer IDE ( Visual Studio Code ) extension that allows the visualization and editing of BPMN, DMN and Test Scenarios inside VSCode. There is also a set of community tooling that's also available for use. All the tools below are backed by Red Hat: Learn DMN in 15 minutes A guided tour in a website through the elements of DMN GitHub Chrome Extension A browser extension that allows you to visualize and edit BPMN, DMN and Test Scenario files directly in GitHub. Online Editors BPMN.new - A free online editor for business processes; DMN.new - A free online editor for decision models; PMML.new - A free online editor for scorecards; Business Modeler Hub Allows for the download of the: VSCode extension, GitHub Chrome Extension, and Desktop App","title":"Tooling Set"},{"location":"guided_exercises/dmn/introduction/#the-dmn-editor","text":"The DMN Editor consists of a number of components: Decision Navigator : shows the nodes used in the Decision Requirements Diagram (DRD, the diagram), and the decisions behind the nodes. Allows for quick navigation through the model. Decision Requirements Diagram Editor : the canvas in which the model can be created. Palette : Contains all the DMN constructs that can be used in a DRD, e.g. Input Node, Decision Node, etc. Expression Editor : Editor in which DMN boxed expressions, like decision tables and literal expressions, can be created. Property Panel : provides access to the properties of the model (name, namespace, etc), nodes, etc. Data Types : allows the user to define (complex) datatypes.","title":"The DMN Editor"},{"location":"guided_exercises/dmn/introduction/#guided-labs","text":"These are the labs you have available in this workshop: Insurance Price calculation: a getting started exercise. You will import an existing module, explore it, deploy it and test it using the decision engine's REST API. Vacation Days: an intermediate level exercise. You will author a model from scratch, use decision tables, work with different hit policies, different FEEL constructs and expressions. Finally, you will deploy it and test it using not only the decision engine's REST API but also the Java KIE Client API. Call Centre: an advanced level exercise. You will author a model from scratch, create data types, consume DMN decision services from within decision nodes, and more FEEL constructs and expressions. Finally, you will deploy it and test it using not only the decision engine's REST API but also the Java KIE Client API. These are independent guided exercises and you don't need to implement the previous use case to implement the next one.","title":"Guided Labs"},{"location":"guided_exercises/operator/configmaps-deleteapp/","text":"ConfigMaps The Operator stores its configuration in a number of ConfigurationMaps . These ConfigurationMaps can be used to change more advanced configurations that can not be configured in the KieApp YAML. In the case the Operator upgrades the version of your RHPAM environment, the Operator is aware that one of the ConfigMaps has changed and will make a backup of it during the upgrade. In the OpenShift Console, open Workloads \u2192 Config Maps . Note that the Operator keeps the current ConfigMaps, and the ones of the last 2 versions. Click on the kieconfigs-7.10.1 ConfigMap and open the YAML tab. Explore the configuration options. Set the initialDelaySeconds of the livenessProbe of the Business Central console from 180 to 240. Click the Save button to save the configuration. Go to \"Workloads \u2192 Deployment Configs\", open the rhpam-trial-rhpamcentr Deployment Config and open the YAML tab. Find the LivenessProbe initialDelaySeconds configuration and notice that it\u2019s still set to 180. Delete the DeploymentConfig. This will have the Operator reconciliation recreate the DC. Open the YAML configuation of this recreated DeploymentConfig. Find the LivenessProbe initialDelaySeconds configuration and note that this time it has been set to 240, the value set in the ConfigMap. Deleting an application Apart from provisioning an RHPAM application, the Operator also allows us to easily delete an application. Navigate to Operators \u2192 Installed Operators \u2192 Business Automation \u2192 KieApp . Click on the kebab icon of the rhpam-trial KieApp and click Delete . Navigate back to Workloads \u2192 Deployment Configs and note that the RHPAM Deployment Configs have been removed.","title":"ConfigMaps and Deleteting Projects"},{"location":"guided_exercises/operator/configmaps-deleteapp/#configmaps","text":"The Operator stores its configuration in a number of ConfigurationMaps . These ConfigurationMaps can be used to change more advanced configurations that can not be configured in the KieApp YAML. In the case the Operator upgrades the version of your RHPAM environment, the Operator is aware that one of the ConfigMaps has changed and will make a backup of it during the upgrade. In the OpenShift Console, open Workloads \u2192 Config Maps . Note that the Operator keeps the current ConfigMaps, and the ones of the last 2 versions. Click on the kieconfigs-7.10.1 ConfigMap and open the YAML tab. Explore the configuration options. Set the initialDelaySeconds of the livenessProbe of the Business Central console from 180 to 240. Click the Save button to save the configuration. Go to \"Workloads \u2192 Deployment Configs\", open the rhpam-trial-rhpamcentr Deployment Config and open the YAML tab. Find the LivenessProbe initialDelaySeconds configuration and notice that it\u2019s still set to 180. Delete the DeploymentConfig. This will have the Operator reconciliation recreate the DC. Open the YAML configuation of this recreated DeploymentConfig. Find the LivenessProbe initialDelaySeconds configuration and note that this time it has been set to 240, the value set in the ConfigMap.","title":"ConfigMaps"},{"location":"guided_exercises/operator/configmaps-deleteapp/#deleting-an-application","text":"Apart from provisioning an RHPAM application, the Operator also allows us to easily delete an application. Navigate to Operators \u2192 Installed Operators \u2192 Business Automation \u2192 KieApp . Click on the kebab icon of the rhpam-trial KieApp and click Delete . Navigate back to Workloads \u2192 Deployment Configs and note that the RHPAM Deployment Configs have been removed.","title":"Deleting an application"},{"location":"guided_exercises/operator/configuration/","text":"KIE App Configuration The definition of the expected state of KIE-App environment is defined in the YAML definition the KIE-App. In this section we will slightly change this configuration to see how the Operator applies changes in the configuration of your Red Hat Process Automation Manager environment. Changing Credentials Go back to the YAML definition of your rhpam-trial KieApp. Add a commonConfig section, with the adminUser to the value pamAdmin , and the adminPassword to redhatpam1! . Click on the Save button. spec: commonConfig: adminPassword: pamAdmin adminUser: redhatpam1 Click the Reload button to reload the YAML view. Click on the Overview tab. Notice the deployments re-deploying. Click on the Business/Central Central URL to open the Business Central console. Log in with the new username and password: pamAdmin / redhatpam1! . Adding a KIE-Server Apart from changing some configuration parameters, we can also change the topology our deployment in the KieApp YAML file. Go back to the YAML definition of your rhpam-trial KieApp. Add a servers section and set the replicas parameter of the rhpam-trial-kieserver to 2 . objects: servers: - deployments: 1 name: rhpam-trial-kieserver replicas: 2 Click the Save button. Go to Workloads \u2192 Deployment Configs . Note that there are now 2 KIE-Server Deployment Configs. Go back to the YAML definition of your rhpam-trial KieApp. Navigate to the servers section and add the property deployments with the value 2 . objects: servers: - deployments: 2 name: rhpam-trial-kieserver replicas: 2 Click the Save button.","title":"Kie App Configuration"},{"location":"guided_exercises/operator/configuration/#kie-app-configuration","text":"The definition of the expected state of KIE-App environment is defined in the YAML definition the KIE-App. In this section we will slightly change this configuration to see how the Operator applies changes in the configuration of your Red Hat Process Automation Manager environment.","title":"KIE App Configuration"},{"location":"guided_exercises/operator/configuration/#changing-credentials","text":"Go back to the YAML definition of your rhpam-trial KieApp. Add a commonConfig section, with the adminUser to the value pamAdmin , and the adminPassword to redhatpam1! . Click on the Save button. spec: commonConfig: adminPassword: pamAdmin adminUser: redhatpam1 Click the Reload button to reload the YAML view. Click on the Overview tab. Notice the deployments re-deploying. Click on the Business/Central Central URL to open the Business Central console. Log in with the new username and password: pamAdmin / redhatpam1! .","title":"Changing Credentials"},{"location":"guided_exercises/operator/configuration/#adding-a-kie-server","text":"Apart from changing some configuration parameters, we can also change the topology our deployment in the KieApp YAML file. Go back to the YAML definition of your rhpam-trial KieApp. Add a servers section and set the replicas parameter of the rhpam-trial-kieserver to 2 . objects: servers: - deployments: 1 name: rhpam-trial-kieserver replicas: 2 Click the Save button. Go to Workloads \u2192 Deployment Configs . Note that there are now 2 KIE-Server Deployment Configs. Go back to the YAML definition of your rhpam-trial KieApp. Navigate to the servers section and add the property deployments with the value 2 . objects: servers: - deployments: 2 name: rhpam-trial-kieserver replicas: 2 Click the Save button.","title":"Adding a KIE-Server"},{"location":"guided_exercises/operator/installer/","text":"Operator Wizard Installer The Business Automation Operator contains an Operator Installer Console . This console gives you a wizard experience to deploy Red Hat Process Automation Manager environments. Go the Business Automation Operator and click in Installer link. Login with Openshift. A page will show up asking for authorization. Select all options and click on \"Allow selected permissions\". Give the application the name my-rhpam-prod . Select the rhpam-production for the Enviroment. Check the Enable Upgrades checkbox. Scroll down and set the Username and Password to pamAdmin : redhatpam1 . Click the Next button. Don\u2019t change any values in the Security section. Click on Next . Go through the Components section of the installer and observe the possible options. Don\u2019t change any values for now. Keep clicking next until you reach the Confirmation screen and click Deploy . Go back to the OpenShift Console. Navigate to Workloads \u2192 Deployment Configs and observe that a new Red Hat Process Automation Manager production environment has been deployed. Note that this environment has a PostgreSQL database deployed. Also note that both the Business Central and KIE-Server Deployment Configs have their ReplicationController set to 3 pods. Go back to the Operators \u2192 Installed Operators \u2192 Business Automation \u2192 KieApp . Delete the my-rhpam-prod we\u2019ve just deployed with the Installer. We will now deploy a new production environment using the installer, but this time we will configure our KIE-Server in the wizard and set the replications of the KIE-Server to 2 instead of 3. Go back to the Business Automation Operator, and open the Wizard. Create a new RHPAM Production Environment. Continue until you reach the KIE Servers screen. Click Add new KIE Server and use the following configuration for your KIE-Server. Click through the rest of the screens until you can press the Deploy button to deploy the environment. Navigate to the Workloads \u2192 Deployment Configs screen to see your RHPAM production environment, including the KIE-Server you configured. Conclusion This concludes the lab on the Business Automation Operator. If you have time left, feel free to explore more features of the operator.","title":"Operator Wizard"},{"location":"guided_exercises/operator/installer/#operator-wizard-installer","text":"The Business Automation Operator contains an Operator Installer Console . This console gives you a wizard experience to deploy Red Hat Process Automation Manager environments. Go the Business Automation Operator and click in Installer link. Login with Openshift. A page will show up asking for authorization. Select all options and click on \"Allow selected permissions\". Give the application the name my-rhpam-prod . Select the rhpam-production for the Enviroment. Check the Enable Upgrades checkbox. Scroll down and set the Username and Password to pamAdmin : redhatpam1 . Click the Next button. Don\u2019t change any values in the Security section. Click on Next . Go through the Components section of the installer and observe the possible options. Don\u2019t change any values for now. Keep clicking next until you reach the Confirmation screen and click Deploy . Go back to the OpenShift Console. Navigate to Workloads \u2192 Deployment Configs and observe that a new Red Hat Process Automation Manager production environment has been deployed. Note that this environment has a PostgreSQL database deployed. Also note that both the Business Central and KIE-Server Deployment Configs have their ReplicationController set to 3 pods. Go back to the Operators \u2192 Installed Operators \u2192 Business Automation \u2192 KieApp . Delete the my-rhpam-prod we\u2019ve just deployed with the Installer. We will now deploy a new production environment using the installer, but this time we will configure our KIE-Server in the wizard and set the replications of the KIE-Server to 2 instead of 3. Go back to the Business Automation Operator, and open the Wizard. Create a new RHPAM Production Environment. Continue until you reach the KIE Servers screen. Click Add new KIE Server and use the following configuration for your KIE-Server. Click through the rest of the screens until you can press the Deploy button to deploy the environment. Navigate to the Workloads \u2192 Deployment Configs screen to see your RHPAM production environment, including the KIE-Server you configured.","title":"Operator Wizard Installer"},{"location":"guided_exercises/operator/installer/#conclusion","text":"This concludes the lab on the Business Automation Operator. If you have time left, feel free to explore more features of the operator.","title":"Conclusion"},{"location":"guided_exercises/operator/introduction/","text":"Red Hat PAM Operator on OpenShift 4 In this lab we will use the enhanced Business Automation Operator 7.10+ to deploy a number of Red Hat Process Automation Manager environments on OpenShift 4. Goal Install the Business Automation Operator on OCP 4. Use the Business Automation Operator 7.10 to deploy a number of Process Automation Manager environments. Change the KIE-App deployment CRDs to show reconciliation. Change Operator ConfigMaps to make advanced configuration changes to the KIE-App. Problem Statement In this lab, the goal is to provision and manage various Red Hat Process Automation Manager architectures using the Business Automation Operator on OpenShift 4. We deploy an RHPAM Trial environment, which is a basic ephemeral environment that does not require any form of storage (e.g. persistent volume, database). We explore Operator reconciliation features by removing provisioned resources like Services and Deployment Configs. We alter the deployment through the Operator to show how the provisioned environment changes. We change a KIE configuration parameter in the Business Automation Operator ConfigMap to demonstrate advanced configuration changes. We provision a more sophisticated Production environment, to show creation of PVCs, deployment of databases and integration with RHPAM Smart Router. We use the Operator Installer console to install a new KIE-App deployment. First steps If you are using your own OpenShift environment , follow the steps below to create a project and install the operator. If you are trying this lab in an environment provisioned by the Red Hat team, skip to the section Inspect the Lab environment . Create a new project in OpenShift. We suggest the name rhpam710-operator-lab-user1 . Navigate to Operators , Operator Hub , and search for Business Automation : Click on the Business Automation and then, click Install . You can select the following options, and click on Submit : Once subscribed, you should wait for the operator to get provisioned. Then you can proceed with the lab. Inspect the Lab environment If you attending to an enablement with a provisioned environment. We provisioned an environment where each user already has a subscription to the Business Automation Operator. These Operator subscriptions are managed by the OpenShift cluster admin. Navigate to the OpenShift Master url. Login to the platform with the provided username and password. Open the project rhpam710-operator-lab-userX . Open the Workloads tab. Observe that the business-automation-operator has already been provisioned to your project. This has been done by the cluster-admin by subscribing your project to the Business Automation Operator. Expand the Operators menu group in the left-hand-side of the screen and click on Installed Operators . This will show the installed Operators, or Operator Subscriptions, in your OpenShift namespace. Click on Business Automation to access the Business Automation Operator instance in your project.","title":"Using the Business Automation Operator"},{"location":"guided_exercises/operator/introduction/#red-hat-pam-operator-on-openshift-4","text":"In this lab we will use the enhanced Business Automation Operator 7.10+ to deploy a number of Red Hat Process Automation Manager environments on OpenShift 4.","title":"Red Hat PAM Operator on OpenShift 4"},{"location":"guided_exercises/operator/introduction/#goal","text":"Install the Business Automation Operator on OCP 4. Use the Business Automation Operator 7.10 to deploy a number of Process Automation Manager environments. Change the KIE-App deployment CRDs to show reconciliation. Change Operator ConfigMaps to make advanced configuration changes to the KIE-App.","title":"Goal"},{"location":"guided_exercises/operator/introduction/#problem-statement","text":"In this lab, the goal is to provision and manage various Red Hat Process Automation Manager architectures using the Business Automation Operator on OpenShift 4. We deploy an RHPAM Trial environment, which is a basic ephemeral environment that does not require any form of storage (e.g. persistent volume, database). We explore Operator reconciliation features by removing provisioned resources like Services and Deployment Configs. We alter the deployment through the Operator to show how the provisioned environment changes. We change a KIE configuration parameter in the Business Automation Operator ConfigMap to demonstrate advanced configuration changes. We provision a more sophisticated Production environment, to show creation of PVCs, deployment of databases and integration with RHPAM Smart Router. We use the Operator Installer console to install a new KIE-App deployment.","title":"Problem Statement"},{"location":"guided_exercises/operator/introduction/#first-steps","text":"If you are using your own OpenShift environment , follow the steps below to create a project and install the operator. If you are trying this lab in an environment provisioned by the Red Hat team, skip to the section Inspect the Lab environment . Create a new project in OpenShift. We suggest the name rhpam710-operator-lab-user1 . Navigate to Operators , Operator Hub , and search for Business Automation : Click on the Business Automation and then, click Install . You can select the following options, and click on Submit : Once subscribed, you should wait for the operator to get provisioned. Then you can proceed with the lab.","title":"First steps"},{"location":"guided_exercises/operator/introduction/#inspect-the-lab-environment","text":"If you attending to an enablement with a provisioned environment. We provisioned an environment where each user already has a subscription to the Business Automation Operator. These Operator subscriptions are managed by the OpenShift cluster admin. Navigate to the OpenShift Master url. Login to the platform with the provided username and password. Open the project rhpam710-operator-lab-userX . Open the Workloads tab. Observe that the business-automation-operator has already been provisioned to your project. This has been done by the cluster-admin by subscribing your project to the Business Automation Operator. Expand the Operators menu group in the left-hand-side of the screen and click on Installed Operators . This will show the installed Operators, or Operator Subscriptions, in your OpenShift namespace. Click on Business Automation to access the Business Automation Operator instance in your project.","title":"Inspect the Lab environment"},{"location":"guided_exercises/operator/reconciliation/","text":"Reconciliation The OpenShift Operators provide functionality to reconciliate an existing environment in order to bring it back to its expected state. We will now test this feature by removing one of the required resources from our deployment. Open the Resources tab. This will show all the resources of the application deployed and managed by the Operator. On the fourth row, we can see the rhpam-trial-kieserver Service resource. In the left menu, go to Networking \u2192 Services . Open rhpam-trial-kieserver . Delete the Service by clicking on the Actions button at the upper right of the screen and clicking on Delete . Notice the Service disappearing and immediately reappearing. This is the Operators reconciliation logic at work, bringing the environment back in its expected state.","title":"Automatic reconciliation"},{"location":"guided_exercises/operator/reconciliation/#reconciliation","text":"The OpenShift Operators provide functionality to reconciliate an existing environment in order to bring it back to its expected state. We will now test this feature by removing one of the required resources from our deployment. Open the Resources tab. This will show all the resources of the application deployed and managed by the Operator. On the fourth row, we can see the rhpam-trial-kieserver Service resource. In the left menu, go to Networking \u2192 Services . Open rhpam-trial-kieserver . Delete the Service by clicking on the Actions button at the upper right of the screen and clicking on Delete . Notice the Service disappearing and immediately reappearing. This is the Operators reconciliation logic at work, bringing the environment back in its expected state.","title":"Reconciliation"},{"location":"guided_exercises/operator/trial-environment/","text":"Deploying an RHPAM Trial Environment From the Business Automation page in your OpenShift Console, open the KieApp tab and click on Create KieApp . A form will be displayed for you to choose which instalation option you want to have. notice the environment field. In this field we define the type of the environment we want to provision. In this case we want to provision the Trial environment, so we accept the default values. TIP: You also have the YAML definition option if you want to do customizations that are not available in the form above. Click on the Create button at the bottom of the page. In the KieApp tab, we can see our new rhpam-trial environment being listed. Expand the Workloads menu on the left side of the screen. Click on Deployment Configs . Observe that the Operator has created 2 Deployment Configs, one for Business Central and one for KIE-Server. Open the Developer Console by clicking on the link in the dropdown box at the top left of the screen. Click on the Topology link to show a graphical representation of the topology of our namespace, which includes an Operator DC, a Business Central DC, and a KIE-Server DC. Go back to the Adminstrator console. Open Networking \u2192 Routes menu to see all the available routes to our KIE application deployed in this namespace. Identify the Business/Decision Central URL link to navigate to the RHPAM Business Central workbench. It should be named rhpam-trial-rhpamcentr-http for the http option, or rhpam-trial-rhpamcentr for https. As the Operator is responsible for deployment and configuration of the RHPAM environment, we can find the details if this deployment in the KieApp instance details screen. Open your KieApp in Operators \u2192 Installed Operators \u2192 Business Automation \u2192 KieApp \u2192 rhpam-trial , and click on the YAML tab. We can see in the YAML description that the adminPassword has been set to RedHat . Navigate back to the Business Central workbench and login with u: adminUser p: RedHat . Explore the Business Central application. In particular, go to Menu \u2192 Deploy \u2192 Execution Servers to see the Execution Server connected to the workbench.","title":"Deploying a trial environment"},{"location":"guided_exercises/operator/trial-environment/#deploying-an-rhpam-trial-environment","text":"From the Business Automation page in your OpenShift Console, open the KieApp tab and click on Create KieApp . A form will be displayed for you to choose which instalation option you want to have. notice the environment field. In this field we define the type of the environment we want to provision. In this case we want to provision the Trial environment, so we accept the default values. TIP: You also have the YAML definition option if you want to do customizations that are not available in the form above. Click on the Create button at the bottom of the page. In the KieApp tab, we can see our new rhpam-trial environment being listed. Expand the Workloads menu on the left side of the screen. Click on Deployment Configs . Observe that the Operator has created 2 Deployment Configs, one for Business Central and one for KIE-Server. Open the Developer Console by clicking on the link in the dropdown box at the top left of the screen. Click on the Topology link to show a graphical representation of the topology of our namespace, which includes an Operator DC, a Business Central DC, and a KIE-Server DC. Go back to the Adminstrator console. Open Networking \u2192 Routes menu to see all the available routes to our KIE application deployed in this namespace. Identify the Business/Decision Central URL link to navigate to the RHPAM Business Central workbench. It should be named rhpam-trial-rhpamcentr-http for the http option, or rhpam-trial-rhpamcentr for https. As the Operator is responsible for deployment and configuration of the RHPAM environment, we can find the details if this deployment in the KieApp instance details screen. Open your KieApp in Operators \u2192 Installed Operators \u2192 Business Automation \u2192 KieApp \u2192 rhpam-trial , and click on the YAML tab. We can see in the YAML description that the adminPassword has been set to RedHat . Navigate back to the Business Central workbench and login with u: adminUser p: RedHat . Explore the Business Central application. In particular, go to Menu \u2192 Deploy \u2192 Execution Servers to see the Execution Server connected to the workbench.","title":"Deploying an RHPAM Trial Environment"},{"location":"guided_exercises/operator/version-upgrade/","text":"Version Upgrades The Operator of RHPAM is also capable of doing both patch and minor upgrades. This means that, for example, the Operation can upgrade an RHPAM environment from 7.10.0 to 7.10.1 or from 7.10.1 to 7.11.0. When creating a new KieApp, you can find the option to enable the version updates. If both the Enable Upgrades and Include minor version upgrades settings are set to true, the KieApp YAML configuration will include the following spec: With this configuration the version upgrade mechanism of the Operator should be enabled for the given KieApp.","title":"Versions and the Operator - Starting Processes with Events"},{"location":"guided_exercises/operator/version-upgrade/#version-upgrades","text":"The Operator of RHPAM is also capable of doing both patch and minor upgrades. This means that, for example, the Operation can upgrade an RHPAM environment from 7.10.0 to 7.10.1 or from 7.10.1 to 7.11.0. When creating a new KieApp, you can find the option to enable the version updates. If both the Enable Upgrades and Include minor version upgrades settings are set to true, the KieApp YAML configuration will include the following spec: With this configuration the version upgrade mechanism of the Operator should be enabled for the given KieApp.","title":"Version Upgrades"},{"location":"guided_exercises/operator/support/readme/","text":"To provision this guide in ocp: 1. Login to the cluster on your terminal 2. run oc create -f ocp-provisioning.yml","title":"Readme"},{"location":"guided_exercises/order_management/create-order-management-app/","text":"Order Management Process This is a Process Management lab in which will implement an Order Management process. The process will use BPMN2 constructs like Swimlanes , User Tasks , Gateways , combined with decision-based routing based on a DMN Model (Decision Model & Notation). It also introduces more dynamic concepts of the Red Hat Process Automation Manager process engine, like dynamic assignments of tasks based on process instance data. Goals Create an Order Management project in Red Hat Process Automation Manager. Define and create the process' domain model using the platform\u2019s Data Modeller. Implement an order management process in the process designer Implement decision logic in a DMN model. Create forms with the platform\u2019s Form Modeller. Deploy the project to the platform\u2019s Execution Server. Execute the end-to-end process. Pre-reqs Successful completion of the Environment Setup Lab or An existing, accessible, DM/PAM 7.3+ environment. Problem Statement In this lab we will create an Order Management process that manages the process of ordering a new phone or laptop. Start the process by providing the order information. The supplier sends an offer stating the expected delivery date and its best offer. Depending on the urgency of the urgency and the price, the order can be auto-approved by a DMN decision. If the order is not auto-approved, the manager needs to complete an approval step. Create a Project To define and deploy a business process, we first need to create a new project in which we can store the BPMN2 model, our domain model and the forms required for user interaction. To create a new project: Navigate to Business Central Login to the platform with the provided username and password. Click on Design to navigate to the Design perspective. In the Design perspective, create a new project. If your space is empty, this can be done by clicking on the blue Add Project button in the center of the page. If you already have projects in your space, you can click on the blue Add Project icon at the top right of the page. Give the project the name order-management , and the description \"Order Management\". With the project created, we can now start building our solution. Solution The Domain Model The business process will collect and carry data through the execution of the process. This data is stored in a data model or domain model. In this lab, we collect two types of data: OrderInfo : contains information about the order, like the item and the price. SupplierInfo : contains information about the supplier, like the name and the expected delivery date. Next: In your project, click on the Add Asset button in the middle of the screen. In the drop-down menu in the upper-left corner, select Model . Click on the Data Object tile. Give the Data Object the name OrderInfo . Leave the package set to default. Add the following fields to the OrderInfo data object: Identifier Label Type item item name String urgency urgency String targetPrice target price double managerApproval approved Boolean When you\u2019ve added the fields, save the data object by clicking on the Save button in the top menu. Use the _breadcrumb` navigator at the top-left of the screen to navigate back to our order-management project. Click on the blue Add Asset button in the top-right corner and create a new Data Object Give it the name SupplierInfo Give the SupplierInfo object the following fields: Identifier Label Type offer best offer double deliveryDate delivery date Date user user String We\u2019re done creating our data model. We can now start with our process design. Process Design With the domain model defined, we can now sketch out the main flow of the process, the actors, the user task nodes and the required automation decisions. Create a new Business Process asset. Name it OrderManagement . When the process designer opens, scroll down in the property panel on the right side of the screen, until you see the section Process Data . Expand the Process Data section and add the following 3 Process Variables by clicking on the + sign. Name Data Type orderInfo OrderInfo supplierInfo SupplierInfo approved Boolean In the palette on the left-side of the editor, select the Lane component: Create the following 3 swimlanes: Supplier , Purchase , Manager Create the Start Event node in the Purchase swimlane. Create the Prepare Offer User Task node in the Supplier swimlane and connect it to the Start Event node. Set the following properties on the node via the properties panel on the right side of the screen: Task Name: PrepareOffer Subject: Prepare Offer for #{orderInfo.item} Actors: #{supplierInfo.user} Assignments: Data Inputs and Assignments Name Data Type Source orderInfo OrderInfo orderInfo supplierInfo SupplierInfo supplierInfo Data Outputs and Assignments Name Data Type Target supplierInfo Supplier Info supplierInfo Create the Auto Approve Order Business Rule node in the Purchase swimlane and connect it to the Prepare Offer node. Set the following properties: Rule language: DMN Assigments: Data Inputs and Assignments Name Data Type Source Order Information OrderInfo orderInfo Supplier Information SupplierInfo supplierInfo Data Outputs and Assignments Name Data Type Target Approve Boolean approved After we\u2019ve created our DMN Decision Model, we will revisit the configuration of this node to reference this DMN model via it\u2019s name and namespace properties. Create an X-OR Gateway / Exclusive Gateway in the Manager swimlane, below the Auto Approve Order node and connect it to that node. Create the Approve User Task in the Manager swimlane and connect it to the X-OR gateway. Set the following properties: Task Name: Approve Subject: Approve Order of #{orderInfo.item} group: rest-all Assignments: Data Inputs and Assignments Name Data Type Source orderInfo OrderInfo orderInfo supplierInfo SupplierInfo supplierInfo Data Outputs and Assignments Name Data Type Target orderInfo OrderInfo orderInfo Create an X-OR Gateway / Exclusive Gateway in the Manager swimlane, after the Approve node and connect it to that node. Create another X-OR Gateway / Exclusive Gateway under the Manager swimlane (so outside of the swimlane) and connect it to the two other X-OR Gateways / Exclusive Gateways as shown in image below: Create the Place Order in ERP Script Task under the Manager swimlane (so outside of the swimlanes) and connect it to the X-OR Gateway we created earlier. Set the following script in the node\u2019s properties properties: System.out.println(\"Place Order in ERP\"); Create an End Event node under the Manager swimlane (so outside of the swimlanes) and connect it to the Place Order in ERP node. Name it Approved . Create an End Event node in the Purchase swimlane and connect it to the X-OR Gateway . Name it Rejected . On the Sequence Flow from the X/OR Gateway before the Approve node that is connnected ot the other X/OR Gateway , set the following condition, which tells the process engine that this path should be taken when the order is not automatically approved: Process Variable: approved Condition: Is true On the Gateway before the Approve node , set the Default Route property to Approve . On the Sequence Flow from the X/OR Gateway after the Approve task, which is connected to the X/OR Gateway before the Place Order in ERP task, set the following condition: Process Variable: orderInfo.managerApproval Condition: Is true On the X/OR Gateway after the Approval node , set the Default Route to Rejected . Save the process definition. With the overall layout of the process definition complete, the routing logic implemented, and the I/O assignments defined, we can now implement the business rules of our automated approval decision. Business Rules and Decisions Our Order Management process contains a Business Rule Task , but we have not yet defined the Decision Model that will be used in the task. In this paragraph we will implement the automatic approval rules in the form of a DMN model. In the main project page, the so called library view , click on the Add Asset button. In the next screen, set the drop-down filter to Decision . Select the DMN asset. Give it the name order-approval . In the DMN editor, open the property-panel on the right-side of the screen and set the Namespace property to: http://www.redhat.com/dmn/demo/order-management-dmn . First we need to import our data-model, so we can use it in our DMN decisions. In the DMN editor, click on the Data Types tab and click on the Import Data Object button at the right-hand side of the screen: Select both the OrderInfo and SupplierInfo objects and click on the Import button: \u200b With the 2 datatypes imported, we need to create a third type that will hold the possible values for the urgency field of our Order Information . Click on the blue Add button in the top-right corner. In the entry that opens, give the data type the Name Urgency and the Type string : Click on the Add Constraints button, select Enumeration as the constraint type , and set the values low and high`. Click on the blue checkmark button to save the type. Navigate back to the model via the Model tab. Add 2 Input nodes to the model and name them Order Information and Supplier Information Select the Order Information node. Open the properties panel on the right-hand side of the screen, and set the Data type to OrderInfo . Do the same for the Supplier Information node. Set the Data type to SupplierInfo . Create a new Business Knowledge Model node, name it Price Tolerance . Click on the node, and click on the Edit button to start editting the node: Click in the Edit parameters . An editor will open. Click on Add parameter . Name the parameter order information and set the type to OrderInfo . Right click in the empty white cell under the parameter definitions and select Clear . The text Select expression will appear in the cell. Click on the cell and select Decision Table . Add an input clause to the decision table. The name of the input clause is order information.urgency , which references the urgency attribute of the order information parameter. Set the type to Urgency , which references the Urgency enumeration we created earlier. Set the output clause data type to number . Leave the name empty. Click on the Price Tolerance cell (top cell of the table), and set the data type to number . Implement the rest of the decision table as shown below. And save the DMN model. Navigate back to the model by clicking on the Back to order-approval link at the top-left of the editor. Create a new Decision Node and name it Approve . Connect the 2 input nodes and out Price Tolerance busines knowledge model node to the new decision node. Select the Approve decision node and click on the edit button. Click on _Select Expression, and set the logic type to Literal Expression . Enter the following expression: Supplier Information.offer < Price Tolerance(Order Information) * Order Information.targetPrice Click on the Approve cell (top cell of the table), and set the data type to boolean . Navigate back to the model by clicking on the Back to order-approval link at the top-left of the editor. Our DMN model is now complete. Make sure to save your model. With our DMN model implemented, we can now revisit our Business Rules Task in our BPMN2 model. Open the order-management process definition and click on the Auto Approval Order node. Open the node\u2019s properties in the property-panel on the right side of the editor, open the Implementation/Execution section and set: Namespace: http://www.redhat.com/dmn/lab/order-approval-dmn Name: order-approval In the same properties panel, expand the Data Assignments section and open the Assignments editor Implement the following data input and output assignments. Our BPMN model is now complete. Make sure to save the model. Now, we should create implement our forms. Forms In this section we are going to create the process start and user-task forms. We could simply generate these forms with the click of a button, which gives us some standard forms based on the process and task data. In this lab however, we will be creating these forms using the Form Modeler tool. This allows us to design these forms to our specific needs. Let\u2019s start with the process start form. We want to create the following form: In the project\u2019s library view, click on Add Asset . Filter on Form , click on the Form tile. Enter the details as shown in the screenshot below: On this form we want to specify the initial order. We therefore require fields from the orderInfo and supplierInfo process variable. When we expand the Model Fields section, we can see our 2 process variables ( orderInfo and supplierInfo ). These are both complex objects. To work with complex objects (as opposed to simple types like integers and booleans), we require a data-form for that specific object. We therefore first need to create a data-form for our OrderInfo and SupplierInfo objects. Go back to the project\u2019s library view, click again on Add Asset and create a new form. Use the following details: Using the Form Modeler constructs, create the following form: To create this form, drag both the item , urgency and targetPrice onto the canvas and configure them as follows. List Box: Radio Group: Decimal Box: Save the form and create another new form for our supplierInfo . Use the following details. . Using the Form Modeler constructs, create the following form: To create this form, drag the user field onto the canvas and configure it as follows. Save the form and open the OrderManagement form (the first form we created). Drag the orderInfo process variable onto the canvas. In the pop-up form, set the OrderManagement-Order form we just created as the Nested Form : 11. Drag the supplierInfo process variable ontoo the canvas. In the pop-up form, set the OrderManagement-SupplierInfo form we just created as the Nested Form : Next, we will create the form for the Prepare Offer User Task . Create a new form. Provide the following details: 2. Our aim is to create a form that looks as such: 3. As with the process start form, this user-task form operates on 2 variables, `orderInfo` and `supplierInfo`. And, as with the process start form, we need to create a data-object form for each of these variables. Technically, data-object forms for a certain data-object can be reused in multiple task-forms. However, creating a data-object form per task-form allows us to design these data-object forms aimed for that specific task. PrepareOffer-OrderInfo PrepareOffer-SupplierInfo Finally, we need to create the task form for the Approve task. Create a new form. Provide the following details. . Our aim is create a form that looks like this: As with the other forms, this user-task form operates on 2 variables, orderInfo , supplierInfo . And, as with the other forms, we need to create a data-object form for each of these variables. Approve-SupplierInfo Approve-OrderInfo Don\u2019t forget to save all your forms!!! The implementation of our process is complete. It\u2019s now time to deploy and test our application. Deploying the Process Service With our Order Management project\u2019s process, decisions and forms completed, we can now package our project in a Deployment Unit (KJAR) and deploy it on the Execution Server. To do this: Go back to our project\u2019s Library View (for example by clicking on the Order Management link in the breadcrumb navigation in the upper-left of the screen). Click on the Deploy button in the upper-right corner of the screen. This will package our project in a Deployment Unit (KJAR) and deploy it onto the Execution Server (KIE-Server). Go to the Execution Servers perspective by clicking on \"Menu \u2192 Deploy \u2192 Execution Servers\". You will see the Deployment Unit deployed on the Execution Server. Execute the process In this section, you will execute the process deployed on the Process Execution Server via the Business Central workbench. Navigate to Menu \u2192 Manage \u2192 Process Definitions . If everything is correct, the order-management process will be listed. Click on the kebab icon of the order-management process and click on Start . In the form that opens, pick the Huawei P10 Phone as the item and set the urgency to low . Set the target price to 700 and set the supplier name to the name of your own Business Central user (e.g. pamAmdmin ). Click on Submit . 3. In the process instance details screen that opens, click on the Diagram tab to open the process instance diagram, which shows the current state of the process. The process is in a wait state at the Prepare Offer task. Navigateto Menu \u2192 Track Task Inbox**. Click on the Prepare Offer task to open its task window. Click on the Start button to start working on the task. Because the task has been assigned to a single user (via #{supplierInfo.user}), you don\u2019t have to first claim the task. Select a random delivery date. Set the best offer to 900 . Click on Complete . The process will continue to the Auto Approve Order decision node. Because of the target prices set, and the offered price, the decision will evaluale to false . Hence, the process will continue to the Approve task. Go back to the Task Inbox and open the Approve task. Click on Claim and on Start . In this form we can approve or disapprove the order via the approved checkbox, and specify a rejection reason if we reject the order. Approve the task by checking the approved checkbox and clicking on Complete : Go back to the process instance view and observe that the process instance is gone. Enable the Completed checkbox in the State filter on the left-hand-side of the screen. Observe that we can see our process instance in the list. Open the process instance, open it\u2019s Diagram tab. Observe that the order has been accepted: Run a couple more process instances with different values to test, for example, the functionality of the Automated Approval Rules . Correcting problems and errors During process instance execution, a lot of things can go wrong. Users might fill in incorrect data, remote services are not available, etc. In an ideal world, the process definition takes a lot of these possible problems into account in its design. E.g. the process definition might contain exception handling logic via boundary catching error events and retry-loops. However, there are situations in which an operator or administrator would like to manually change the process to another statem for example, restart an already completed User Task . In the latest version of Red Hat Process Automation Manager this is now possible via the Process Instance interface in Business Central. Start a new process instance of our Order Management process. Complete the Prepare Offer task in such a way that the order is not automatically approved and the process will hit the Approve User Task wait state. Go to the Process Instances view and select the process instance. Navigate to the Diagram tab. Observe that the process is waiting in the Approve User Task . Click on the Prepare Offer node to select it. In the Node Actions panel on the left-hand-side of the screen, verify that the Prepare Offer node is selected and click on Trigger . Observe that the Prepare Offer User Task has been activated. Although we have re-activated the Prepare Offer node, we have not yet de-activated the Approve task. Click on the active Approve task and expand the Node Instances section in the Node Actions panel. Click on the kebab icon of the active Approve instance and click on Cancel : 6. Open the Task Inbox . Observe that the Approve User Task is gone and that we have a new Prepare Offer task. Open the Prepare Offer task, set the price to a price which will trigger the rules to automatically approve the order, and complete the task. . Go to the process instances view and observe that the process instance has been completed. . Enable the Completed filter in the State filter panel on the left-hand-side of the screen. Open the completed process instance and open its Diagram tab. Execute the process via APIs The Execution Server provides a rich RESTful API that allows user to interact with the process engine and deployed processes via a REST. This powerful feature allows users to create modern user interface and applications in their technology of choice (e.g. Entando DXP, ReactJS/Redux, AngularJS, etc.) and integrate these applications with the process engine to create modern, process driven, enterprise applications. The Swagger interface provides the description and documentation of the Execution Server\u2019s RESTful API. At the same time, it allows the APIs to be called from the UI. This enables developers and users to quickly test a, in this case, a deployed business process. Navigate to the KIE Server Swagger Page Locate the Process instances section. The Process Instances API provides a vast array of operations to interact with the process engine. Locate the POST operation for the resource /server/containers/{containerId}/processes/{processId}/instances . This is the RESTful operation with which we can start a new process instance. Expand the operation: Click on the Try it out button. Set the containerId to order-management (in this case we use the alias of the container). Set the processId to order-management.OrderManagement . Set Parameter content type to application/json . Set the Response content type to application/json . Set the body to: json { \"orderInfo\" : { \"com.myspace.order\\_management.OrderInfo\" : { \"item\" : \"Huawei P10\", \"urgency\" : \"low\", \"price\" : 0.0, \"targetPrice\": \"700.0\" } }, \"supplierInfo\" : { \"com.myspace.order\\_management.SupplierInfo\" : { \"user\" : \"pamAdmin\" } } } Click on the Execute button. If requested, provide the username and password of your Business Central and KIE-Server user (in this example we have been using u: pamAdmin , p: redhatpam1! ). Inspect the response. Note that the operation returns the process instance id of the started process. Go back to the Business Central workbench. Go the process instances view and inspect the process instance we have just started. The RESTful API provides many more operations. Let\u2019s use the API to fetch our Task List and complete the Request Offer task. In the Swagger API, navigate to the Process queries section. Find the GET operation for the resource /server/queries/tasks/instances/pot-owners . Expand the operation and click on the Try it out button. Make sure the *Response content type is set to application/json . Leave all the other fields set to their default values. Click on the Execute button. This will return all the tasks for our user (in the case of this example this is the pamAdmin user). We can see the Prepare Offer task that is available in our inbox. Let\u2019s complete this task. Go to the Task Instances section in the Swagger interface and locate the PUT operation of the /server/containers/{containerId}/tasks/{taskInstanceId}/states/completed resource. This is the operation with which we can complete a task. Set the containerId to order-management . Set the taskInstanceId to the id of the task instance you want to complete. The task instance id an be found in the list of task instances we got back from our previous REST operation. Set auto-progress to true . This controls the auto progression of the taks through the various states of the task lifecycle (i.e. claimed, started, etc.) Set the Parameter content type to application/json . Set the Response content type to application/json . Set the body to: json { \"supplierInfo\": { \"com.myspace.order\\_management.SupplierInfo\" : { \"user\": \"pamAdmin\", \"offer\": \"900\", \"deliveryDate\":\"2020-03-11T12:00:00.000Z\" } } } Click on the Execute button. If you\u2019ve entered everything correctly, the task will be completed and the process will move to the next wait state, the Prepare Offer task. . Go back to the Business Central workbench. Go to the process instances view. Select the process instance of the task you\u2019ve just completed. Observe that the Prepare Offer task has been completed and that the process is now waiting on the Approve User Task . The rest of the tasks can be completed in the same way via the API. Using the KIE-Server Client Red Hat Process Automation Manager provides a KIE-Server Client API that allows the user to interact with the KIE-Server from a Java client using a higher level API. It abstracts the data marshalling and unmarshalling and the creation and execution of the RESTful commands from the developer, allowing him/her to focus on developing business logic. In this section we will create a simple Java client for our Order Management process. Create a new Maven Java JAR project in your favourite IDE (e.g. IntelliJ, Eclipse, Visual Studio Code). Add the following dependency to your project: <dependency> <groupid> org.kie.server </groupid> <artifactId> kie-server-client </artifactId> <version> 7.30.0.Final </version> <scope> compile </scope> </dependency> Create a Java package in your src/main/java folder with the name com.myspace.order_management . Download the OrderInfo.java file from this location and add it to the package you\u2019ve just created. Download the SupplierInfo.java file from this location and add it to the package. Create a new Java class called Main . Add a public static void main(String[] args) method to your main class. Before we implement our method, we first define a number of constants that we will need when implementing our method (note that the values of your constants can be different depending on your environment, model namespace, etc.): private static final String KIE_SERVER_URL = \"http://localhost:8080/kie-server/services/rest/server\" ; private static final String CONTAINER_ID = \"order-management\" ; private static final String USERNAME = \"pamAdmin\" ; private static final String PASSWORD = \"redhatpam1!\" ; private static final String PROCESS_ID = \"order-management.OrderManagement\" ; KIE-Server client API classes can mostly be retrieved from the KieServicesFactory class. We first need to create a KieServicesConfiguration instance that will hold our credentials and defines how we want our client to communicate with the server: KieServicesConfiguration kieServicesConfig = KieServicesFactory . newRestConfiguration ( KIE_SERVER_URL , new EnteredCredentialsProvider ( USERNAME , PASSWORD )); To allow the KIE-Server Client\u2019s marshaller to marshall and unmarshall instances of our domain model, we need to add our domain model classes to the KieServicesConfiguration . Set < Class <?>> extraClasses = new HashSet <> (); extraClasses . add ( OrderInfo . class ); extraClasses . add ( SupplierInfo . class ); kieServicesConfig . addExtraClasses ( extraClasses ); Next, we create the KieServicesClient : KieServicesClient kieServicesClient = KieServicesFactory . newKieServicesClient ( kieServicesConfig ); From this client we retrieve our ProcessServicesClient : ProcessServicesClient processServicesClient = kieServicesClient . getServicesClient ( ProcessServicesClient . class ); We now create a Map which we will use to pass the process input variables. We create a new OrderInfo instance and SupplierInfo instance and put them in the Map . Map < String , Object > inputData = new HashMap <> (); OrderInfo orderInfo = new OrderInfo (); orderInfo . setItem ( \"Huawei P10\" ); orderInfo . setUrgency ( \"low\" ); inputData . put ( \"orderInfo\" , orderInfo ); SupplierInfo supplierInfo = new SupplierInfo (); supplierInfo . setUser ( \"pamAdmin\" ); inputData . put ( \"supplierInfo\" , supplierInfo ); We can now start a new process instance via the ProcessServicesClient . Long processInstanceId = processServicesClient . startProcess ( CONTAINER_ID , PROCESS_ID , inputData ); Finally, we can print the process instance id to System.out . System . out . println ( \"New *Order Management* process instance started with instance-id: \" + processInstanceId ); Compile your project and run it. Observe the output in the console, which should say: New Order Management process instance started with instance-id The complete project can be found here: https://github.com/DuncanDoyle/order-management-rhpam-lab-client The KIE-Server Client provides more services to interact with the Execution Server: UserTaskServicesClient : provides functionality to interact with the UserTask services, for example to claim, start and complete a User Task . CaseServicesClient : provides functionality to interact with the Case Management features of the Execution Server. ProcessAdminServicesClient : provides the administration API for processes. etc. We leave as an exercise to the reader to try to complete a User Task , of the process instance we\u2019ve just created, using the UserTaskServicesClient .","title":"Order Management Process"},{"location":"guided_exercises/order_management/create-order-management-app/#order-management-process","text":"This is a Process Management lab in which will implement an Order Management process. The process will use BPMN2 constructs like Swimlanes , User Tasks , Gateways , combined with decision-based routing based on a DMN Model (Decision Model & Notation). It also introduces more dynamic concepts of the Red Hat Process Automation Manager process engine, like dynamic assignments of tasks based on process instance data.","title":"Order Management Process"},{"location":"guided_exercises/order_management/create-order-management-app/#goals","text":"Create an Order Management project in Red Hat Process Automation Manager. Define and create the process' domain model using the platform\u2019s Data Modeller. Implement an order management process in the process designer Implement decision logic in a DMN model. Create forms with the platform\u2019s Form Modeller. Deploy the project to the platform\u2019s Execution Server. Execute the end-to-end process.","title":"Goals"},{"location":"guided_exercises/order_management/create-order-management-app/#pre-reqs","text":"Successful completion of the Environment Setup Lab or An existing, accessible, DM/PAM 7.3+ environment.","title":"Pre-reqs"},{"location":"guided_exercises/order_management/create-order-management-app/#problem-statement","text":"In this lab we will create an Order Management process that manages the process of ordering a new phone or laptop. Start the process by providing the order information. The supplier sends an offer stating the expected delivery date and its best offer. Depending on the urgency of the urgency and the price, the order can be auto-approved by a DMN decision. If the order is not auto-approved, the manager needs to complete an approval step.","title":"Problem Statement"},{"location":"guided_exercises/order_management/create-order-management-app/#create-a-project","text":"To define and deploy a business process, we first need to create a new project in which we can store the BPMN2 model, our domain model and the forms required for user interaction. To create a new project: Navigate to Business Central Login to the platform with the provided username and password. Click on Design to navigate to the Design perspective. In the Design perspective, create a new project. If your space is empty, this can be done by clicking on the blue Add Project button in the center of the page. If you already have projects in your space, you can click on the blue Add Project icon at the top right of the page. Give the project the name order-management , and the description \"Order Management\". With the project created, we can now start building our solution.","title":"Create a Project"},{"location":"guided_exercises/order_management/create-order-management-app/#solution","text":"","title":"Solution"},{"location":"guided_exercises/order_management/create-order-management-app/#the-domain-model","text":"The business process will collect and carry data through the execution of the process. This data is stored in a data model or domain model. In this lab, we collect two types of data: OrderInfo : contains information about the order, like the item and the price. SupplierInfo : contains information about the supplier, like the name and the expected delivery date. Next: In your project, click on the Add Asset button in the middle of the screen. In the drop-down menu in the upper-left corner, select Model . Click on the Data Object tile. Give the Data Object the name OrderInfo . Leave the package set to default. Add the following fields to the OrderInfo data object: Identifier Label Type item item name String urgency urgency String targetPrice target price double managerApproval approved Boolean When you\u2019ve added the fields, save the data object by clicking on the Save button in the top menu. Use the _breadcrumb` navigator at the top-left of the screen to navigate back to our order-management project. Click on the blue Add Asset button in the top-right corner and create a new Data Object Give it the name SupplierInfo Give the SupplierInfo object the following fields: Identifier Label Type offer best offer double deliveryDate delivery date Date user user String We\u2019re done creating our data model. We can now start with our process design.","title":"The Domain Model"},{"location":"guided_exercises/order_management/create-order-management-app/#process-design","text":"With the domain model defined, we can now sketch out the main flow of the process, the actors, the user task nodes and the required automation decisions. Create a new Business Process asset. Name it OrderManagement . When the process designer opens, scroll down in the property panel on the right side of the screen, until you see the section Process Data . Expand the Process Data section and add the following 3 Process Variables by clicking on the + sign. Name Data Type orderInfo OrderInfo supplierInfo SupplierInfo approved Boolean In the palette on the left-side of the editor, select the Lane component: Create the following 3 swimlanes: Supplier , Purchase , Manager Create the Start Event node in the Purchase swimlane. Create the Prepare Offer User Task node in the Supplier swimlane and connect it to the Start Event node. Set the following properties on the node via the properties panel on the right side of the screen: Task Name: PrepareOffer Subject: Prepare Offer for #{orderInfo.item} Actors: #{supplierInfo.user} Assignments: Data Inputs and Assignments Name Data Type Source orderInfo OrderInfo orderInfo supplierInfo SupplierInfo supplierInfo Data Outputs and Assignments Name Data Type Target supplierInfo Supplier Info supplierInfo Create the Auto Approve Order Business Rule node in the Purchase swimlane and connect it to the Prepare Offer node. Set the following properties: Rule language: DMN Assigments: Data Inputs and Assignments Name Data Type Source Order Information OrderInfo orderInfo Supplier Information SupplierInfo supplierInfo Data Outputs and Assignments Name Data Type Target Approve Boolean approved After we\u2019ve created our DMN Decision Model, we will revisit the configuration of this node to reference this DMN model via it\u2019s name and namespace properties. Create an X-OR Gateway / Exclusive Gateway in the Manager swimlane, below the Auto Approve Order node and connect it to that node. Create the Approve User Task in the Manager swimlane and connect it to the X-OR gateway. Set the following properties: Task Name: Approve Subject: Approve Order of #{orderInfo.item} group: rest-all Assignments: Data Inputs and Assignments Name Data Type Source orderInfo OrderInfo orderInfo supplierInfo SupplierInfo supplierInfo Data Outputs and Assignments Name Data Type Target orderInfo OrderInfo orderInfo Create an X-OR Gateway / Exclusive Gateway in the Manager swimlane, after the Approve node and connect it to that node. Create another X-OR Gateway / Exclusive Gateway under the Manager swimlane (so outside of the swimlane) and connect it to the two other X-OR Gateways / Exclusive Gateways as shown in image below: Create the Place Order in ERP Script Task under the Manager swimlane (so outside of the swimlanes) and connect it to the X-OR Gateway we created earlier. Set the following script in the node\u2019s properties properties: System.out.println(\"Place Order in ERP\"); Create an End Event node under the Manager swimlane (so outside of the swimlanes) and connect it to the Place Order in ERP node. Name it Approved . Create an End Event node in the Purchase swimlane and connect it to the X-OR Gateway . Name it Rejected . On the Sequence Flow from the X/OR Gateway before the Approve node that is connnected ot the other X/OR Gateway , set the following condition, which tells the process engine that this path should be taken when the order is not automatically approved: Process Variable: approved Condition: Is true On the Gateway before the Approve node , set the Default Route property to Approve . On the Sequence Flow from the X/OR Gateway after the Approve task, which is connected to the X/OR Gateway before the Place Order in ERP task, set the following condition: Process Variable: orderInfo.managerApproval Condition: Is true On the X/OR Gateway after the Approval node , set the Default Route to Rejected . Save the process definition. With the overall layout of the process definition complete, the routing logic implemented, and the I/O assignments defined, we can now implement the business rules of our automated approval decision.","title":"Process Design"},{"location":"guided_exercises/order_management/create-order-management-app/#business-rules-and-decisions","text":"Our Order Management process contains a Business Rule Task , but we have not yet defined the Decision Model that will be used in the task. In this paragraph we will implement the automatic approval rules in the form of a DMN model. In the main project page, the so called library view , click on the Add Asset button. In the next screen, set the drop-down filter to Decision . Select the DMN asset. Give it the name order-approval . In the DMN editor, open the property-panel on the right-side of the screen and set the Namespace property to: http://www.redhat.com/dmn/demo/order-management-dmn . First we need to import our data-model, so we can use it in our DMN decisions. In the DMN editor, click on the Data Types tab and click on the Import Data Object button at the right-hand side of the screen: Select both the OrderInfo and SupplierInfo objects and click on the Import button: \u200b With the 2 datatypes imported, we need to create a third type that will hold the possible values for the urgency field of our Order Information . Click on the blue Add button in the top-right corner. In the entry that opens, give the data type the Name Urgency and the Type string : Click on the Add Constraints button, select Enumeration as the constraint type , and set the values low and high`. Click on the blue checkmark button to save the type. Navigate back to the model via the Model tab. Add 2 Input nodes to the model and name them Order Information and Supplier Information Select the Order Information node. Open the properties panel on the right-hand side of the screen, and set the Data type to OrderInfo . Do the same for the Supplier Information node. Set the Data type to SupplierInfo . Create a new Business Knowledge Model node, name it Price Tolerance . Click on the node, and click on the Edit button to start editting the node: Click in the Edit parameters . An editor will open. Click on Add parameter . Name the parameter order information and set the type to OrderInfo . Right click in the empty white cell under the parameter definitions and select Clear . The text Select expression will appear in the cell. Click on the cell and select Decision Table . Add an input clause to the decision table. The name of the input clause is order information.urgency , which references the urgency attribute of the order information parameter. Set the type to Urgency , which references the Urgency enumeration we created earlier. Set the output clause data type to number . Leave the name empty. Click on the Price Tolerance cell (top cell of the table), and set the data type to number . Implement the rest of the decision table as shown below. And save the DMN model. Navigate back to the model by clicking on the Back to order-approval link at the top-left of the editor. Create a new Decision Node and name it Approve . Connect the 2 input nodes and out Price Tolerance busines knowledge model node to the new decision node. Select the Approve decision node and click on the edit button. Click on _Select Expression, and set the logic type to Literal Expression . Enter the following expression: Supplier Information.offer < Price Tolerance(Order Information) * Order Information.targetPrice Click on the Approve cell (top cell of the table), and set the data type to boolean . Navigate back to the model by clicking on the Back to order-approval link at the top-left of the editor. Our DMN model is now complete. Make sure to save your model. With our DMN model implemented, we can now revisit our Business Rules Task in our BPMN2 model. Open the order-management process definition and click on the Auto Approval Order node. Open the node\u2019s properties in the property-panel on the right side of the editor, open the Implementation/Execution section and set: Namespace: http://www.redhat.com/dmn/lab/order-approval-dmn Name: order-approval In the same properties panel, expand the Data Assignments section and open the Assignments editor Implement the following data input and output assignments. Our BPMN model is now complete. Make sure to save the model. Now, we should create implement our forms.","title":"Business Rules and Decisions"},{"location":"guided_exercises/order_management/create-order-management-app/#forms","text":"In this section we are going to create the process start and user-task forms. We could simply generate these forms with the click of a button, which gives us some standard forms based on the process and task data. In this lab however, we will be creating these forms using the Form Modeler tool. This allows us to design these forms to our specific needs. Let\u2019s start with the process start form. We want to create the following form: In the project\u2019s library view, click on Add Asset . Filter on Form , click on the Form tile. Enter the details as shown in the screenshot below: On this form we want to specify the initial order. We therefore require fields from the orderInfo and supplierInfo process variable. When we expand the Model Fields section, we can see our 2 process variables ( orderInfo and supplierInfo ). These are both complex objects. To work with complex objects (as opposed to simple types like integers and booleans), we require a data-form for that specific object. We therefore first need to create a data-form for our OrderInfo and SupplierInfo objects. Go back to the project\u2019s library view, click again on Add Asset and create a new form. Use the following details: Using the Form Modeler constructs, create the following form: To create this form, drag both the item , urgency and targetPrice onto the canvas and configure them as follows. List Box: Radio Group: Decimal Box: Save the form and create another new form for our supplierInfo . Use the following details. . Using the Form Modeler constructs, create the following form: To create this form, drag the user field onto the canvas and configure it as follows. Save the form and open the OrderManagement form (the first form we created). Drag the orderInfo process variable onto the canvas. In the pop-up form, set the OrderManagement-Order form we just created as the Nested Form : 11. Drag the supplierInfo process variable ontoo the canvas. In the pop-up form, set the OrderManagement-SupplierInfo form we just created as the Nested Form : Next, we will create the form for the Prepare Offer User Task . Create a new form. Provide the following details: 2. Our aim is to create a form that looks as such: 3. As with the process start form, this user-task form operates on 2 variables, `orderInfo` and `supplierInfo`. And, as with the process start form, we need to create a data-object form for each of these variables. Technically, data-object forms for a certain data-object can be reused in multiple task-forms. However, creating a data-object form per task-form allows us to design these data-object forms aimed for that specific task. PrepareOffer-OrderInfo PrepareOffer-SupplierInfo Finally, we need to create the task form for the Approve task. Create a new form. Provide the following details. . Our aim is create a form that looks like this: As with the other forms, this user-task form operates on 2 variables, orderInfo , supplierInfo . And, as with the other forms, we need to create a data-object form for each of these variables. Approve-SupplierInfo Approve-OrderInfo Don\u2019t forget to save all your forms!!! The implementation of our process is complete. It\u2019s now time to deploy and test our application.","title":"Forms"},{"location":"guided_exercises/order_management/create-order-management-app/#deploying-the-process-service","text":"With our Order Management project\u2019s process, decisions and forms completed, we can now package our project in a Deployment Unit (KJAR) and deploy it on the Execution Server. To do this: Go back to our project\u2019s Library View (for example by clicking on the Order Management link in the breadcrumb navigation in the upper-left of the screen). Click on the Deploy button in the upper-right corner of the screen. This will package our project in a Deployment Unit (KJAR) and deploy it onto the Execution Server (KIE-Server). Go to the Execution Servers perspective by clicking on \"Menu \u2192 Deploy \u2192 Execution Servers\". You will see the Deployment Unit deployed on the Execution Server.","title":"Deploying the Process Service"},{"location":"guided_exercises/order_management/create-order-management-app/#execute-the-process","text":"In this section, you will execute the process deployed on the Process Execution Server via the Business Central workbench. Navigate to Menu \u2192 Manage \u2192 Process Definitions . If everything is correct, the order-management process will be listed. Click on the kebab icon of the order-management process and click on Start . In the form that opens, pick the Huawei P10 Phone as the item and set the urgency to low . Set the target price to 700 and set the supplier name to the name of your own Business Central user (e.g. pamAmdmin ). Click on Submit . 3. In the process instance details screen that opens, click on the Diagram tab to open the process instance diagram, which shows the current state of the process. The process is in a wait state at the Prepare Offer task. Navigateto Menu \u2192 Track Task Inbox**. Click on the Prepare Offer task to open its task window. Click on the Start button to start working on the task. Because the task has been assigned to a single user (via #{supplierInfo.user}), you don\u2019t have to first claim the task. Select a random delivery date. Set the best offer to 900 . Click on Complete . The process will continue to the Auto Approve Order decision node. Because of the target prices set, and the offered price, the decision will evaluale to false . Hence, the process will continue to the Approve task. Go back to the Task Inbox and open the Approve task. Click on Claim and on Start . In this form we can approve or disapprove the order via the approved checkbox, and specify a rejection reason if we reject the order. Approve the task by checking the approved checkbox and clicking on Complete : Go back to the process instance view and observe that the process instance is gone. Enable the Completed checkbox in the State filter on the left-hand-side of the screen. Observe that we can see our process instance in the list. Open the process instance, open it\u2019s Diagram tab. Observe that the order has been accepted: Run a couple more process instances with different values to test, for example, the functionality of the Automated Approval Rules .","title":"Execute the process"},{"location":"guided_exercises/order_management/create-order-management-app/#correcting-problems-and-errors","text":"During process instance execution, a lot of things can go wrong. Users might fill in incorrect data, remote services are not available, etc. In an ideal world, the process definition takes a lot of these possible problems into account in its design. E.g. the process definition might contain exception handling logic via boundary catching error events and retry-loops. However, there are situations in which an operator or administrator would like to manually change the process to another statem for example, restart an already completed User Task . In the latest version of Red Hat Process Automation Manager this is now possible via the Process Instance interface in Business Central. Start a new process instance of our Order Management process. Complete the Prepare Offer task in such a way that the order is not automatically approved and the process will hit the Approve User Task wait state. Go to the Process Instances view and select the process instance. Navigate to the Diagram tab. Observe that the process is waiting in the Approve User Task . Click on the Prepare Offer node to select it. In the Node Actions panel on the left-hand-side of the screen, verify that the Prepare Offer node is selected and click on Trigger . Observe that the Prepare Offer User Task has been activated. Although we have re-activated the Prepare Offer node, we have not yet de-activated the Approve task. Click on the active Approve task and expand the Node Instances section in the Node Actions panel. Click on the kebab icon of the active Approve instance and click on Cancel : 6. Open the Task Inbox . Observe that the Approve User Task is gone and that we have a new Prepare Offer task. Open the Prepare Offer task, set the price to a price which will trigger the rules to automatically approve the order, and complete the task. . Go to the process instances view and observe that the process instance has been completed. . Enable the Completed filter in the State filter panel on the left-hand-side of the screen. Open the completed process instance and open its Diagram tab.","title":"Correcting problems and errors"},{"location":"guided_exercises/order_management/create-order-management-app/#execute-the-process-via-apis","text":"The Execution Server provides a rich RESTful API that allows user to interact with the process engine and deployed processes via a REST. This powerful feature allows users to create modern user interface and applications in their technology of choice (e.g. Entando DXP, ReactJS/Redux, AngularJS, etc.) and integrate these applications with the process engine to create modern, process driven, enterprise applications. The Swagger interface provides the description and documentation of the Execution Server\u2019s RESTful API. At the same time, it allows the APIs to be called from the UI. This enables developers and users to quickly test a, in this case, a deployed business process. Navigate to the KIE Server Swagger Page Locate the Process instances section. The Process Instances API provides a vast array of operations to interact with the process engine. Locate the POST operation for the resource /server/containers/{containerId}/processes/{processId}/instances . This is the RESTful operation with which we can start a new process instance. Expand the operation: Click on the Try it out button. Set the containerId to order-management (in this case we use the alias of the container). Set the processId to order-management.OrderManagement . Set Parameter content type to application/json . Set the Response content type to application/json . Set the body to: json { \"orderInfo\" : { \"com.myspace.order\\_management.OrderInfo\" : { \"item\" : \"Huawei P10\", \"urgency\" : \"low\", \"price\" : 0.0, \"targetPrice\": \"700.0\" } }, \"supplierInfo\" : { \"com.myspace.order\\_management.SupplierInfo\" : { \"user\" : \"pamAdmin\" } } } Click on the Execute button. If requested, provide the username and password of your Business Central and KIE-Server user (in this example we have been using u: pamAdmin , p: redhatpam1! ). Inspect the response. Note that the operation returns the process instance id of the started process. Go back to the Business Central workbench. Go the process instances view and inspect the process instance we have just started. The RESTful API provides many more operations. Let\u2019s use the API to fetch our Task List and complete the Request Offer task. In the Swagger API, navigate to the Process queries section. Find the GET operation for the resource /server/queries/tasks/instances/pot-owners . Expand the operation and click on the Try it out button. Make sure the *Response content type is set to application/json . Leave all the other fields set to their default values. Click on the Execute button. This will return all the tasks for our user (in the case of this example this is the pamAdmin user). We can see the Prepare Offer task that is available in our inbox. Let\u2019s complete this task. Go to the Task Instances section in the Swagger interface and locate the PUT operation of the /server/containers/{containerId}/tasks/{taskInstanceId}/states/completed resource. This is the operation with which we can complete a task. Set the containerId to order-management . Set the taskInstanceId to the id of the task instance you want to complete. The task instance id an be found in the list of task instances we got back from our previous REST operation. Set auto-progress to true . This controls the auto progression of the taks through the various states of the task lifecycle (i.e. claimed, started, etc.) Set the Parameter content type to application/json . Set the Response content type to application/json . Set the body to: json { \"supplierInfo\": { \"com.myspace.order\\_management.SupplierInfo\" : { \"user\": \"pamAdmin\", \"offer\": \"900\", \"deliveryDate\":\"2020-03-11T12:00:00.000Z\" } } } Click on the Execute button. If you\u2019ve entered everything correctly, the task will be completed and the process will move to the next wait state, the Prepare Offer task. . Go back to the Business Central workbench. Go to the process instances view. Select the process instance of the task you\u2019ve just completed. Observe that the Prepare Offer task has been completed and that the process is now waiting on the Approve User Task . The rest of the tasks can be completed in the same way via the API.","title":"Execute the process via APIs"},{"location":"guided_exercises/order_management/create-order-management-app/#using-the-kie-server-client","text":"Red Hat Process Automation Manager provides a KIE-Server Client API that allows the user to interact with the KIE-Server from a Java client using a higher level API. It abstracts the data marshalling and unmarshalling and the creation and execution of the RESTful commands from the developer, allowing him/her to focus on developing business logic. In this section we will create a simple Java client for our Order Management process. Create a new Maven Java JAR project in your favourite IDE (e.g. IntelliJ, Eclipse, Visual Studio Code). Add the following dependency to your project: <dependency> <groupid> org.kie.server </groupid> <artifactId> kie-server-client </artifactId> <version> 7.30.0.Final </version> <scope> compile </scope> </dependency> Create a Java package in your src/main/java folder with the name com.myspace.order_management . Download the OrderInfo.java file from this location and add it to the package you\u2019ve just created. Download the SupplierInfo.java file from this location and add it to the package. Create a new Java class called Main . Add a public static void main(String[] args) method to your main class. Before we implement our method, we first define a number of constants that we will need when implementing our method (note that the values of your constants can be different depending on your environment, model namespace, etc.): private static final String KIE_SERVER_URL = \"http://localhost:8080/kie-server/services/rest/server\" ; private static final String CONTAINER_ID = \"order-management\" ; private static final String USERNAME = \"pamAdmin\" ; private static final String PASSWORD = \"redhatpam1!\" ; private static final String PROCESS_ID = \"order-management.OrderManagement\" ; KIE-Server client API classes can mostly be retrieved from the KieServicesFactory class. We first need to create a KieServicesConfiguration instance that will hold our credentials and defines how we want our client to communicate with the server: KieServicesConfiguration kieServicesConfig = KieServicesFactory . newRestConfiguration ( KIE_SERVER_URL , new EnteredCredentialsProvider ( USERNAME , PASSWORD )); To allow the KIE-Server Client\u2019s marshaller to marshall and unmarshall instances of our domain model, we need to add our domain model classes to the KieServicesConfiguration . Set < Class <?>> extraClasses = new HashSet <> (); extraClasses . add ( OrderInfo . class ); extraClasses . add ( SupplierInfo . class ); kieServicesConfig . addExtraClasses ( extraClasses ); Next, we create the KieServicesClient : KieServicesClient kieServicesClient = KieServicesFactory . newKieServicesClient ( kieServicesConfig ); From this client we retrieve our ProcessServicesClient : ProcessServicesClient processServicesClient = kieServicesClient . getServicesClient ( ProcessServicesClient . class ); We now create a Map which we will use to pass the process input variables. We create a new OrderInfo instance and SupplierInfo instance and put them in the Map . Map < String , Object > inputData = new HashMap <> (); OrderInfo orderInfo = new OrderInfo (); orderInfo . setItem ( \"Huawei P10\" ); orderInfo . setUrgency ( \"low\" ); inputData . put ( \"orderInfo\" , orderInfo ); SupplierInfo supplierInfo = new SupplierInfo (); supplierInfo . setUser ( \"pamAdmin\" ); inputData . put ( \"supplierInfo\" , supplierInfo ); We can now start a new process instance via the ProcessServicesClient . Long processInstanceId = processServicesClient . startProcess ( CONTAINER_ID , PROCESS_ID , inputData ); Finally, we can print the process instance id to System.out . System . out . println ( \"New *Order Management* process instance started with instance-id: \" + processInstanceId ); Compile your project and run it. Observe the output in the console, which should say: New Order Management process instance started with instance-id The complete project can be found here: https://github.com/DuncanDoyle/order-management-rhpam-lab-client The KIE-Server Client provides more services to interact with the Execution Server: UserTaskServicesClient : provides functionality to interact with the UserTask services, for example to claim, start and complete a User Task . CaseServicesClient : provides functionality to interact with the Case Management features of the Execution Server. ProcessAdminServicesClient : provides the administration API for processes. etc. We leave as an exercise to the reader to try to complete a User Task , of the process instance we\u2019ve just created, using the UserTaskServicesClient .","title":"Using the KIE-Server Client"},{"location":"guided_exercises/order_management/try-order-management-app/","text":"Getting started with RHPAM This guide shows you the experience of using Red Hat Process Automation Manager to author, deploy, and execute your business automation applications. With three steps, this guide will get you from installation to deployment and testing of a business application: We will install RHPAM locally, and it will run on top of Red Hat JBoss EAP (a.k.a. WildFly). Once we have it up and running, we will import an existing application, so that we have an overview of some capabilities by exploring the tool and the project itself. Finally, we'll wrap up by deploying the project and testing it. Set up Pre-requisites We expect you to have installed in your machine: Java JDK 11 ( if you don't have it yet, you can download OpenJDK built by Red Hat https://developers.redhat.com/openjdk-install ) GIT client (https://git-scm.com/) Red Hat Process Automation Manager 7 Installation Demo : NOTE : You should use this installer to quickly install EAP, PAM and pre-configure the environment and user access you'll need. $ git clone https://github.com/jbossdemocentral/rhpam7-install-demo.git You should now have successfully installed Red Hat Process Automation Manager. You have two key components deployed in your Red Hat EAP right now: Business Central and KIE Server . Business Central is the component that allows you to develop business assets like processes and decisions, to manage projects, build and package them. Finally, you can deploy it in KIE Server. KIE Server is a lightweight engine capable of executing business assets like processes, cases and decisions. It can be easily integrated with your services, for example via REST or JMS. Luckily, Red Hat Process Automation Manager comes with a number of out-of-the-box template and example applications that can be used to quickly build and deploy a process microservice. Explore Let's start by accessing Business Central. In your browser, access Business Central by navigating to http://localhost:8080/business-central Log in with the credentials: User: pamAdmin Password: redhatdm1! Click on \"Design, create and modify projects and pages\" Select \"MySpace\", and next, click on \"Import Project\": Insert the following repository URL, and click on Import. https://github.com/jbossdemocentral/rhpam7-order-management-demo-repo.git Select the Order-Management project and click on OK. Once the project has been imported, notice it has 27 assets. Click on the filter button \"All\" and select Process. Open the order-management process. This is the automated process that determines the approval or denial of an order request. As you see below, it is implemented with the BPMN2 standard. The final element of this process, is a sub-process \"Place Order in ERP\". This subprocess includes advanced bpmn2 modeling concepts like compensation and event based gateways. Have in mind that PAM supports the modeling of advanced flows using the bpmn2 specification, but don't worry if you don't fully get what is happening in this subprocess. Notice this process tasks are aggregated in three lanes: Manager, Purchase and Supplier. The approval decision will be made based on multiple authors, but, in this process we even have the support of automated decision. The automated decision is made on the node \"Auto Approve Decision\", that references a DMN Model that is also part of this business project. Close the process modeler. Now, filter the assets by Decision. You should see a Test Scenario and a DMN model. Open the order-approval. It is a simple decision model that can define the \"Approve\" decision based on the data input \"Order Information\" and on the \"Price Tolerance\" business rules. Now, close the decision asset. In your project page, click on the Deploy button. Business Central will trigger the build of this maven project, that will be packaged in a KJAR (the deployment unit which contains the assets) and will be deployed on the KIE server. Once the build and deployment has finished, you'll see a successful deployment message. Click on the \"View deployment details\" link. The page will show a running \u201cdefault-kieserver\u201d with the \u201corder-management_1.1-SNAPSHOT\u201d container deployed. Our business project is now available to be consumed by client applications! Let's have a look at how we can consume this business application. Experience The engine, KIE Server, is the service which exposes the business project and also the one we use when integrating with client applications. It comes with a Swagger UI that allows us to test the RESTful endpoints of the engine and consume rules deployed on it. Another way to consume our business project is to use Business Central UI to interact with the engine and test our business assets. For this hello world, let's use Business Central process and task management capabilities. In Business Central, let's open the Menu in the top bar and navigate to \"Process Definitions\" We can see three different process definitions. We'll start a new process instance based on the \"order-management\" process. Click on the actions kebab, and select \"Start\" The form that opened is also part of our business process and we can customize it if needed. For now, let's just fill in the data required to start our process instance, and click the \"Submit\" button. Item Name: Laptop Dell XPS 15 Urgency: Medium A new process instance will start in the engine. In order to visualize the current status, click on \"Diagram\". Notice we currently have a Human Task named \"Request Offer\" waiting for human intervention. Now, let's work on this task. In the Menu, access the \"Task Inbox\": In the list you should see a list of tasks you have permission to see and work on. Let's claim the Request Offer task to our user, and start working on it. Click on the kebab and select the \"Claim and Work\" option: You'll see the task data available for your analysis, as a knowledge worker - someone responsible for executing the task. Click on the blue \"Start\" button to start working on the task.Based on this offer, we'll define our reply. Inform the following data and click on the blue \"Complete\" button: Category : optional Target Price: 250 Suplier list: supplier 1 According to our process, a new task will be created for the suppliers. The supplier should provide an offer - so let's do it. Still on the task list, claim and work the task \"Prepare Offer\": Click \"Start\" blue button, inform any date, and the best offer as 1000 . Click on complete. At this point, the automatic approval was already taken, and our request was not automatically approved. You can confirm this by visualizing the process instance. On the kebab, select \"View Process\" You'll be redirected to the list of process instances. Select the process instance with id 1, and then, choose the \"Diagram\" option: At this point, you have learned how you manage processes and tasks using Business Central. You know how to start new process instances, how to interact with the process tasks and how to complete them. What about finishing this process by your own? Following the same idea, In Business Central, you can reprove the request, reject the order and reach the end of this process instance. Conclusion Congratulations, you successfully concluded a Hello World in Red Hat Process Automation Manager. In this guide, we installed Red Hat PAM, imported a project directly from GitHub, checked out the a process definition modeled and an automation decision. We wrapped up our tutorial by deploying and testing our services using Business Central UI. If you want to know more about the Order Management demo, we recommend you take a look at the project's instructions at the github repository: https://github.com/jbossdemocentral/rhpam7-order-management-demo-repo.","title":"Getting started with RHPAM"},{"location":"guided_exercises/order_management/try-order-management-app/#getting-started-with-rhpam","text":"This guide shows you the experience of using Red Hat Process Automation Manager to author, deploy, and execute your business automation applications. With three steps, this guide will get you from installation to deployment and testing of a business application: We will install RHPAM locally, and it will run on top of Red Hat JBoss EAP (a.k.a. WildFly). Once we have it up and running, we will import an existing application, so that we have an overview of some capabilities by exploring the tool and the project itself. Finally, we'll wrap up by deploying the project and testing it.","title":"Getting started with RHPAM"},{"location":"guided_exercises/order_management/try-order-management-app/#set-up","text":"Pre-requisites We expect you to have installed in your machine: Java JDK 11 ( if you don't have it yet, you can download OpenJDK built by Red Hat https://developers.redhat.com/openjdk-install ) GIT client (https://git-scm.com/) Red Hat Process Automation Manager 7 Installation Demo : NOTE : You should use this installer to quickly install EAP, PAM and pre-configure the environment and user access you'll need. $ git clone https://github.com/jbossdemocentral/rhpam7-install-demo.git You should now have successfully installed Red Hat Process Automation Manager. You have two key components deployed in your Red Hat EAP right now: Business Central and KIE Server . Business Central is the component that allows you to develop business assets like processes and decisions, to manage projects, build and package them. Finally, you can deploy it in KIE Server. KIE Server is a lightweight engine capable of executing business assets like processes, cases and decisions. It can be easily integrated with your services, for example via REST or JMS. Luckily, Red Hat Process Automation Manager comes with a number of out-of-the-box template and example applications that can be used to quickly build and deploy a process microservice.","title":"Set up"},{"location":"guided_exercises/order_management/try-order-management-app/#explore","text":"Let's start by accessing Business Central. In your browser, access Business Central by navigating to http://localhost:8080/business-central Log in with the credentials: User: pamAdmin Password: redhatdm1! Click on \"Design, create and modify projects and pages\" Select \"MySpace\", and next, click on \"Import Project\": Insert the following repository URL, and click on Import. https://github.com/jbossdemocentral/rhpam7-order-management-demo-repo.git Select the Order-Management project and click on OK. Once the project has been imported, notice it has 27 assets. Click on the filter button \"All\" and select Process. Open the order-management process. This is the automated process that determines the approval or denial of an order request. As you see below, it is implemented with the BPMN2 standard. The final element of this process, is a sub-process \"Place Order in ERP\". This subprocess includes advanced bpmn2 modeling concepts like compensation and event based gateways. Have in mind that PAM supports the modeling of advanced flows using the bpmn2 specification, but don't worry if you don't fully get what is happening in this subprocess. Notice this process tasks are aggregated in three lanes: Manager, Purchase and Supplier. The approval decision will be made based on multiple authors, but, in this process we even have the support of automated decision. The automated decision is made on the node \"Auto Approve Decision\", that references a DMN Model that is also part of this business project. Close the process modeler. Now, filter the assets by Decision. You should see a Test Scenario and a DMN model. Open the order-approval. It is a simple decision model that can define the \"Approve\" decision based on the data input \"Order Information\" and on the \"Price Tolerance\" business rules. Now, close the decision asset. In your project page, click on the Deploy button. Business Central will trigger the build of this maven project, that will be packaged in a KJAR (the deployment unit which contains the assets) and will be deployed on the KIE server. Once the build and deployment has finished, you'll see a successful deployment message. Click on the \"View deployment details\" link. The page will show a running \u201cdefault-kieserver\u201d with the \u201corder-management_1.1-SNAPSHOT\u201d container deployed. Our business project is now available to be consumed by client applications! Let's have a look at how we can consume this business application.","title":"Explore"},{"location":"guided_exercises/order_management/try-order-management-app/#experience","text":"The engine, KIE Server, is the service which exposes the business project and also the one we use when integrating with client applications. It comes with a Swagger UI that allows us to test the RESTful endpoints of the engine and consume rules deployed on it. Another way to consume our business project is to use Business Central UI to interact with the engine and test our business assets. For this hello world, let's use Business Central process and task management capabilities. In Business Central, let's open the Menu in the top bar and navigate to \"Process Definitions\" We can see three different process definitions. We'll start a new process instance based on the \"order-management\" process. Click on the actions kebab, and select \"Start\" The form that opened is also part of our business process and we can customize it if needed. For now, let's just fill in the data required to start our process instance, and click the \"Submit\" button. Item Name: Laptop Dell XPS 15 Urgency: Medium A new process instance will start in the engine. In order to visualize the current status, click on \"Diagram\". Notice we currently have a Human Task named \"Request Offer\" waiting for human intervention. Now, let's work on this task. In the Menu, access the \"Task Inbox\": In the list you should see a list of tasks you have permission to see and work on. Let's claim the Request Offer task to our user, and start working on it. Click on the kebab and select the \"Claim and Work\" option: You'll see the task data available for your analysis, as a knowledge worker - someone responsible for executing the task. Click on the blue \"Start\" button to start working on the task.Based on this offer, we'll define our reply. Inform the following data and click on the blue \"Complete\" button: Category : optional Target Price: 250 Suplier list: supplier 1 According to our process, a new task will be created for the suppliers. The supplier should provide an offer - so let's do it. Still on the task list, claim and work the task \"Prepare Offer\": Click \"Start\" blue button, inform any date, and the best offer as 1000 . Click on complete. At this point, the automatic approval was already taken, and our request was not automatically approved. You can confirm this by visualizing the process instance. On the kebab, select \"View Process\" You'll be redirected to the list of process instances. Select the process instance with id 1, and then, choose the \"Diagram\" option: At this point, you have learned how you manage processes and tasks using Business Central. You know how to start new process instances, how to interact with the process tasks and how to complete them. What about finishing this process by your own? Following the same idea, In Business Central, you can reprove the request, reject the order and reach the end of this process instance.","title":"Experience"},{"location":"guided_exercises/order_management/try-order-management-app/#conclusion","text":"Congratulations, you successfully concluded a Hello World in Red Hat Process Automation Manager. In this guide, we installed Red Hat PAM, imported a project directly from GitHub, checked out the a process definition modeled and an automation decision. We wrapped up our tutorial by deploying and testing our services using Business Central UI. If you want to know more about the Order Management demo, we recommend you take a look at the project's instructions at the github repository: https://github.com/jbossdemocentral/rhpam7-order-management-demo-repo.","title":"Conclusion"},{"location":"guided_exercises/pam_kafka/","text":"PAM + Kafka Workshop A set of guided labs to get you up started on how to: Running locally Have docker or podman running locally: docker run -it --rm -p 8080:8080 -v $(pwd):/app-data -e CONTENT_URL_PREFIX=\"file:///app-data\" -e WORKSHOPS_URLS=\"file:///app-data/_pam_kafka_workshop.yml\" -e LOG_TO_STDOUT=true quay.io/osevg/workshopper Running on ocp Login on ocp and: oc create -f support/ocp-provisioning.yml","title":"PAM + Kafka Workshop"},{"location":"guided_exercises/pam_kafka/#pam-kafka-workshop","text":"","title":"PAM + Kafka Workshop"},{"location":"guided_exercises/pam_kafka/#a-set-of-guided-labs-to-get-you-up-started-on-how-to","text":"","title":"A set of guided labs to get you up started on how to:"},{"location":"guided_exercises/pam_kafka/#running-locally","text":"Have docker or podman running locally: docker run -it --rm -p 8080:8080 -v $(pwd):/app-data -e CONTENT_URL_PREFIX=\"file:///app-data\" -e WORKSHOPS_URLS=\"file:///app-data/_pam_kafka_workshop.yml\" -e LOG_TO_STDOUT=true quay.io/osevg/workshopper","title":"Running locally"},{"location":"guided_exercises/pam_kafka/#running-on-ocp","text":"Login on ocp and: oc create -f support/ocp-provisioning.yml","title":"Running on ocp"},{"location":"guided_exercises/pam_kafka/auditing-events/","text":"Auditing with Kafka When using the Kafka extension in Red Hat Process Automation Manager, every transaction for processes, cases and tasks execution can be tracked via events. For each of these categories, we'll have an event emitted to a Kafka topic, in other words, we'll have three topics here: jbpm-processes-events , jbpm-tasks-events , jbpm-cases-events . To enable this feature, you need to add the jbpm-event-emitters-kafka library to the engine, KIE Server. This can either be downloaded in the community repository for jBPM or via the Red Hat customer portal: rhpam-7.10.0-maven-repository.zip . The maven repository have ~1.5GB. In order to facilitate the execution of this lab, you can download the jbpm-event-emmiters-kafka for PAM 7.10.0 here ; Stop Red Hat PAM. Download the jbpm-event-emitters-kafka . It's name will be similar to jbpm-event-emitters-kafka-7.x.x.Final-redhat-x.jar . Since this is a behavior only needed by the engine, place the library inside the kie-server.war folder, inside the WEB-INF directory. TIP: If you downloaded the maven repository zip file in the Red Hat Customer Portal, you can find the jar inside the folder maven-repository/org/jbpm/jbpm-event-emitters-kafka/7.48.0.Final-redhat-00004/jbpm-event-emitters-kafka-7.48.0.Final-redhat-00004.jar cp jbpm-event-emitters-kafka-7.48.0.Final-redhat-00004.jar $JBOSS_EAP/standalone/deployments/kie-server.war/WEB-INF/lib/ Next,start Red Hat PAM server. Let's check the auditing behavior. Testing the feature To check the auditing capabilities you can start new processes, interact with human tasks and track the events that are being published on the jbpm-tasks-events and jbpm-processes-events topics. The event tracking are active also for processes that doesn't use message events elements. In this example we will check the behavior for our event driven business application. Start a new process by emitting an event. Let's start a process that will not be automatically approved. In this way, we will also have a human task created. You can emit the following event to the incoming-requests topic: {\"data\" : {\"customerId\": 1, \"customerScore\":100, \"requestedValue\": 1200}} You should be able to see a new process instance can be seen in Business Central in the following status: You can use the kafka consumer CLI script to check the messages that were emitted on the topics: jbpm-processes-events and jbpm-tasks-events . You should be able to see an event like this published on the jbpm-process-events : ``` {\"specversion\":\"1.0\",\"time\":\"2021-04-15T10:00:05.609-0300\",\"id\":\"28e13bc0-1c92-42fd-8909-b48a206325d3\",\"type\":\"process\",\"source\":\"/process/cc-limit-approval-app.cc-limit-raise-approval-with-end-events/2\",\"data\":{\"compositeId\":\"default-kieserver_2\",\"id\":2,\"processId\":\"cc-limit-approval-app.cc-limit-raise-approval-with-end-events\",\"processName\":\"cc-limit-raise-approval-with-events\",\"processVersion\":\"1.0\",\"state\":1,\"containerId\":\"cc-limit-approval-app_1.0.0-SNAPSHOT\",\"initiator\":\"unknown\",\"date\":\"2021-04-15T10:00:05.608-0300\",\"processInstanceDescription\":\"cc-limit-raise-approval-with-events\",\"correlationKey\":\"2\",\"parentId\":-1,\"variables\":{\"request\":{\"customerId\":1,\"requestedValue\":1200,\"customerScore\":100,\"denyReason\":null},\"approval\":false,\"initiator\":\"unknown\"}}} ``` * You should be able to see an event like this published on the `jbpm-tasks-events`: {\"specversion\":\"1.0\",\"time\":\"2021-04-15T10:00:05.612-0300\",\"id\":\"2ac83d91-40d7-49f3-a114-2b72816a20a4\",\"type\":\"task\",\"source\":\"/process/cc-limit-approval-app.cc-limit-raise-approval-with-end-events/2\",\"data\":{\"compositeId\":\"default-kieserver_2\",\"id\":2,\"priority\":0,\"name\":\"Analyst validation\",\"subject\":\"\",\"description\":\"\",\"taskType\":null,\"formName\":\"Task\",\"status\":\"Ready\",\"actualOwner\":null,\"createdBy\":null,\"createdOn\":\"2021-04-15T10:00:05.590-0300\",\"activationTime\":\"2021-04-15T10:00:05.590-0300\",\"expirationDate\":null,\"skipable\":false,\"workItemId\":2,\"processInstanceId\":2,\"parentId\":-1,\"processId\":\"cc-limit-approval-app.cc-limit-raise-approval-with-end-events\",\"containerId\":\"cc-limit-approval-app_1.0.0-SNAPSHOT\",\"potentialOwners\":[\"kie-server\"],\"excludedOwners\":[],\"businessAdmins\":[\"Administrator\",\"Administrators\"],\"inputData\":{\"Skippable\":\"false\",\"request\":{\"customerId\":1,\"requestedValue\":1200,\"customerScore\":100,\"denyReason\":null},\"TaskName\":\"Task\",\"NodeName\":\"Analyst validation\",\"GroupId\":\"kie-server\"},\"outputData\":null}} Using Business Central, tnteract with the human task Analyst Validation , and check the events emitted on the jbpm-tasks-events . You should be able to see at every task change, a new event in the jbpm-tasks-events . Also, for every transaction commited for the process, you should see new events on the jbpm-process-events . By now, you have an event-driven process, that can be integrated within an event driven architecture, and furthermore, can be tracked and monitored in an asyncronous way by the usage of events. The complete project can be found at: https://github.com/kmacedovarela/cc-limit-approval-app","title":"Auditing through events"},{"location":"guided_exercises/pam_kafka/auditing-events/#auditing-with-kafka","text":"When using the Kafka extension in Red Hat Process Automation Manager, every transaction for processes, cases and tasks execution can be tracked via events. For each of these categories, we'll have an event emitted to a Kafka topic, in other words, we'll have three topics here: jbpm-processes-events , jbpm-tasks-events , jbpm-cases-events . To enable this feature, you need to add the jbpm-event-emitters-kafka library to the engine, KIE Server. This can either be downloaded in the community repository for jBPM or via the Red Hat customer portal: rhpam-7.10.0-maven-repository.zip . The maven repository have ~1.5GB. In order to facilitate the execution of this lab, you can download the jbpm-event-emmiters-kafka for PAM 7.10.0 here ; Stop Red Hat PAM. Download the jbpm-event-emitters-kafka . It's name will be similar to jbpm-event-emitters-kafka-7.x.x.Final-redhat-x.jar . Since this is a behavior only needed by the engine, place the library inside the kie-server.war folder, inside the WEB-INF directory. TIP: If you downloaded the maven repository zip file in the Red Hat Customer Portal, you can find the jar inside the folder maven-repository/org/jbpm/jbpm-event-emitters-kafka/7.48.0.Final-redhat-00004/jbpm-event-emitters-kafka-7.48.0.Final-redhat-00004.jar cp jbpm-event-emitters-kafka-7.48.0.Final-redhat-00004.jar $JBOSS_EAP/standalone/deployments/kie-server.war/WEB-INF/lib/ Next,start Red Hat PAM server. Let's check the auditing behavior.","title":"Auditing with Kafka"},{"location":"guided_exercises/pam_kafka/auditing-events/#testing-the-feature","text":"To check the auditing capabilities you can start new processes, interact with human tasks and track the events that are being published on the jbpm-tasks-events and jbpm-processes-events topics. The event tracking are active also for processes that doesn't use message events elements. In this example we will check the behavior for our event driven business application. Start a new process by emitting an event. Let's start a process that will not be automatically approved. In this way, we will also have a human task created. You can emit the following event to the incoming-requests topic: {\"data\" : {\"customerId\": 1, \"customerScore\":100, \"requestedValue\": 1200}} You should be able to see a new process instance can be seen in Business Central in the following status: You can use the kafka consumer CLI script to check the messages that were emitted on the topics: jbpm-processes-events and jbpm-tasks-events . You should be able to see an event like this published on the jbpm-process-events : ``` {\"specversion\":\"1.0\",\"time\":\"2021-04-15T10:00:05.609-0300\",\"id\":\"28e13bc0-1c92-42fd-8909-b48a206325d3\",\"type\":\"process\",\"source\":\"/process/cc-limit-approval-app.cc-limit-raise-approval-with-end-events/2\",\"data\":{\"compositeId\":\"default-kieserver_2\",\"id\":2,\"processId\":\"cc-limit-approval-app.cc-limit-raise-approval-with-end-events\",\"processName\":\"cc-limit-raise-approval-with-events\",\"processVersion\":\"1.0\",\"state\":1,\"containerId\":\"cc-limit-approval-app_1.0.0-SNAPSHOT\",\"initiator\":\"unknown\",\"date\":\"2021-04-15T10:00:05.608-0300\",\"processInstanceDescription\":\"cc-limit-raise-approval-with-events\",\"correlationKey\":\"2\",\"parentId\":-1,\"variables\":{\"request\":{\"customerId\":1,\"requestedValue\":1200,\"customerScore\":100,\"denyReason\":null},\"approval\":false,\"initiator\":\"unknown\"}}} ``` * You should be able to see an event like this published on the `jbpm-tasks-events`: {\"specversion\":\"1.0\",\"time\":\"2021-04-15T10:00:05.612-0300\",\"id\":\"2ac83d91-40d7-49f3-a114-2b72816a20a4\",\"type\":\"task\",\"source\":\"/process/cc-limit-approval-app.cc-limit-raise-approval-with-end-events/2\",\"data\":{\"compositeId\":\"default-kieserver_2\",\"id\":2,\"priority\":0,\"name\":\"Analyst validation\",\"subject\":\"\",\"description\":\"\",\"taskType\":null,\"formName\":\"Task\",\"status\":\"Ready\",\"actualOwner\":null,\"createdBy\":null,\"createdOn\":\"2021-04-15T10:00:05.590-0300\",\"activationTime\":\"2021-04-15T10:00:05.590-0300\",\"expirationDate\":null,\"skipable\":false,\"workItemId\":2,\"processInstanceId\":2,\"parentId\":-1,\"processId\":\"cc-limit-approval-app.cc-limit-raise-approval-with-end-events\",\"containerId\":\"cc-limit-approval-app_1.0.0-SNAPSHOT\",\"potentialOwners\":[\"kie-server\"],\"excludedOwners\":[],\"businessAdmins\":[\"Administrator\",\"Administrators\"],\"inputData\":{\"Skippable\":\"false\",\"request\":{\"customerId\":1,\"requestedValue\":1200,\"customerScore\":100,\"denyReason\":null},\"TaskName\":\"Task\",\"NodeName\":\"Analyst validation\",\"GroupId\":\"kie-server\"},\"outputData\":null}} Using Business Central, tnteract with the human task Analyst Validation , and check the events emitted on the jbpm-tasks-events . You should be able to see at every task change, a new event in the jbpm-tasks-events . Also, for every transaction commited for the process, you should see new events on the jbpm-process-events . By now, you have an event-driven process, that can be integrated within an event driven architecture, and furthermore, can be tracked and monitored in an asyncronous way by the usage of events. The complete project can be found at: https://github.com/kmacedovarela/cc-limit-approval-app","title":"Testing the feature"},{"location":"guided_exercises/pam_kafka/emitting-events/","text":"Emmitting Events from Business Processes In order to be able to finish processes based on new events, we will need to set up our environment. In this setup we will: Check the required configuration in the business project Add bpmn components to emit messages Emitting events in a business process Now, we need to End Message Events instead of two End Events . In Business Central, open the cc-limit-approval-app process. Convert the two End Events to End Message Events . It should look like this: Next, configure the Kafka topic name in the message name for both nodes as following: Raise Approved message name: requests-approved Raise Denied message name: requests-denied See below one of the nodes, the Raise Denied node configuration: Save the process definition. Configuring the business application In business central, navigate to the Project Settings -> Deployments -> Work Item handlers : Observe that there is a task configured named Send Task . In PAM 7.10 you need this configuration to be able to use any Message Events (ending and throwing) that would emit events. Consuming the events from Kafka topic using Kafka Consumer CLI In order to validate if our process is emitting processes as we expect, we need to listen to the Kafka topics requests-approved and requests-denied to validate if the messages were emitted correctly. Open a new terminal tab, and navigate to the Kafka project folder. $ cd ~/enablement/amq-examples/strimzi-all-in-one/ Start the Kafka command line tool that allows us to consume events that happen in a topic, and therefore, will allow us to know if RHPAM published the events when the process ended. The tool is kafka-console-consumer.sh . Let's check if the process emitted events on the topic requests-approved . $ docker-compose exec kafka bin/kafka-console-consumer.sh --topic requests-approved --from-beginning --bootstrap-server localhost:9092 Testing the solution To test the solution, we will start a new process instance that will start, be automatically approved, and end without any human interaction. A new process instance should get started whenever you publish a new event on the incoming-requests topic, and, when there is an automatic approval, the process will end and publish an event to the requests-approved topic. Let's see this in action: Like we did on the first lab, let's start a new process instance by publishing a message in the incoming-requests topic. If you canceled the execution of the kafka producer, here's how you can start it: docker-compose exec kafka bin/kafka-console-producer.sh --topic incoming-requests --bootstrap-server localhost:9092 You can use the following data in your event: {\"data\" : {\"customerId\": 1, \"customerScore\": 250, \"requestedValue\":1500}} Once you publish the event, a new process should get started. Now check the terminal where you are consuming the messages in the requests-approved topic. You should see a new event published by your process. The event will look like this: {\"specversion\":\"1.0\",\"time\":\"2021-04-14T18:04:42.532-0300\",\"id\":\"25ba2dd0-a8d0-4cfc-9ba4-d2e556ffb4d0\",\"type\":\"empty\",\"source\":\"/process/cc-limit-approval-app.cc-limit-raise-approval/5\",\"data\":null} Identify the process ID on the event above. In this example, the process instance that emitted this event was process of ID 5 . Let's check this same process instance in Business Central. In Business Central, open the Menu -> Manage -> Process Instances . On the left column, filter by \"Completed\" State. You should see as many instances as the number of events you published on Kafka. Identify your process instance ID. In this example, instance with id 5 . Select the process instance. Next, select the tab Diagram . You should see something like:","title":"Emitting Events in Processes"},{"location":"guided_exercises/pam_kafka/emitting-events/#emmitting-events-from-business-processes","text":"In order to be able to finish processes based on new events, we will need to set up our environment. In this setup we will: Check the required configuration in the business project Add bpmn components to emit messages","title":"Emmitting Events from Business Processes"},{"location":"guided_exercises/pam_kafka/emitting-events/#emitting-events-in-a-business-process","text":"Now, we need to End Message Events instead of two End Events . In Business Central, open the cc-limit-approval-app process. Convert the two End Events to End Message Events . It should look like this: Next, configure the Kafka topic name in the message name for both nodes as following: Raise Approved message name: requests-approved Raise Denied message name: requests-denied See below one of the nodes, the Raise Denied node configuration: Save the process definition.","title":"Emitting events in a business process"},{"location":"guided_exercises/pam_kafka/emitting-events/#configuring-the-business-application","text":"In business central, navigate to the Project Settings -> Deployments -> Work Item handlers : Observe that there is a task configured named Send Task . In PAM 7.10 you need this configuration to be able to use any Message Events (ending and throwing) that would emit events.","title":"Configuring the business application"},{"location":"guided_exercises/pam_kafka/emitting-events/#consuming-the-events-from-kafka-topic-using-kafka-consumer-cli","text":"In order to validate if our process is emitting processes as we expect, we need to listen to the Kafka topics requests-approved and requests-denied to validate if the messages were emitted correctly. Open a new terminal tab, and navigate to the Kafka project folder. $ cd ~/enablement/amq-examples/strimzi-all-in-one/ Start the Kafka command line tool that allows us to consume events that happen in a topic, and therefore, will allow us to know if RHPAM published the events when the process ended. The tool is kafka-console-consumer.sh . Let's check if the process emitted events on the topic requests-approved . $ docker-compose exec kafka bin/kafka-console-consumer.sh --topic requests-approved --from-beginning --bootstrap-server localhost:9092","title":"Consuming the events from Kafka topic using Kafka Consumer CLI"},{"location":"guided_exercises/pam_kafka/emitting-events/#testing-the-solution","text":"To test the solution, we will start a new process instance that will start, be automatically approved, and end without any human interaction. A new process instance should get started whenever you publish a new event on the incoming-requests topic, and, when there is an automatic approval, the process will end and publish an event to the requests-approved topic. Let's see this in action: Like we did on the first lab, let's start a new process instance by publishing a message in the incoming-requests topic. If you canceled the execution of the kafka producer, here's how you can start it: docker-compose exec kafka bin/kafka-console-producer.sh --topic incoming-requests --bootstrap-server localhost:9092 You can use the following data in your event: {\"data\" : {\"customerId\": 1, \"customerScore\": 250, \"requestedValue\":1500}} Once you publish the event, a new process should get started. Now check the terminal where you are consuming the messages in the requests-approved topic. You should see a new event published by your process. The event will look like this: {\"specversion\":\"1.0\",\"time\":\"2021-04-14T18:04:42.532-0300\",\"id\":\"25ba2dd0-a8d0-4cfc-9ba4-d2e556ffb4d0\",\"type\":\"empty\",\"source\":\"/process/cc-limit-approval-app.cc-limit-raise-approval/5\",\"data\":null} Identify the process ID on the event above. In this example, the process instance that emitted this event was process of ID 5 . Let's check this same process instance in Business Central. In Business Central, open the Menu -> Manage -> Process Instances . On the left column, filter by \"Completed\" State. You should see as many instances as the number of events you published on Kafka. Identify your process instance ID. In this example, instance with id 5 . Select the process instance. Next, select the tab Diagram . You should see something like:","title":"Testing the solution"},{"location":"guided_exercises/pam_kafka/env-setup/","text":"Environment Setup Red Hat Process Automation Manager In order to follow these guided labs, you should have RHPAM 7.9+ in your local environment. If you need to setup PAM locally, you can use this repository to help you get up and running quickly: Red Hat PAM Install Demo Kafka Event-driven processes can react to the events that happens in the ecosystem. Kafka is an open-source even streaming platform, and currently, one of the most popular tools. In this type of architecture, we have the Kafka topics used as the communication layer in between the services. Each service can now be considered a consumer or a producer , in other words, each service can publish or consume events to/from the topics . Red Hat supports the integration between RHPAM and AMQ Streams (Kafka). To follow the labs, you should have an accessible Kafka server. The KIE Server (process engine) will communicate with the topics that we will create in the Kafka server. If you don't have an environment available you can get a Kafka (Strimzi) server quickly running by using Docker. Let's clone the project to the enablement folder. Create a new folder named enablement and access it: $ mkdir ~/enablement && cd ~/enablement Clone this repository to your local machine. $ git clone https://github.com/hguerrero/amq-examples The docker-compose file available in this quickstart should bootstrap everything you need to have your Strimzi up and running: Zookeeper, Kafka server v2.5.0, Apicurio Registry and a Kafka Bridge. Access the amq-examples/strimzi-all-in-one/ folder: $ cd amq-examples/strimzi-all-in-one/ Start the Kafka environment: docker-compose up Docker will download the images and start the services for you. You now have a Kafka server running on localhost port 9092. Creating the Kafka topics In the upcoming labs we will need three topics: incoming-requests , requests-approved and requests-denied . Next, you need to create these topics in your Kafka server. If you are using the containerized option mentioned in this lab, you can create the topics using the kafka-topics.sh available in the kafka container. Open a new terminal and let's using the kafka container we have just started. Enter the Kafka folder: $ cd ~/enablement/amq-examples/strimzi-all-in-one/ Create the following three topics: $ docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic incoming-requests $ docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic requests-approved $ docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic requests-denied Next steps At this point you should have Red Hat PAM, and Kafka on your environment. Before proceeding to the next steps, make sure you have Red Hat PAM and Kafka server up and running.","title":"Environment Setup"},{"location":"guided_exercises/pam_kafka/env-setup/#environment-setup","text":"Red Hat Process Automation Manager In order to follow these guided labs, you should have RHPAM 7.9+ in your local environment. If you need to setup PAM locally, you can use this repository to help you get up and running quickly: Red Hat PAM Install Demo Kafka Event-driven processes can react to the events that happens in the ecosystem. Kafka is an open-source even streaming platform, and currently, one of the most popular tools. In this type of architecture, we have the Kafka topics used as the communication layer in between the services. Each service can now be considered a consumer or a producer , in other words, each service can publish or consume events to/from the topics . Red Hat supports the integration between RHPAM and AMQ Streams (Kafka). To follow the labs, you should have an accessible Kafka server. The KIE Server (process engine) will communicate with the topics that we will create in the Kafka server. If you don't have an environment available you can get a Kafka (Strimzi) server quickly running by using Docker. Let's clone the project to the enablement folder. Create a new folder named enablement and access it: $ mkdir ~/enablement && cd ~/enablement Clone this repository to your local machine. $ git clone https://github.com/hguerrero/amq-examples The docker-compose file available in this quickstart should bootstrap everything you need to have your Strimzi up and running: Zookeeper, Kafka server v2.5.0, Apicurio Registry and a Kafka Bridge. Access the amq-examples/strimzi-all-in-one/ folder: $ cd amq-examples/strimzi-all-in-one/ Start the Kafka environment: docker-compose up Docker will download the images and start the services for you. You now have a Kafka server running on localhost port 9092. Creating the Kafka topics In the upcoming labs we will need three topics: incoming-requests , requests-approved and requests-denied . Next, you need to create these topics in your Kafka server. If you are using the containerized option mentioned in this lab, you can create the topics using the kafka-topics.sh available in the kafka container. Open a new terminal and let's using the kafka container we have just started. Enter the Kafka folder: $ cd ~/enablement/amq-examples/strimzi-all-in-one/ Create the following three topics: $ docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic incoming-requests $ docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic requests-approved $ docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic requests-denied","title":"Environment Setup"},{"location":"guided_exercises/pam_kafka/env-setup/#next-steps","text":"At this point you should have Red Hat PAM, and Kafka on your environment. Before proceeding to the next steps, make sure you have Red Hat PAM and Kafka server up and running.","title":"Next steps"},{"location":"guided_exercises/pam_kafka/introduction/","text":"Introduction In this guided lab let\u2019s see in practice how we can use process automation applications that fits within event-driven architectures. We can list at least three ways to adjust our business application fit within EDA: We can build processes that can react to events that happen in the ecosystem; From within the process, we can emit events to notify the ecosystem about key activities in the business process and interact with external services via events; We can track every transaction committed either for business processes, cases (case management), or human tasks by publishing events for. The alignment of tech evolution and business standards like BMPN When providing an implementation for a specification, each provider has the opportunity to deliver the solution of choice. It is not different for the BPMN specification. It allows different implementations for its diagram elements, and this is how RHPAM delivers the most recent tech concepts by still allowing business users to use the modeling notation they are used to. In RHPAM (a.k.a. jBPM), it is possible to make use of message events (starting, intermediate or ending) to interact via events. In this case, the KIE Server Kafka extension makes sure the communication occurs effectively with the event streaming brokers. In the upcoming labs we will learn how to model the processes and when and how to add configurations to the business project and KIE Server.","title":"Introduction"},{"location":"guided_exercises/pam_kafka/introduction/#introduction","text":"In this guided lab let\u2019s see in practice how we can use process automation applications that fits within event-driven architectures. We can list at least three ways to adjust our business application fit within EDA: We can build processes that can react to events that happen in the ecosystem; From within the process, we can emit events to notify the ecosystem about key activities in the business process and interact with external services via events; We can track every transaction committed either for business processes, cases (case management), or human tasks by publishing events for. The alignment of tech evolution and business standards like BMPN When providing an implementation for a specification, each provider has the opportunity to deliver the solution of choice. It is not different for the BPMN specification. It allows different implementations for its diagram elements, and this is how RHPAM delivers the most recent tech concepts by still allowing business users to use the modeling notation they are used to. In RHPAM (a.k.a. jBPM), it is possible to make use of message events (starting, intermediate or ending) to interact via events. In this case, the KIE Server Kafka extension makes sure the communication occurs effectively with the event streaming brokers. In the upcoming labs we will learn how to model the processes and when and how to add configurations to the business project and KIE Server.","title":"Introduction"},{"location":"guided_exercises/pam_kafka/lab-one-setup/","text":"Red Hat PAM Kafka extension In order to be able to start processes based on new events, we will need to configure the Red Hat PAM Kafka extension. The Red Hat PAM Kafka extension allows the KIE Server (process and decision engine) to react to events and publish events to kafka topics. INFO: There are several options in PAM to customize the Kafka address, topic names, etc. In our case, we\u2019re using the default Kafka address, which is, localhost:9092. More customization information can be found in the official Red Hat product documentation: Configuring a KIE Server to send and receive Kafka messages from the process. In this setup steps, we will configure PAM only in the server level - we are not yet configuring the business project . We will see how to configure the project as we move forward on the labs. Enabling the Kafka extension We can configure the engine to support different capabilities. In order to enable processes to be started through eventing, we only need to enable the extension via system property. With PAM up and running, execute: $JBOSS_HOME/bin/jboss-cli.sh -c [standalone@localhost:9990 /] /system-property=org.kie.kafka.server.ext.disabled:add(value=false) [standalone@localhost:9990 /] :shutdown(restart=true) The first command will enable the Kafka extension. Next, we're reestarting EAP so that the new configuration is active. You can check EAP logs to confirm it is restarting. The following output will show up in PAM logs: INFO [org.kie.server.services.impl.KieServerImpl] (ServerService Thread Pool -- 74) Kafka KIE Server extension has been successfully registered as server extension This is the only configuration you will need in a server level to be able to start processes using events.","title":"Setup - Starting Processes with Events"},{"location":"guided_exercises/pam_kafka/lab-one-setup/#red-hat-pam-kafka-extension","text":"In order to be able to start processes based on new events, we will need to configure the Red Hat PAM Kafka extension. The Red Hat PAM Kafka extension allows the KIE Server (process and decision engine) to react to events and publish events to kafka topics. INFO: There are several options in PAM to customize the Kafka address, topic names, etc. In our case, we\u2019re using the default Kafka address, which is, localhost:9092. More customization information can be found in the official Red Hat product documentation: Configuring a KIE Server to send and receive Kafka messages from the process. In this setup steps, we will configure PAM only in the server level - we are not yet configuring the business project . We will see how to configure the project as we move forward on the labs.","title":"Red Hat PAM Kafka extension"},{"location":"guided_exercises/pam_kafka/lab-one-setup/#enabling-the-kafka-extension","text":"We can configure the engine to support different capabilities. In order to enable processes to be started through eventing, we only need to enable the extension via system property. With PAM up and running, execute: $JBOSS_HOME/bin/jboss-cli.sh -c [standalone@localhost:9990 /] /system-property=org.kie.kafka.server.ext.disabled:add(value=false) [standalone@localhost:9990 /] :shutdown(restart=true) The first command will enable the Kafka extension. Next, we're reestarting EAP so that the new configuration is active. You can check EAP logs to confirm it is restarting. The following output will show up in PAM logs: INFO [org.kie.server.services.impl.KieServerImpl] (ServerService Thread Pool -- 74) Kafka KIE Server extension has been successfully registered as server extension This is the only configuration you will need in a server level to be able to start processes using events.","title":"Enabling the Kafka extension"},{"location":"guided_exercises/pam_kafka/start-event/","text":"The Credit Card Raise Approval Project In this use case we should handle the automation of a credit card limit raise approval process. Most card issuers allow customers to request an increased credit limit through their websites, mobile apps or over the phone. Let\u2019s consider we need to deliver this automation for a bank that wants to achieve a similar use case within an event-driven architecture. The existing process is started via REST. It has a step for automatic request validation using DMN, and if the request not approved, it goes to a manual analysis. If approved, the service responsible for updating the cc limit is invoked via REST (the diagram only represents this REST call with a script task since this is not relevant for this lab's scenario). Finally, the process ends either with an approved or denied request. Now, with the architecture shift, the service responsible for increasing the credit card limit should not be invoked via REST anymore. The external service now listens to the topic \u201crequest-approved\u201d in order to track when to execute the limit raise. The business process should get started based on events, and whenever the process finishes, it should post a message to a specific topic depending on whether the request was approved or not. Process v2. Whenever a new event happens in a topic, a new instance will be triggered. Depending on how this process ends, an event is published in a different topic, therefore, different services can react based on the approval status In this strategy we have a resilient way of communication between services where the broker is responsible for storing and providing the events. Adding to that, the tech team can evolve the solutions by using the features available in Kafka itself, like the possibility to replay all the events that happened in a specific time, in chronological order. Importing the project Let's import the existing project so we can start implementing the eventing capabilities. Access business central, and import the following project: https://github.com/kmacedovarela/cc-limit-approval-app-step1 Let's check the existing project. Open the cc-limit-raise-approval process. Notice it is a traditional process. Processes like this can be started either via REST or JMS. Reacting to events The first task we'll do, is to enable the existing process to react to events that are published in a specific topic. Whenever a new event is published, a new process instance should be created. To allow this process definition to be started with events, the first step is to change the start event to a start message event : Whenever a customer make a new request (independently of the channel used) an event should be published on the incoming-requests Kafka topic . With that, a new process instance should be started whenever a new event is published in this topic. Let's configure the start message event : Important: we need to receive the data that is the event data. The KIE Server provides automatic marshalling to help us mapping the input directly to a Data Object (a POJO). This project has an object named LimitRaiseRequest.java which we will use to receive the incoming data. On the properties panel of the Start Message Event , configure the input data: Name: request Data Type: LimitRaiseRequest Target: request Save the process. Your process should now look like this: Deploying the project Now, let's deploy and test the project. On the breadcrumb, click on \"cc-limit-approval-app-step1\" to go back to the Project Explorer view. Click on the \"Deploy\" button. Testing the project Let's publish a new event in the incoming-requests topic using the Kafka producer CLI tool. Open a new tab in your terminal and access the strimzi-all-in-one project folder. $ cd ~/enablement/amq-examples/strimzi-all-in-one Next, use the Kafka producer to publish new messages on the topic incoming-requests . $ docker-compose exec kafka bin/kafka-console-producer.sh --topic incoming-requests --bootstrap-server localhost:9092 You can send the following data, and press enter: {\"data\" : {\"customerId\": 1, \"customerScore\": 250, \"requestedValue\":1500}} Back to the browser, open Business Central. On the top menu, go to Menu -> Manage -> Process Instances . On the left column, filter by \"Completed\" State. You should see as many instances as the number of events you published on Kafka: Select a process instance, and next, select the tab Diagram . You should see something like:","title":"Starting Processes with Events"},{"location":"guided_exercises/pam_kafka/start-event/#the-credit-card-raise-approval-project","text":"In this use case we should handle the automation of a credit card limit raise approval process. Most card issuers allow customers to request an increased credit limit through their websites, mobile apps or over the phone. Let\u2019s consider we need to deliver this automation for a bank that wants to achieve a similar use case within an event-driven architecture. The existing process is started via REST. It has a step for automatic request validation using DMN, and if the request not approved, it goes to a manual analysis. If approved, the service responsible for updating the cc limit is invoked via REST (the diagram only represents this REST call with a script task since this is not relevant for this lab's scenario). Finally, the process ends either with an approved or denied request. Now, with the architecture shift, the service responsible for increasing the credit card limit should not be invoked via REST anymore. The external service now listens to the topic \u201crequest-approved\u201d in order to track when to execute the limit raise. The business process should get started based on events, and whenever the process finishes, it should post a message to a specific topic depending on whether the request was approved or not. Process v2. Whenever a new event happens in a topic, a new instance will be triggered. Depending on how this process ends, an event is published in a different topic, therefore, different services can react based on the approval status In this strategy we have a resilient way of communication between services where the broker is responsible for storing and providing the events. Adding to that, the tech team can evolve the solutions by using the features available in Kafka itself, like the possibility to replay all the events that happened in a specific time, in chronological order.","title":"The Credit Card Raise Approval Project"},{"location":"guided_exercises/pam_kafka/start-event/#importing-the-project","text":"Let's import the existing project so we can start implementing the eventing capabilities. Access business central, and import the following project: https://github.com/kmacedovarela/cc-limit-approval-app-step1 Let's check the existing project. Open the cc-limit-raise-approval process. Notice it is a traditional process. Processes like this can be started either via REST or JMS.","title":"Importing the project"},{"location":"guided_exercises/pam_kafka/start-event/#reacting-to-events","text":"The first task we'll do, is to enable the existing process to react to events that are published in a specific topic. Whenever a new event is published, a new process instance should be created. To allow this process definition to be started with events, the first step is to change the start event to a start message event : Whenever a customer make a new request (independently of the channel used) an event should be published on the incoming-requests Kafka topic . With that, a new process instance should be started whenever a new event is published in this topic. Let's configure the start message event : Important: we need to receive the data that is the event data. The KIE Server provides automatic marshalling to help us mapping the input directly to a Data Object (a POJO). This project has an object named LimitRaiseRequest.java which we will use to receive the incoming data. On the properties panel of the Start Message Event , configure the input data: Name: request Data Type: LimitRaiseRequest Target: request Save the process. Your process should now look like this:","title":"Reacting to events"},{"location":"guided_exercises/pam_kafka/start-event/#deploying-the-project","text":"Now, let's deploy and test the project. On the breadcrumb, click on \"cc-limit-approval-app-step1\" to go back to the Project Explorer view. Click on the \"Deploy\" button.","title":"Deploying the project"},{"location":"guided_exercises/pam_kafka/start-event/#testing-the-project","text":"Let's publish a new event in the incoming-requests topic using the Kafka producer CLI tool. Open a new tab in your terminal and access the strimzi-all-in-one project folder. $ cd ~/enablement/amq-examples/strimzi-all-in-one Next, use the Kafka producer to publish new messages on the topic incoming-requests . $ docker-compose exec kafka bin/kafka-console-producer.sh --topic incoming-requests --bootstrap-server localhost:9092 You can send the following data, and press enter: {\"data\" : {\"customerId\": 1, \"customerScore\": 250, \"requestedValue\":1500}} Back to the browser, open Business Central. On the top menu, go to Menu -> Manage -> Process Instances . On the left column, filter by \"Completed\" State. You should see as many instances as the number of events you published on Kafka: Select a process instance, and next, select the tab Diagram . You should see something like:","title":"Testing the project"},{"location":"guided_exercises/tools/authoring-decisions/","text":"Authoring a Decision Let's author a simple decision and test it. The use case we'll try out is the automation of a repeated decision for requests approval. Create a new Decision In the project we've just created: Select the folder where you want to create the new file. Click on resources . Next, click on the new folder icon: Name the file automated-request-approval.dmn and press enter. The file should open in the DMN Editor. Create the following DMN: This DRD contains: A decision node Approval of type boolean ; Two inputs: A request type , which is string A request price , that is a number . Implement the following decision table, in the decision node: Save the diagram Testing the decision Before deploying the decision service in KIE Server, let's do some unit testing using the Test Scenario Simulation tooling. Configuring the project In order to use test scenarios, you need to add at least three dependencies to your project: junit:junit org.drools:drools-scenario-simulation-backend org.drools:drools-scenario-simulation-api Open the pom.xml file and add the following dependencies: <dependencies> <dependency> <groupId>org.drools</groupId> <artifactId>drools-scenario-simulation-api</artifactId> <version>${version.org.kie}</version> <scope>test</scope> </dependency> <dependency> <groupId>org.drools</groupId> <artifactId>drools-scenario-simulation-backend</artifactId> <version>${version.org.kie}</version> <scope>test</scope> </dependency> <dependency> <groupId>junit</groupId> <artifactId>junit</artifactId> <version>4.12</version> <scope>test</scope> </dependency> </dependencies> Adding the JUnit Runner In this scenario, the version.org.kie should be compatible with the product version you want to use. In this scenario, we are using RHPAM 7.10, which would be <version.org.kie>7.48.0.Final-redhat-00006</version.org.kie> . Create a new folder testscenario: /src/test/java/testscenario In the folder you just created, add a file and name it ScenarioJunitActivatorTest.java In this class, you should add a the Scenario Activator. This class allows the test scenarios to run along with the junit tests. package testscenario; /** * Do not remove this file */ @org.junit.runner.RunWith(org.drools.scenariosimulation.backend.runner.ScenarioJunitActivator.class) public class ScenarioJunitActivatorTest { } It should look like this: Creating the test scenario On the folder src/test/resources/org/kie/businessapp create a new file named ValidateAutomaticDecision.scesim . The editor should open up with the option to choose the Source type . This is the type of rule you want to test. Select DMN, next, choose your DMN file and click on the create button. The tool will already bring the inputs and expected result columns based on your DMN. Now, implement the following test: Runing the tests You can run the tests in two ways: using maven or the JUnit activator class. To run the test with maven you can for example run: mvn test If you want to run the tests using the activator class: Right click the ScenarioJunitActivatorTest.java file and select Run Java : The execution results should show up: Try changing the line one expected result from true to false . Click on the re-run button to see the results. Finally, adjust the tests and make sure that your project can compile when you run: mvn clean install Next Steps Now it's time to deploy our project to KIE Server and test it out.","title":"Authoring and testing decisions"},{"location":"guided_exercises/tools/authoring-decisions/#authoring-a-decision","text":"Let's author a simple decision and test it. The use case we'll try out is the automation of a repeated decision for requests approval.","title":"Authoring a Decision"},{"location":"guided_exercises/tools/authoring-decisions/#create-a-new-decision","text":"In the project we've just created: Select the folder where you want to create the new file. Click on resources . Next, click on the new folder icon: Name the file automated-request-approval.dmn and press enter. The file should open in the DMN Editor. Create the following DMN: This DRD contains: A decision node Approval of type boolean ; Two inputs: A request type , which is string A request price , that is a number . Implement the following decision table, in the decision node: Save the diagram","title":"Create a new Decision"},{"location":"guided_exercises/tools/authoring-decisions/#testing-the-decision","text":"Before deploying the decision service in KIE Server, let's do some unit testing using the Test Scenario Simulation tooling.","title":"Testing the decision"},{"location":"guided_exercises/tools/authoring-decisions/#configuring-the-project","text":"In order to use test scenarios, you need to add at least three dependencies to your project: junit:junit org.drools:drools-scenario-simulation-backend org.drools:drools-scenario-simulation-api Open the pom.xml file and add the following dependencies: <dependencies> <dependency> <groupId>org.drools</groupId> <artifactId>drools-scenario-simulation-api</artifactId> <version>${version.org.kie}</version> <scope>test</scope> </dependency> <dependency> <groupId>org.drools</groupId> <artifactId>drools-scenario-simulation-backend</artifactId> <version>${version.org.kie}</version> <scope>test</scope> </dependency> <dependency> <groupId>junit</groupId> <artifactId>junit</artifactId> <version>4.12</version> <scope>test</scope> </dependency> </dependencies>","title":"Configuring the project"},{"location":"guided_exercises/tools/authoring-decisions/#adding-the-junit-runner","text":"In this scenario, the version.org.kie should be compatible with the product version you want to use. In this scenario, we are using RHPAM 7.10, which would be <version.org.kie>7.48.0.Final-redhat-00006</version.org.kie> . Create a new folder testscenario: /src/test/java/testscenario In the folder you just created, add a file and name it ScenarioJunitActivatorTest.java In this class, you should add a the Scenario Activator. This class allows the test scenarios to run along with the junit tests. package testscenario; /** * Do not remove this file */ @org.junit.runner.RunWith(org.drools.scenariosimulation.backend.runner.ScenarioJunitActivator.class) public class ScenarioJunitActivatorTest { } It should look like this:","title":"Adding the JUnit Runner"},{"location":"guided_exercises/tools/authoring-decisions/#creating-the-test-scenario","text":"On the folder src/test/resources/org/kie/businessapp create a new file named ValidateAutomaticDecision.scesim . The editor should open up with the option to choose the Source type . This is the type of rule you want to test. Select DMN, next, choose your DMN file and click on the create button. The tool will already bring the inputs and expected result columns based on your DMN. Now, implement the following test:","title":"Creating the test scenario"},{"location":"guided_exercises/tools/authoring-decisions/#runing-the-tests","text":"You can run the tests in two ways: using maven or the JUnit activator class. To run the test with maven you can for example run: mvn test If you want to run the tests using the activator class: Right click the ScenarioJunitActivatorTest.java file and select Run Java : The execution results should show up: Try changing the line one expected result from true to false . Click on the re-run button to see the results. Finally, adjust the tests and make sure that your project can compile when you run: mvn clean install","title":"Runing the tests"},{"location":"guided_exercises/tools/authoring-decisions/#next-steps","text":"Now it's time to deploy our project to KIE Server and test it out.","title":"Next Steps"},{"location":"guided_exercises/tools/deploying-project/","text":"Deploying the project in KIE Server It's time to deploy our business application in KIE Server. Deployment We can deploy the project directly in KIE Server without the need to use Business Central. To do so, we can use the available REST API. Open KIE Server REST API. (i.e. http://localhost:8080/kie-server/docs) Under \u201cKIE Server and KIE container\" category select the following: PUT /server/containers/{containerId} Creates a new KIE container in the KIE Server with a specified KIE container ID Click on \"Try it out\" Insert your project details. The GAV can be found for example, in your pom.xml . See an example: containerId : mybusinessapp body : {\"container-id\" : \"mybusinessapp\", \"release-id\" : { \"group-id\" : \"org.kie.businessapp\", \"artifact-id\" : \"mybusinessapp\", \"version\" : \"1.0\" } } Click on the blue button \"Execute\". You should get a 201 result as follows: Testing the Automated Approval Decision Now, using the KIE server REST API, we'll consume the decision we've just deployed. Under the section DMN Models locate: POST /server/containers/{containerId}/dmn Evaluates decisions for given input Click on try it out Use the following data: ContainerID : mybusinessapp Body: { \"dmn-context\": { \"request type\": \"urgent\", \"request price\": \"250\" } } Extra Lab: Business Central Finally, you can import this project in Business Central. In order to do so, this needs to be a git-based project and Business Central needs to have access to the git repository where the project is stored. The following steps consider a local environment scenario. Access your application folder in the terminal. Initialize the git repository and do the first commit git init git add -A git commit -m \"first commit\" With this you can already import the project in Business Central. Open business central and select the import the project option. In the pop-up, in the Repository URL field, you should insert the git repository. If it is on your local machine you can inform something like: /$PROJECT_DIR/tooling-labs/mybusinessapp . Confirm the operation. You should see the project. Select it and click the Ok button. Feel free to explore the project and validate the test scenario and deployment through business central.","title":"Deploying and consuming services"},{"location":"guided_exercises/tools/deploying-project/#deploying-the-project-in-kie-server","text":"It's time to deploy our business application in KIE Server.","title":"Deploying the project in KIE Server"},{"location":"guided_exercises/tools/deploying-project/#deployment","text":"We can deploy the project directly in KIE Server without the need to use Business Central. To do so, we can use the available REST API. Open KIE Server REST API. (i.e. http://localhost:8080/kie-server/docs) Under \u201cKIE Server and KIE container\" category select the following: PUT /server/containers/{containerId} Creates a new KIE container in the KIE Server with a specified KIE container ID Click on \"Try it out\" Insert your project details. The GAV can be found for example, in your pom.xml . See an example: containerId : mybusinessapp body : {\"container-id\" : \"mybusinessapp\", \"release-id\" : { \"group-id\" : \"org.kie.businessapp\", \"artifact-id\" : \"mybusinessapp\", \"version\" : \"1.0\" } } Click on the blue button \"Execute\". You should get a 201 result as follows:","title":"Deployment"},{"location":"guided_exercises/tools/deploying-project/#testing-the-automated-approval-decision","text":"Now, using the KIE server REST API, we'll consume the decision we've just deployed. Under the section DMN Models locate: POST /server/containers/{containerId}/dmn Evaluates decisions for given input Click on try it out Use the following data: ContainerID : mybusinessapp Body: { \"dmn-context\": { \"request type\": \"urgent\", \"request price\": \"250\" } }","title":"Testing the Automated Approval Decision"},{"location":"guided_exercises/tools/deploying-project/#extra-lab-business-central","text":"Finally, you can import this project in Business Central. In order to do so, this needs to be a git-based project and Business Central needs to have access to the git repository where the project is stored. The following steps consider a local environment scenario. Access your application folder in the terminal. Initialize the git repository and do the first commit git init git add -A git commit -m \"first commit\" With this you can already import the project in Business Central. Open business central and select the import the project option. In the pop-up, in the Repository URL field, you should insert the git repository. If it is on your local machine you can inform something like: /$PROJECT_DIR/tooling-labs/mybusinessapp . Confirm the operation. You should see the project. Select it and click the Ok button. Feel free to explore the project and validate the test scenario and deployment through business central.","title":"Extra Lab: Business Central"},{"location":"guided_exercises/tools/getting-started/","text":"Business Automation projects in VSCode To start working with business automation projects in VSCode, you'll need to install the VSCode Extension that allows you to work with BPMN, DMN and Test Scenarios through graphical editors. Installing the VSCode extension To install the extension in VSCode, open the extensions menu, and search for Business Automation. You should find the Red Hat Business Automation Bundle. Click on install. If this is the first time you are using VSCode, it would be interesting to also install the code command in path, so that you can open projects directly from the terminal. To do so, press cmd+shift+p (or ctrl+shift+p ) to launch VSCode Quick Open menu. And next, search for Instal code command in PATH : Create new a project Let's create a new project using the maven archetype. This project should contain the structure and files that Business Central expects, so this project should be editable and authored in both VScode and Business Central. Now we will use the terminal. You can either use your terminal or use the built-in terminal In VScode. To use the terminal in VSCode you can press cmd+shift+p (or ctrl+shift+p ) to launch VSCode Quick Open menu. And next, open a new intergrated terminal : Next, in the terminal navigate to the directory where you would like to create the new project. Let's call it $PROJECT_DIR from now on. Create a new folder named tooling-labs . $ cd $PROJECT_DIR $ mkdir tooling-labs $ cd tooling-labs Now, use the maven archetype to create a new project in the tooling-labs directory: mvn archetype:generate \\ -DarchetypeGroupId=org.kie \\ -DarchetypeArtifactId=kie-kjar-archetype \\ -DarchetypeVersion=7.48.0.Final-redhat-00004 TIP: If you need to create a case project, you can use the parameter -DcaseProject=true . Maven will download the libraries, and once it finishes, it will confirm if you want to create the project using the default GAV (group:artifact:version). Type \"Y\" and press enter. You should get a new project named mybusinessapp . If you are in VSCode built-in terminal, you can open the project with: $ code -r mybusinessapp/ In VSCode, navigate through the project structure and confirm that it has a kie-deployment-descriptor.xml and a kmodule.xml . These are the files that Business Central needs to understand that this is a business project that should be packaged in a kjar. These files are also needed by KIE Server. Next Steps Now, let's author a DMN file, test it and deploy it to KIE Server.","title":"Getting Started"},{"location":"guided_exercises/tools/getting-started/#business-automation-projects-in-vscode","text":"To start working with business automation projects in VSCode, you'll need to install the VSCode Extension that allows you to work with BPMN, DMN and Test Scenarios through graphical editors.","title":"Business Automation projects in VSCode"},{"location":"guided_exercises/tools/getting-started/#installing-the-vscode-extension","text":"To install the extension in VSCode, open the extensions menu, and search for Business Automation. You should find the Red Hat Business Automation Bundle. Click on install. If this is the first time you are using VSCode, it would be interesting to also install the code command in path, so that you can open projects directly from the terminal. To do so, press cmd+shift+p (or ctrl+shift+p ) to launch VSCode Quick Open menu. And next, search for Instal code command in PATH :","title":"Installing the VSCode extension"},{"location":"guided_exercises/tools/getting-started/#create-new-a-project","text":"Let's create a new project using the maven archetype. This project should contain the structure and files that Business Central expects, so this project should be editable and authored in both VScode and Business Central. Now we will use the terminal. You can either use your terminal or use the built-in terminal In VScode. To use the terminal in VSCode you can press cmd+shift+p (or ctrl+shift+p ) to launch VSCode Quick Open menu. And next, open a new intergrated terminal : Next, in the terminal navigate to the directory where you would like to create the new project. Let's call it $PROJECT_DIR from now on. Create a new folder named tooling-labs . $ cd $PROJECT_DIR $ mkdir tooling-labs $ cd tooling-labs Now, use the maven archetype to create a new project in the tooling-labs directory: mvn archetype:generate \\ -DarchetypeGroupId=org.kie \\ -DarchetypeArtifactId=kie-kjar-archetype \\ -DarchetypeVersion=7.48.0.Final-redhat-00004 TIP: If you need to create a case project, you can use the parameter -DcaseProject=true . Maven will download the libraries, and once it finishes, it will confirm if you want to create the project using the default GAV (group:artifact:version). Type \"Y\" and press enter. You should get a new project named mybusinessapp . If you are in VSCode built-in terminal, you can open the project with: $ code -r mybusinessapp/ In VSCode, navigate through the project structure and confirm that it has a kie-deployment-descriptor.xml and a kmodule.xml . These are the files that Business Central needs to understand that this is a business project that should be packaged in a kjar. These files are also needed by KIE Server.","title":"Create new a project"},{"location":"guided_exercises/tools/getting-started/#next-steps","text":"Now, let's author a DMN file, test it and deploy it to KIE Server.","title":"Next Steps"},{"location":"guided_exercises/tools/introduction/","text":"Introduction This is a series of guided exercises that will allow you to experiment the authoring tools in VSCode and deployment in RHPAM engine, KIE Server. Tooling Set In Red Hat PAM and DM you can author decisions using: Business Central (in RHPAM) or Decision Central (in RHDM) A more business friendly UI; Business Automation VSCode Extension A developer IDE ( Visual Studio Code ) extension that allows the visualization and editing of BPMN, DMN and Test Scenarios inside VSCode. There is also a set of community tooling that's also available for use. All the tools below are backed by Red Hat: Learn DMN in 15 minutes A guided tour in a website through the elements of DMN GitHub Chrome Extension A browser extension that allows you to visualize and edit BPMN, DMN and Test Scenario files directly in GitHub. Online Editors BPMN.new - A free online editor for business processes; DMN.new - A free online editor for decision models; PMML.new - A free online editor for scorecards; Business Modeler Hub Allows for the download of the: VSCode extension, GitHub Chrome Extension, and Desktop App","title":"Introduction"},{"location":"guided_exercises/tools/introduction/#introduction","text":"This is a series of guided exercises that will allow you to experiment the authoring tools in VSCode and deployment in RHPAM engine, KIE Server.","title":"Introduction"},{"location":"guided_exercises/tools/introduction/#tooling-set","text":"In Red Hat PAM and DM you can author decisions using: Business Central (in RHPAM) or Decision Central (in RHDM) A more business friendly UI; Business Automation VSCode Extension A developer IDE ( Visual Studio Code ) extension that allows the visualization and editing of BPMN, DMN and Test Scenarios inside VSCode. There is also a set of community tooling that's also available for use. All the tools below are backed by Red Hat: Learn DMN in 15 minutes A guided tour in a website through the elements of DMN GitHub Chrome Extension A browser extension that allows you to visualize and edit BPMN, DMN and Test Scenario files directly in GitHub. Online Editors BPMN.new - A free online editor for business processes; DMN.new - A free online editor for decision models; PMML.new - A free online editor for scorecards; Business Modeler Hub Allows for the download of the: VSCode extension, GitHub Chrome Extension, and Desktop App","title":"Tooling Set"}]}